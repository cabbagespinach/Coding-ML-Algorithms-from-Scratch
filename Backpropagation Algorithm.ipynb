{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0d9b6b",
   "metadata": {
    "id": "0e0d9b6b"
   },
   "source": [
    "# Implementation of the Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0173f1",
   "metadata": {
    "id": "0a0173f1"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5ab192",
   "metadata": {
    "id": "4d5ab192"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arvir\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Arvir\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d6dd6",
   "metadata": {
    "id": "510d6dd6"
   },
   "source": [
    "## Functions for the Multilayer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5df1624",
   "metadata": {
    "id": "c5df1624"
   },
   "outputs": [],
   "source": [
    "def xavier_init(fan_in, fan_out):\n",
    "    limit = np.sqrt(6 / (fan_in + fan_out))\n",
    "    return np.random.uniform(-limit, limit, size=(fan_in, fan_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ab5b12",
   "metadata": {
    "id": "e4ab5b12"
   },
   "outputs": [],
   "source": [
    "def get_activation_potential(input_neurons, weight):\n",
    "    return input_neurons @ weight.T\n",
    "\n",
    "def augment_matrix(matrix):\n",
    "    return np.hstack((np.ones((matrix.shape[0], 1)), matrix))\n",
    "\n",
    "def compute_delta(input_, gradient, learning_rate):\n",
    "    batch_size = input_.shape[0]\n",
    "    i = 0\n",
    "    overall_delta = []\n",
    "    while i < batch_size:\n",
    "        batch_delta = np.array([])\n",
    "        for neuron in gradient[i]:\n",
    "            batch_delta = np.concatenate((batch_delta, input_[i] * neuron * learning_rate))\n",
    "        i += 1\n",
    "        overall_delta.append(batch_delta)\n",
    "    return np.mean(overall_delta, axis=0)\n",
    "\n",
    "def choose_function(function_name, logistic, tanh, relu):\n",
    "    if function_name == 'logistic':\n",
    "        return logistic\n",
    "    elif function_name == 'tanh':\n",
    "        return tanh\n",
    "    elif function_name == 'relu':\n",
    "        return relu\n",
    "    else: return 'Invalid Function Name'\n",
    "\n",
    "def get_error(desired_output, output_neurons):\n",
    "    return (1/2)*((desired_output - output_neurons)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10670aa",
   "metadata": {
    "id": "d10670aa"
   },
   "outputs": [],
   "source": [
    "def logistic_output(activation,logistic_slope_param):\n",
    "    return 1/(1+np.exp(-1*logistic_slope_param*activation))\n",
    "\n",
    "# Local gradient output of the output layer should have the same dimension as the output matrix of the output layer\n",
    "def logistic_gradient_output(desired_output, output_neurons, logistic_slope_param):\n",
    "    return logistic_slope_param * np.multiply(np.multiply((desired_output - output_neurons),\n",
    "                                            output_neurons\n",
    "                                            ),(1-output_neurons))\n",
    "\n",
    "def logistic_gradient_hidden(hidden_neurons, output_gradient,\n",
    "                                   output_weight, logistic_slope_param):\n",
    "\n",
    "    summation = output_gradient @ output_weight\n",
    "    summation = summation[:, 1:]\n",
    "\n",
    "    return logistic_slope_param * np.multiply(np.multiply(hidden_neurons,\n",
    "                                            (1-hidden_neurons)),\n",
    "                                            summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9465d1b",
   "metadata": {
    "id": "e9465d1b"
   },
   "outputs": [],
   "source": [
    "def tanh_output(activation, a, b):\n",
    "    return a * np.tanh(b * activation)\n",
    "\n",
    "def tanh_gradient_output(desired_output, output_neurons, a, b):\n",
    "    return np.multiply(\n",
    "        (b / a) * (desired_output - output_neurons),\n",
    "        np.multiply(a - output_neurons, a + output_neurons))\n",
    "\n",
    "def tanh_gradient_hidden(hidden_neurons, output_gradient_tanh, output_weight, a, b):\n",
    "    return (b / a) * (output_gradient_tanh @ output_weight)[:, 1:] * (a - hidden_neurons) * (a + hidden_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc81706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_output(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # For numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7461bbd7",
   "metadata": {
    "id": "7461bbd7"
   },
   "outputs": [],
   "source": [
    "def relu_output(activation, leaky_param):\n",
    "    return np.where(activation > 0, activation, activation * leaky_param)\n",
    "\n",
    "def relu_gradient_output(output_neurons, leaky_param):\n",
    "    return np.where(output_neurons >= 0, output_neurons, leaky_param)\n",
    "\n",
    "def relu_gradient_hidden(hidden_neurons, output_gradient, output_weight, leaky_param):\n",
    "    multiplier = np.where(hidden_neurons > 0, 1, leaky_param)\n",
    "    return multiplier * ((output_gradient @ output_weight)[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb606aa",
   "metadata": {
    "id": "4cb606aa"
   },
   "source": [
    "## Functions for the plot and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05fab3ed",
   "metadata": {
    "id": "05fab3ed"
   },
   "outputs": [],
   "source": [
    "def plot_curves(training_results, validation_results, filename, display_to_screen=False, save_to_file=True):\n",
    "    df_train = pd.DataFrame(training_results)\n",
    "    df_val = pd.DataFrame(validation_results)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Plot Training SSE on primary y-axis\n",
    "    x_train = df_train['Epoch'] + (df_train['Iteration'] - 1) * 5\n",
    "    ax1.plot(x_train, df_train['SSE'], label='Training SSE', color='tab:blue')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Training SSE', color='tab:blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # Create secondary y-axis for Validation SSE\n",
    "    ax2 = ax1.twinx()\n",
    "    x_val = df_val['Iteration'] * 5\n",
    "    ax2.plot(x_val, df_val['SSE'], label='Validation SSE', color='tab:orange', linestyle='--')\n",
    "    ax2.set_ylabel('Validation SSE', color='tab:orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "    # Title and grid\n",
    "    plt.title('Training vs Validation SSE')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create a combined legend\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_to_file:\n",
    "        plt.savefig(filename)\n",
    "    if display_to_screen:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_curves_misclassifications(training_results, validation_results, filename, display_to_screen=False, save_to_file=True):\n",
    "    df_train = pd.DataFrame(training_results)\n",
    "    df_val = pd.DataFrame(validation_results)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Plot Training SSE on primary y-axis\n",
    "    x_train = df_train['Epoch'] + (df_train['Iteration'] - 1) * 5\n",
    "    ax1.plot(x_train, df_train['Misclassifications'], label='Training Misclassifications', color='tab:blue')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Training Misclassifications', color='tab:blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # Create secondary y-axis for Validation SSE\n",
    "    ax2 = ax1.twinx()\n",
    "    x_val = df_val['Iteration'] * 5\n",
    "    ax2.plot(x_val, df_val['Misclassifications'], label='Validation Misclassifications', color='tab:orange', linestyle='--')\n",
    "    ax2.set_ylabel('Validation Misclassifications', color='tab:orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "    # Title and grid\n",
    "    plt.title('Training vs Validation Misclassifications')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create a combined legend\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_to_file:\n",
    "        plt.savefig(filename)\n",
    "    if display_to_screen:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def compute_confusion_matrix(predictions, labels, num_classes=8):\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    for true, pred in zip(labels, predictions):\n",
    "        matrix[true-1][pred-1] += 1  # row = true, column = predicted\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def plot_confusion_matrix_pure_matplotlib(conf_matrix, filename, class_names=None, normalize=False,  display_to_screen=False, save_to_file=True):\n",
    "    if normalize:\n",
    "        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1, keepdims=True)\n",
    "        conf_matrix = np.round(conf_matrix, 2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cax = ax.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\" + (\" (Normalized)\" if normalize else \"\"))\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Tick labels\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(conf_matrix.shape[0])]\n",
    "\n",
    "    ax.set_xticks(np.arange(len(class_names)))\n",
    "    ax.set_yticks(np.arange(len(class_names)))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Display numbers inside the heatmap\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            text = f\"{conf_matrix[i, j]:.2f}\" if normalize else int(conf_matrix[i, j])\n",
    "            ax.text(j, i, text,\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_to_file:\n",
    "        plt.savefig(filename)\n",
    "    if display_to_screen:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def accuracy(conf_matrix):\n",
    "    correct = np.trace(conf_matrix)\n",
    "    total = np.sum(conf_matrix)\n",
    "    return correct / total\n",
    "\n",
    "def precision_recall_f1(conf_matrix):\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    f1 = np.zeros(num_classes)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i]\n",
    "        FP = conf_matrix[:, i].sum() - TP\n",
    "        FN = conf_matrix[i, :].sum() - TP\n",
    "\n",
    "        precision[i] = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        recall[i] = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "        if (precision[i] + recall[i]) > 0:\n",
    "            f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "        else:\n",
    "            f1[i] = 0.0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def matthews_corrcoef(conf_matrix):\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    mcc = np.zeros(num_classes)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i]\n",
    "        FP = conf_matrix[:, i].sum() - TP\n",
    "        FN = conf_matrix[i, :].sum() - TP\n",
    "        TN = conf_matrix.sum() - (TP + FP + FN)\n",
    "\n",
    "        numerator = (TP * TN) - (FP * FN)\n",
    "        denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "        mcc[i] = numerator / denominator if denominator > 0 else 0.0\n",
    "\n",
    "    return mcc\n",
    "\n",
    "def save_metrics_to_file(conf_matrix, filepath):\n",
    "    acc = accuracy(conf_matrix)\n",
    "    prec, rec, f1 = precision_recall_f1(conf_matrix)\n",
    "    mcc = matthews_corrcoef(conf_matrix)\n",
    "\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(\"=== Evaluation Metrics ===\\n\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(f\"{'Class':<10}{'Precision':<12}{'Recall':<12}{'F1-Score':<12}{'MCC':<12}\\n\")\n",
    "        f.write(\"-\" * 58 + \"\\n\")\n",
    "        for i in range(len(prec)):\n",
    "            f.write(f\"{i:<10}{prec[i]:<12.4f}{rec[i]:<12.4f}{f1[i]:<12.4f}{mcc[i]:<12.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168effe",
   "metadata": {
    "id": "d168effe"
   },
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff54428e",
   "metadata": {
    "id": "ff54428e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', header=None)\n",
    "df_labels = pd.read_csv('data_labels.csv', header=None)\n",
    "df_test = pd.read_csv('test_set.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850de905",
   "metadata": {
    "id": "850de905"
   },
   "source": [
    "## Apply SMOTE to the imbalanced dataset, then split the dataset into training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d85d144",
   "metadata": {
    "id": "5d85d144",
    "outputId": "50f168cc-dbcb-4db4-b5e3-86937bf8031a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE - X: (13000, 354)\n",
      "After SMOTE - y: (13000, 1)\n",
      "Train X: (12200, 354) Train y: (12200, 1)\n",
      "Test X: (800, 354) Test y: (800, 1)\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(df, df_labels)\n",
    "\n",
    "print(\"After SMOTE - X:\", X_resampled.shape)\n",
    "print(\"After SMOTE - y:\", y_resampled.shape)\n",
    "\n",
    "# Train-test split\n",
    "validation_size = 800\n",
    "validation_indices = random.sample(range(len(X_resampled)), 800)\n",
    "\n",
    "validation_set = X_resampled.loc[validation_indices]\n",
    "training_set = X_resampled.drop(validation_indices)\n",
    "\n",
    "validation_labels = y_resampled.loc[validation_indices]\n",
    "training_labels = y_resampled.drop(validation_indices)\n",
    "\n",
    "print(\"Train X:\", training_set.shape, \"Train y:\", training_labels.shape)\n",
    "print(\"Test X:\", validation_set.shape, \"Test y:\", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf382d4f",
   "metadata": {
    "id": "cf382d4f"
   },
   "outputs": [],
   "source": [
    "training_set.to_csv('training_set.csv')\n",
    "validation_set.to_csv('validation_set.csv')\n",
    "training_labels.to_csv('training_labels.csv')\n",
    "validation_labels.to_csv('validation_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91208e6b",
   "metadata": {
    "id": "91208e6b",
    "outputId": "d5d543e5-5804-4518-b5c6-e57f9ba9c969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5    1548\n",
      "3    1532\n",
      "4    1530\n",
      "7    1526\n",
      "8    1524\n",
      "1    1519\n",
      "6    1514\n",
      "2    1507\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(training_labels['0'].value_counts())\n",
    "except:\n",
    "    try:\n",
    "        print(training_labels[0].value_counts())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e16046d",
   "metadata": {
    "id": "3e16046d",
    "outputId": "7731db00-dab9-4a7a-aed1-ceb0cc93d845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2    118\n",
      "6    111\n",
      "1    106\n",
      "8    101\n",
      "7     99\n",
      "4     95\n",
      "3     93\n",
      "5     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(validation_labels['0'].value_counts())\n",
    "except:\n",
    "    try:\n",
    "        print(validation_labels[0].value_counts())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e093768",
   "metadata": {},
   "source": [
    "## Fixed Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9449ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "momentum_term = 0.9\n",
    "logistic_slope_param = 2\n",
    "\n",
    "epoch = 5\n",
    "patience = 10\n",
    "min_delta = 0.001\n",
    "\n",
    "input_layer_count = 354\n",
    "output_layer_count = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bda6f5",
   "metadata": {
    "id": "d0bda6f5"
   },
   "source": [
    "### Network A Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb2f75c",
   "metadata": {
    "id": "9bb2f75c"
   },
   "outputs": [],
   "source": [
    "Network = 'A'\n",
    "\n",
    "# tanh, logistic, relu\n",
    "function_hidden1 = 'tanh'\n",
    "function_hidden2 = 'tanh'\n",
    "function_output = 'logistic'\n",
    "\n",
    "tanh_param_a = 1.716\n",
    "tanh_param_b = 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96338aa",
   "metadata": {},
   "source": [
    "### Network B Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9397fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh, logistic, relu\n",
    "function_hidden1 = 'relu'\n",
    "function_hidden2 = 'relu'\n",
    "function_output = 'logistic'\n",
    "\n",
    "leaky_param = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea742d66",
   "metadata": {
    "id": "ea742d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter options\n",
    "nodes_options = [[256,256],[256,128],[256,64],[256,32],[256,16],[128,64],[128,16],[32,16],[16,16]]\n",
    "learning_rate_options = [0.001,0.005,0.01]\n",
    "\n",
    "# Create the list of hyperparameter combinations\n",
    "hyperparameter_configs = []\n",
    "\n",
    "for option in nodes_options:\n",
    "    for lr in learning_rate_options:\n",
    "        config = {\n",
    "            \"hidden1\": option[0],\n",
    "            \"hidden2\": option[1],\n",
    "            \"learning_rate\": lr\n",
    "        }\n",
    "        hyperparameter_configs.append(config)\n",
    "\n",
    "print(len(hyperparameter_configs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b42b22",
   "metadata": {
    "id": "06b42b22"
   },
   "source": [
    "# Training Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8242bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_v2(function_hidden1, function_hidden2, function_output, Xb, W1, W2, W3, b1, b2, b3, Yb, tanh_param_a, tanh_param_b, logistic_slope_param, leaky_param):\n",
    "    # — forward —\n",
    "    z1 = Xb.dot(W1) + b1                                        # (mb×H1)\n",
    "    if function_hidden1 == 'relu':\n",
    "        a1 = relu_output(z1, leaky_param)                       # (mb×H1)\n",
    "    elif function_hidden1 == 'logistic':\n",
    "        a1 = logistic_output(z1, logistic_slope_param)         # (mb×H1)\n",
    "    elif function_hidden1 == 'tanh':\n",
    "        a1 = tanh_output(z1, tanh_param_a, tanh_param_b)\n",
    "    \n",
    "    z2 = a1.dot(W2) + b2                                        # (mb×H2)\n",
    "    if function_hidden2 == 'relu':\n",
    "        a2 = relu_output(z2, leaky_param)                       # (mb×H2)\n",
    "    elif function_hidden2 == 'logistic':\n",
    "        a2 = logistic_output(z2, logistic_slope_param)         # (mb×H2)\n",
    "    elif function_hidden2 == 'tanh':\n",
    "        a2 = tanh_output(z2, tanh_param_a, tanh_param_b)\n",
    "\n",
    "    z3 = a2.dot(W3) + b3                                      # (mb×C)\n",
    "    if function_output == 'relu':\n",
    "        ŷ = relu_output(z3, leaky_param)                    # (mb×C)\n",
    "    elif function_output == 'logistic':\n",
    "        ŷ = logistic_output(z3, logistic_slope_param)            # (mb×C)\n",
    "    elif function_output == 'tanh':\n",
    "        ŷ = tanh_output(z3, tanh_param_a, tanh_param_b)            # (mb×C)\n",
    "    if not Yb:\n",
    "        return ŷ\n",
    "    sse = get_error(Yb, ŷ)\n",
    "    total_sse += sse\n",
    "\n",
    "    classification_computed = np.argmax(ŷ, axis=1)\n",
    "    classification_actual = np.argmax(Yb, axis=1)\n",
    "    misclassification_count = np.sum(classification_computed != classification_actual)\n",
    "    total_misclassifications += misclassification_count\n",
    "    \n",
    "    return sse, misclassification_count, classification_actual, classification_computed\n",
    "\n",
    "def tanh_gradient_hidden_v2(hidden_neurons, output_gradient_tanh, output_weight, a, b):\n",
    "    return (b / a) * (output_gradient_tanh @ output_weight.T) * (a - hidden_neurons) * (a + hidden_neurons)\n",
    "\n",
    "def relu_gradient_hidden_v2(hidden_neurons, output_gradient, output_weight, leaky_param):\n",
    "    multiplier = np.where(hidden_neurons > 0, 1, leaky_param)\n",
    "    return multiplier * ((output_gradient @ output_weight.T))\n",
    "\n",
    "def logistic_gradient_hidden_v2(hidden_neurons, output_gradient,\n",
    "                                   output_weight, logistic_slope_param):\n",
    "\n",
    "    summation = output_gradient @ output_weight.T\n",
    "    summation = summation\n",
    "\n",
    "    return logistic_slope_param * np.multiply(np.multiply(hidden_neurons,\n",
    "                                            (1-hidden_neurons)),\n",
    "                                            summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f65d9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def backprop_training_v2(df, df_labels, patience, hidden_layer_count1, hidden_layer_count2,\n",
    "                         learning_rate, tanh_param_a, tanh_param_b, leaky_param, logistic_slope_param,\n",
    "                         activation_function1=\"tanh\", activation_function2=\"tanh\"):\n",
    "    now = datetime.now()\n",
    "    start_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    # 1) SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(df, df_labels)\n",
    "\n",
    "    # 2) After SMOTE, convert to numpy arrays once:\n",
    "    X = X_resampled            # shape (N, D)\n",
    "    y = pd.get_dummies(y_resampled[0],\n",
    "                    columns=list(range(1,9))).sort_index(axis=1)\n",
    "                                        # shape (N, C), one-hot\n",
    "\n",
    "    # 3) Single train/validation split:\n",
    "    # Train-test split\n",
    "    validation_size = 800\n",
    "    validation_indices = random.sample(range(len(X_resampled)), validation_size)\n",
    "\n",
    "    X_val = X.loc[validation_indices]\n",
    "    X_train = X.drop(validation_indices)\n",
    "\n",
    "    y_val = y.loc[validation_indices]\n",
    "    y_train = y.drop(validation_indices)\n",
    "\n",
    "    X_val = X_val.to_numpy()\n",
    "    X_train = X_train.to_numpy()\n",
    "    y_val = y_val.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    patience     = 10       # how many epochs to wait without improvement\n",
    "    max_epochs   = 50        # a hard cap, in case validation never improves\n",
    "\n",
    "    # 4) In your training loop, shuffle each epoch and batch by slicing:\n",
    "    m, D = X_train.shape\n",
    "    _, C = y_train.shape\n",
    "    H1 = hidden_layer_count1\n",
    "    H2 = hidden_layer_count2\n",
    "\n",
    "    # 5) Initialize weights & biases once\n",
    "    W1 = xavier_init(D, H1);  b1 = np.zeros((1, H1))\n",
    "    W2 = xavier_init(H1, H2); b2 = np.zeros((1, H2))\n",
    "    W3 = xavier_init(H2, C);  b3 = np.zeros((1, C))\n",
    "\n",
    "    # 6) Initialize velocities for momentum\n",
    "    vW1 = np.zeros_like(W1);  vb1 = np.zeros_like(b1)\n",
    "    vW2 = np.zeros_like(W2);  vb2 = np.zeros_like(b2)\n",
    "    vW3 = np.zeros_like(W3);  vb3 = np.zeros_like(b3)\n",
    "\n",
    "    m = X_train.shape[0]\n",
    "\n",
    "    patience_counter  = 0\n",
    "\n",
    "    training_results = []\n",
    "    validation_results = []\n",
    "    iteration = 0\n",
    "\n",
    "    min_sse = float('inf')\n",
    "    min_misclassifications = float('inf')\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        # Collect all \n",
    "        training_all_actual = []\n",
    "        training_all_computed = []\n",
    "        validation_all_actual = []\n",
    "        validation_all_computed = []\n",
    "\n",
    "        # ———  Shuffle training set  —————————————\n",
    "        perm    = np.random.permutation(m)\n",
    "        X_shuff = X_train[perm]\n",
    "        Y_shuff = y_train[perm]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_acc  = 0\n",
    "        total_sse = 0\n",
    "        total_misclassifications = 0\n",
    "\n",
    "        # ———  Mini-batch training  ——————————————\n",
    "        for start in range(0, m, batch_size):\n",
    "            end      = start + batch_size\n",
    "            Xb, Yb   = X_shuff[start:end], Y_shuff[start:end]\n",
    "            mb       = Xb.shape[0]              # last batch might be smaller\n",
    "\n",
    "            z1 = Xb.dot(W1) + b1                                        # (mb×H1)\n",
    "            if activation_function1 == \"tanh\":\n",
    "                a1 = tanh_output(z1, tanh_param_a, tanh_param_b)\n",
    "            elif activation_function1 == \"relu\":\n",
    "                a1 = relu_output(z1, leaky_param)\n",
    "            elif activation_function1 == \"logistic\":\n",
    "                a1 = logistic_output(z1, logistic_slope_param)\n",
    "            \n",
    "            z2 = a1.dot(W2) + b2                                        # (mb×H2)\n",
    "            if activation_function2 == \"tanh\":\n",
    "                a2 = tanh_output(z2, tanh_param_a, tanh_param_b)\n",
    "            elif activation_function2 == \"relu\":\n",
    "                a2 = relu_output(z2, leaky_param)\n",
    "            elif activation_function2 == \"logistic\":\n",
    "                a2 = logistic_output(z2, logistic_slope_param)\n",
    "\n",
    "            z3   = a2.dot(W3) + b3                                      # (mb×C)\n",
    "            ŷ    = logistic_output(z3, logistic_slope_param)            # (mb×C)\n",
    "\n",
    "            sse = get_error(Yb, ŷ)\n",
    "            total_sse += sse\n",
    "\n",
    "            classification_computed = np.argmax(ŷ, axis=1)\n",
    "            classification_actual = np.argmax(Yb, axis=1)\n",
    "            misclassification_count = np.sum(classification_computed != classification_actual)\n",
    "            total_misclassifications += misclassification_count\n",
    "\n",
    "            # inside your batch loop, replace the SSE/loss & E computation with:\n",
    "            eps = 1e-8  # to avoid log(0)\n",
    "            # — BINARY CROSS–ENTROPY LOSS —\n",
    "            # Yb: (mb×C) one-hot / binary labels\n",
    "            # y_hat: (mb×C) sigmoid outputs in (0,1)\n",
    "            bce_loss = -np.sum(\n",
    "                Yb * np.log(ŷ + eps) +\n",
    "                (1 - Yb) * np.log(1 - ŷ + eps)\n",
    "            ) / mb\n",
    "\n",
    "            # track total loss/accuracy as before\n",
    "            epoch_loss += bce_loss * mb\n",
    "            preds = (ŷ >= 0.5).astype(int)           # threshold at 0.5\n",
    "            labels = Yb\n",
    "            acc   = np.mean(preds == labels)\n",
    "            epoch_acc += acc * mb\n",
    "\n",
    "            # — GRADIENT AT OUTPUT LAYER —  \n",
    "            # For sigmoid + BCE, the upstream delta simplifies to:\n",
    "            E = (ŷ - Yb)                        # shape (mb×C)\n",
    "\n",
    "            # now proceed exactly as you already do:\n",
    "            dW3 = (a2.T @ E) / mb                   # (H2×C)\n",
    "            db3 =  E.sum(axis=0, keepdims=True) / mb\n",
    "\n",
    "            # and then your tanh-backprop for the hidden layers:\n",
    "            if activation_function2 == \"tanh\":\n",
    "                d2 = tanh_gradient_hidden_v2(a2, E, W3, tanh_param_a, tanh_param_b)\n",
    "            elif activation_function2 == \"relu\":\n",
    "                d2 = relu_gradient_hidden_v2(a2, E, W3, leaky_param)\n",
    "            elif activation_function2 == \"logistic\":\n",
    "                d2 = logistic_gradient_hidden_v2(a2, E, W3, logistic_slope_param)\n",
    "            dW2 = (a1.T @ d2) / mb\n",
    "            db2 =  d2.sum(axis=0, keepdims=True) / mb\n",
    "\n",
    "            if activation_function1 == \"tanh\":\n",
    "                d1 = tanh_gradient_hidden_v2(a1, d2, W2, tanh_param_a, tanh_param_b)\n",
    "            elif activation_function1 == \"relu\":\n",
    "                d1 = relu_gradient_hidden_v2(a1, d2, W2, leaky_param)\n",
    "            elif activation_function1 == \"logistic\":\n",
    "                d1 = logistic_gradient_hidden_v2(a1, d2, W2, logistic_slope_param)\n",
    "            dW1 = (Xb.T @ d1) / mb\n",
    "            db1 =  d1.sum(axis=0, keepdims=True) / mb\n",
    "\n",
    "            # — momentum updates —\n",
    "            vW3 = momentum_term*vW3 + (1-momentum_term)*dW3\n",
    "            vb3 = momentum_term*vb3 + (1-momentum_term)*db3\n",
    "            W3 -= learning_rate * vW3\n",
    "            b3 -= learning_rate * vb3\n",
    "\n",
    "            vW2 = momentum_term*vW2 + (1-momentum_term)*dW2\n",
    "            vb2 = momentum_term*vb2 + (1-momentum_term)*db2\n",
    "            W2 -= learning_rate * vW2\n",
    "            b2 -= learning_rate * vb2\n",
    "\n",
    "            vW1 = momentum_term*vW1 + (1-momentum_term)*dW1\n",
    "            vb1 = momentum_term*vb1 + (1-momentum_term)*db1\n",
    "            W1 -= learning_rate * vW1\n",
    "            b1 -= learning_rate * vb1\n",
    "\n",
    "            training_all_actual.extend(np.argmax(Yb, axis=1))\n",
    "            training_all_computed.extend(classification_computed)\n",
    "\n",
    "        temp_dict = {}\n",
    "        temp_dict['Iteration'] = iteration\n",
    "        temp_dict['Epoch'] = epoch\n",
    "        temp_dict['SSE'] = total_sse\n",
    "        temp_dict['Misclassifications'] = total_misclassifications\n",
    "        temp_dict['Training Loss'] = epoch_loss\n",
    "        temp_dict['Training Accuracy'] = epoch_acc\n",
    "        temp_dict['Training Misclassifications'] = total_misclassifications\n",
    "        training_results.append(temp_dict)\n",
    "\n",
    "        # ———  End of epoch metrics  ——————————————\n",
    "        epoch_loss /= m\n",
    "        epoch_acc  /= m\n",
    "\n",
    "        # ———  Validation pass  ————————————————\n",
    "        # (vectorized, no weight updates)\n",
    "        # compute loss, acc, misclassifications\n",
    "        total_sse = 0\n",
    "        total_misclassifications = 0\n",
    "        if epoch % 5 == 0:\n",
    "            z1_val = X_val.dot(W1) + b1\n",
    "            a1_val = tanh_output(z1_val, tanh_param_a, tanh_param_b)\n",
    "\n",
    "            z2_val = a1_val.dot(W2) + b2\n",
    "            a2_val = tanh_output(z2_val, tanh_param_a, tanh_param_b)\n",
    "\n",
    "            z3_val = a2_val.dot(W3) + b3\n",
    "            y_hat_val = logistic_output(z3_val, logistic_slope_param)\n",
    "\n",
    "            val_loss = -np.sum(y_val * np.log(y_hat_val + 1e-8)) / X_val.shape[0]\n",
    "            val_preds = np.argmax(y_hat_val, axis=1)\n",
    "            val_labels = np.argmax(y_val, axis=1)\n",
    "            val_acc = np.mean(val_preds == val_labels)\n",
    "            val_mis = np.sum(val_preds != val_labels)\n",
    "            sse = get_error(y_val, y_hat_val)\n",
    "            min_sse = min(sse, min_sse)\n",
    "\n",
    "            total_sse += sse\n",
    "            total_misclassifications += val_mis\n",
    "\n",
    "            # Edit here\n",
    "            validation_all_actual.extend(val_labels)\n",
    "            validation_all_computed.extend(val_preds)\n",
    "\n",
    "            temp_dict = {}\n",
    "            temp_dict['Iteration'] = iteration\n",
    "            temp_dict['SSE'] = total_sse\n",
    "            temp_dict['Misclassifications'] = total_misclassifications\n",
    "            temp_dict['Validation Loss'] = val_loss\n",
    "            temp_dict['Validation Accuracy'] = val_acc\n",
    "            temp_dict['Validation Misclassifications'] = val_mis\n",
    "            validation_results.append(temp_dict)\n",
    "            iteration += 1\n",
    "\n",
    "            print(f\"Epoch {epoch:>2}: \"\n",
    "                f\"train_loss={epoch_loss:.4f}, train_acc={epoch_acc:.4f} | \"\n",
    "                f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, \"\n",
    "                f\"val_mis={val_mis}\")\n",
    "\n",
    "            # — early stopping check —\n",
    "            if total_misclassifications < min_misclassifications:\n",
    "                patience_counter = 0\n",
    "                validation_all_actual_curr = copy.deepcopy(validation_all_actual)\n",
    "                validation_all_computed_curr = copy.deepcopy(validation_all_computed)\n",
    "                training_all_actual_curr = copy.deepcopy(training_all_actual)\n",
    "                training_all_computed_curr = copy.deepcopy(training_all_computed)\n",
    "                min_misclassifications = total_misclassifications*1\n",
    "                min_train_acc = epoch_acc*1\n",
    "                min_train_loss = epoch_loss*1\n",
    "                min_val_acc = val_acc*1\n",
    "                min_val_loss = val_loss*1\n",
    "                print('Min SSE:', min_sse)\n",
    "                print('Min Misclassifications:', min_misclassifications)\n",
    "                best_W1, best_b1 = W1.copy(), b1.copy()\n",
    "                best_W2, best_b2 = W2.copy(), b2.copy()\n",
    "                best_W3, best_b3 = W3.copy(), b3.copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"  → no improvement for {patience_counter}/{patience} epochs\")\n",
    "\n",
    "            # stop if we've gone too long without improving\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Stopping early on epoch {epoch} (no val_loss improvement in last {patience} epochs).\")\n",
    "                break\n",
    "\n",
    "    print('learning rate:', learning_rate)\n",
    "    print('logistic slope:', logistic_slope_param)\n",
    "    print('Final Min SSE:', min_sse)\n",
    "    print('Final Min Misclassifications', min_misclassifications)\n",
    "\n",
    "    now = datetime.now()\n",
    "    end_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    t1 = datetime.strptime(start_time, '%H:%M:%S')\n",
    "    t2 = datetime.strptime(end_time, '%H:%M:%S')\n",
    "    training_duration = t2-t1\n",
    "\n",
    "    print(\"lengths\")\n",
    "    print(len(training_all_actual_curr))\n",
    "    print(len(training_all_computed_curr))\n",
    "    print(len(validation_all_actual_curr))\n",
    "    print(len(validation_all_computed_curr))\n",
    "\n",
    "    return (\n",
    "        training_results,\n",
    "        validation_results,\n",
    "        training_all_actual_curr,\n",
    "        training_all_computed_curr,\n",
    "        validation_all_actual_curr,\n",
    "        validation_all_computed_curr,\n",
    "        best_W1,\n",
    "        best_W2,\n",
    "        best_W3,\n",
    "        best_b1,\n",
    "        best_b2,\n",
    "        best_b3,\n",
    "        start_time,\n",
    "        end_time,\n",
    "        training_duration,\n",
    "        min_train_loss,\n",
    "        min_train_acc,\n",
    "        min_val_loss,\n",
    "        min_val_acc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89b46856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def calculate_and_save_metrics(training_results, validation_results, training_all_actual_curr,\n",
    "                               training_all_computed_curr, validation_all_actual_curr,\n",
    "                               validation_all_computed_curr, H1, H2, best_W1, best_W2, best_W3,\n",
    "                               best_b1, best_b2, best_b3, learning_rate, activation1, activation2,\n",
    "                               start_time, end_time, duration):\n",
    "    \n",
    "    # Create a folder for the current hyperparameter configuration\n",
    "    # Use the hyperparameters as the folder name\n",
    "    os.makedirs(os.path.join(\"artifacts\", f\"{H1}_{H2}_{activation1}_{activation2}_{learning_rate}\"), exist_ok=True)\n",
    "    folder_name = os.path.join(\"artifacts\", f\"{H1}_{H2}_{activation1}_{activation2}_{learning_rate}\")\n",
    "    filepath=\"hyperparameters.txt\"\n",
    "\n",
    "    with open(os.path.join(folder_name, filepath), 'w') as f:\n",
    "        f.write(f\"hidden_layer_count1: {H1}\\n\")\n",
    "        f.write(f\"hidden_layer_count2: {H2}\\n\")\n",
    "        f.write(f\"Network: {Network}\\n\")\n",
    "        f.write(f\"batch_size: {batch_size}\\n\")\n",
    "        f.write(f\"function_hidden1: {function_hidden1}\\n\")\n",
    "        f.write(f\"function_hidden2: {function_hidden2}\\n\")\n",
    "        f.write(f\"function_output: {function_output}\\n\")\n",
    "        f.write(f\"momentum_term: {momentum_term}\\n\")\n",
    "        f.write(f\"learning_rate: {learning_rate}\\n\")\n",
    "        f.write(f\"logistic_slope_param: {logistic_slope_param}\\n\")\n",
    "        f.write(f\"tanh_param_a: {tanh_param_a}\\n\")\n",
    "        f.write(f\"tanh_param_b: {tanh_param_b}\\n\")\n",
    "        f.write(f\"leaky_param: {leaky_param}\\n\")\n",
    "        f.write(f\"start:{start_time}\\n\")\n",
    "        f.write(f\"end:{end_time}\\n\")\n",
    "        f.write(f\"duration:{duration}\\n\")\n",
    "\n",
    "    # Export the files needed\n",
    "    training_actual_df = pd.DataFrame(training_all_actual_curr)\n",
    "    training_computed_df = pd.DataFrame(training_all_computed_curr)\n",
    "    validation_actual_df = pd.DataFrame(validation_all_actual_curr)\n",
    "    validation_computed_df = pd.DataFrame(validation_all_computed_curr)\n",
    "\n",
    "    best_W1_df = pd.DataFrame(best_W1)\n",
    "    best_b1_df = pd.DataFrame(best_b1)\n",
    "    best_W2_df = pd.DataFrame(best_W2)\n",
    "    best_b2_df = pd.DataFrame(best_b2)\n",
    "    best_W3_df = pd.DataFrame(best_W3)\n",
    "    best_b3_df = pd.DataFrame(best_b3)\n",
    "\n",
    "    # Includes the SSE and Total Misclassifications per Epoch\n",
    "    training_results_df = pd.DataFrame(training_results)\n",
    "\n",
    "    # Includes the SSE and Total Misclassifications per Iteration (5 epochs)\n",
    "    validation_results_df = pd.DataFrame(validation_results)\n",
    "\n",
    "    training_actual_df.to_csv(os.path.join(folder_name, 'Training_Actual.csv'), index=False)\n",
    "    training_computed_df.to_csv(os.path.join(folder_name, 'Training_Computed.csv'), index=False)\n",
    "    validation_actual_df.to_csv(os.path.join(folder_name, 'Validation_Actual.csv'), index=False)\n",
    "    validation_computed_df.to_csv(os.path.join(folder_name, 'Validation_Computed.csv'), index=False)\n",
    "\n",
    "    training_results_df.to_csv(os.path.join(folder_name, 'training_results.csv'), index=False)\n",
    "    validation_results_df.to_csv(os.path.join(folder_name, 'validation_results.csv'), index=False)\n",
    "\n",
    "    best_W1_df.to_csv(os.path.join(folder_name, 'hidden_weight1.csv'), index=False, header=None)\n",
    "    best_b1_df.to_csv(os.path.join(folder_name, 'hidden_biases1.csv'), index=False, header=None)\n",
    "    best_W2_df.to_csv(os.path.join(folder_name, 'hidden_weight2.csv'), index=False, header=None)\n",
    "    best_b2_df.to_csv(os.path.join(folder_name, 'hidden_biases2.csv'), index=False, header=None)\n",
    "    best_W3_df.to_csv(os.path.join(folder_name, 'output_weight.csv'), index=False, header=None)\n",
    "    best_b3_df.to_csv(os.path.join(folder_name, 'output_biases.csv'), index=False, header=None)\n",
    "\n",
    "    # Training and Validation SSE per Epoch\n",
    "    plot_curves(training_results, validation_results, filename=os.path.join(folder_name,\"training_curves.png\"))\n",
    "    plot_curves_misclassifications(training_results, validation_results, filename=os.path.join(folder_name,\"training_curves_misc.png\"))\n",
    "\n",
    "    # Confusion Matrix for the Training Set\n",
    "    training_cm = compute_confusion_matrix(training_all_computed_curr, training_all_actual_curr, num_classes=8)\n",
    "    class_names = ['Class 1', 'Class 2', 'Class 3', 'Class 4',\n",
    "                'Class 5', 'Class 6', 'Class 7', 'Class 8']\n",
    "\n",
    "    plot_confusion_matrix_pure_matplotlib(training_cm, os.path.join(folder_name, \"training_confusion_matrix.png\"), class_names, normalize=False)\n",
    "\n",
    "    # Export the Accuracy, Precision, Recall, F1 scores, Matthews Correlation Coefficient\n",
    "    save_metrics_to_file(training_cm, os.path.join(folder_name, \"training_metrics.txt\"))\n",
    "\n",
    "    validation_cm = compute_confusion_matrix(validation_all_computed_curr, validation_all_actual_curr, num_classes=8)\n",
    "    plot_confusion_matrix_pure_matplotlib(validation_cm, os.path.join(folder_name, \"validation_confusion_matrix.png\"), class_names, normalize=False)\n",
    "\n",
    "    # Export the Accuracy, Precision, Recall, F1 scores, Matthews Correlation Coefficient\n",
    "    save_metrics_to_file(validation_cm, os.path.join(folder_name, \"validation_metrics.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08f6d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 1 ---------\n",
      "h1 = 256\n",
      "h2 = 256\n",
      "{'hidden1': 256, 'hidden2': 256, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.0836, train_acc=0.8957 | val_loss=1.2930, val_acc=0.7163, val_mis=227\n",
      "Min SSE: 235.57618281603945\n",
      "Min Misclassifications: 227\n",
      "Epoch 10: train_loss=1.6119, train_acc=0.9195 | val_loss=0.9899, val_acc=0.7900, val_mis=168\n",
      "Min SSE: 179.71446326455958\n",
      "Min Misclassifications: 168\n",
      "Epoch 15: train_loss=1.3364, train_acc=0.9345 | val_loss=0.7968, val_acc=0.8512, val_mis=119\n",
      "Min SSE: 148.98095490750234\n",
      "Min Misclassifications: 119\n",
      "Epoch 20: train_loss=1.1416, train_acc=0.9433 | val_loss=0.6650, val_acc=0.8900, val_mis=88\n",
      "Min SSE: 126.5322982715096\n",
      "Min Misclassifications: 88\n",
      "Epoch 25: train_loss=0.9896, train_acc=0.9511 | val_loss=0.5803, val_acc=0.8962, val_mis=83\n",
      "Min SSE: 109.48574340478373\n",
      "Min Misclassifications: 83\n",
      "Epoch 30: train_loss=0.8711, train_acc=0.9589 | val_loss=0.5042, val_acc=0.9038, val_mis=77\n",
      "Min SSE: 96.00387536823038\n",
      "Min Misclassifications: 77\n",
      "Epoch 35: train_loss=0.7787, train_acc=0.9654 | val_loss=0.4686, val_acc=0.9150, val_mis=68\n",
      "Min SSE: 86.12701878994531\n",
      "Min Misclassifications: 68\n",
      "Epoch 40: train_loss=0.7063, train_acc=0.9701 | val_loss=0.4349, val_acc=0.9213, val_mis=63\n",
      "Min SSE: 79.07685910503207\n",
      "Min Misclassifications: 63\n",
      "Epoch 45: train_loss=0.6486, train_acc=0.9730 | val_loss=0.4047, val_acc=0.9263, val_mis=59\n",
      "Min SSE: 72.15002262775234\n",
      "Min Misclassifications: 59\n",
      "Epoch 50: train_loss=0.5999, train_acc=0.9757 | val_loss=0.3655, val_acc=0.9337, val_mis=53\n",
      "Min SSE: 66.52269775463287\n",
      "Min Misclassifications: 53\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 66.52269775463287\n",
      "Final Min Misclassifications 53\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[1, 6, 1, 0, 0, 4, 6, 3, 5, 7, 3, 7, 5, 6, 1, 6, 4, 0, 2, 2, 4, 7, 4, 5, 0, 3, 7, 7, 5, 3, 1, 3, 4, 1, 0, 1, 2, 4, 7, 6, 3, 0, 1, 4, 1, 1, 2, 2, 5, 4, 1, 6, 4, 7, 5, 7, 2, 5, 5, 6, 2, 4, 5, 0, 3, 2, 4, 6, 3, 0, 1, 6, 3, 5, 7, 6, 7, 7, 7, 1, 3, 1, 7, 1, 4, 3, 2, 5, 7, 5, 6, 5, 5, 4, 6, 3, 1, 3, 7, 5, 1, 3, 5, 3, 1, 2, 1, 5, 1, 5, 3, 0, 2, 2, 2, 1, 2, 6, 4, 2, 5, 6, 2, 1, 7, 0, 7, 2, 3, 5, 0, 5, 7, 6, 4, 6, 2, 3, 2, 1, 3, 2, 0, 4, 2, 7, 3, 1, 6, 1, 6, 2, 5, 4, 4, 3, 7, 6, 2, 3, 4, 0, 4, 7, 0, 6, 5, 3, 5, 7, 4, 6, 7, 1, 2, 3, 0, 4, 2, 7, 2, 3, 5, 6, 5, 5, 0, 4, 6, 5, 4, 4, 5, 3, 4, 7, 1, 4, 7, 0, 2, 1, 6, 5, 7, 6, 7, 6, 7, 2, 1, 5, 7, 5, 3, 5, 7, 0, 6, 0, 1, 0, 7, 5, 0, 2, 7, 3, 4, 3, 5, 3, 0, 3, 1, 4, 3, 7, 4, 6, 3, 1, 1, 2, 1, 7, 4, 7, 6, 0, 2, 1, 3, 4, 5, 7, 1, 1, 5, 1, 5, 0, 2, 2, 0, 6, 4, 5, 2, 0, 1, 7, 1, 6, 2, 1, 3, 1, 5, 1, 5, 5, 2, 6, 3, 7, 3, 6, 1, 5, 4, 4, 1, 0, 1, 4, 2, 3, 0, 7, 0, 6, 6, 3, 5, 4, 7, 4, 2, 6, 4, 2, 6, 1, 5, 4, 1, 6, 2, 5, 2, 3, 3, 0, 3, 5, 4, 3, 7, 1, 4, 3, 7, 2, 1, 2, 1, 0, 0, 6, 0, 7, 1, 6, 1, 4, 5, 6, 4, 2, 5, 6, 7, 4, 6, 1, 3, 3, 2, 1, 6, 4, 5, 1, 2, 7, 2, 3, 4, 4, 3, 0, 7, 2, 6, 2, 6, 4, 4, 2, 5, 6, 7, 1, 3, 5, 1, 2, 2, 5, 5, 6, 0, 0, 7, 2, 6, 5, 5, 1, 1, 4, 0, 6, 2, 0, 4, 6, 7, 3, 2, 4, 3, 6, 6, 5, 2, 6, 7, 1, 3, 3, 1, 4, 3, 7, 3, 4, 0, 2, 6, 6, 7, 7, 4, 0, 0, 1, 0, 4, 1, 5, 5, 2, 1, 0, 2, 7, 3, 1, 6, 1, 4, 7, 1, 2, 0, 4, 1, 6, 1, 7, 2, 3, 2, 0, 6, 2, 2, 0, 6, 6, 3, 5, 0, 6, 6, 3, 7, 7, 4, 7, 5, 7, 0, 4, 2, 4, 4, 0, 1, 1, 7, 7, 4, 7, 4, 0, 7, 6, 2, 4, 7, 7, 2, 3, 4, 7, 5, 2, 1, 7, 6, 6, 2, 4, 4, 6, 1, 1, 0, 3, 0, 5, 7, 5, 5, 0, 1, 0, 5, 0, 6, 7, 1, 0, 7, 1, 2, 2, 4, 1, 0, 3, 5, 2, 0, 3, 2, 2, 7, 6, 0, 5, 0, 3, 3, 3, 7, 0, 2, 6, 4, 7, 1, 5, 3, 3, 0, 4, 1, 6, 1, 4, 7, 2, 5, 4, 4, 0, 6, 2, 2, 4, 5, 2, 3, 7, 1, 3, 6, 6, 5, 4, 1, 5, 0, 6, 7, 1, 0, 2, 5, 6, 0, 3, 0, 0, 6, 4, 0, 5, 4, 5, 3, 0, 5, 3, 3, 5, 7, 3, 7, 5, 2, 6, 3, 4, 1, 1, 5, 2, 3, 2, 3, 7, 3, 7, 3, 1, 4, 2, 5, 0, 4, 0, 0, 0, 2, 6, 5, 3, 1, 3, 3, 6, 7, 1, 1, 7, 0, 2, 6, 2, 4, 4, 2, 3, 4, 6, 3, 3, 5, 4, 0, 5, 1, 1, 4, 5, 4, 0, 4, 4, 2, 1, 4, 1, 0, 7, 7, 6, 0, 1, 3, 0, 1, 2, 2, 1, 4, 6, 3, 7, 5, 6, 0, 2, 0, 0, 6, 0, 7, 2, 6, 0, 4, 7, 7, 4, 3, 6, 1, 5, 0, 3, 3, 5, 4, 0, 1, 2, 5, 5, 6, 0, 7, 1, 4, 1, 4, 5, 1, 7, 2, 0, 7, 0, 4, 2, 3, 4, 2, 4, 2, 5, 0, 6, 5, 1, 7, 5, 3, 2, 2, 3, 7, 3, 0, 4, 7, 1, 7, 1, 0, 6, 5, 0, 3, 1, 3, 2, 5, 2, 4, 0, 3, 7, 2, 4, 6, 6, 5, 4, 1, 0, 4, 7, 5, 7]\n",
      "New best validation accuracy:  0.93375\n",
      "Given hidden layer counts and learning rate:  256 256 0.001\n",
      "New best training duration:  0:01:39\n",
      "Given hidden layer counts and learning rate:  256 256 0.001\n",
      "--------- Config 2 ---------\n",
      "h1 = 256\n",
      "h2 = 256\n",
      "{'hidden1': 256, 'hidden2': 256, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.0566, train_acc=0.9479 | val_loss=0.5361, val_acc=0.9113, val_mis=71\n",
      "Min SSE: 100.74273150340744\n",
      "Min Misclassifications: 71\n",
      "Epoch 10: train_loss=0.6355, train_acc=0.9730 | val_loss=0.2993, val_acc=0.9550, val_mis=36\n",
      "Min SSE: 55.96380163023914\n",
      "Min Misclassifications: 36\n",
      "Epoch 15: train_loss=0.4695, train_acc=0.9811 | val_loss=0.2197, val_acc=0.9663, val_mis=27\n",
      "Min SSE: 40.164019620957426\n",
      "Min Misclassifications: 27\n",
      "Epoch 20: train_loss=0.3729, train_acc=0.9850 | val_loss=0.2158, val_acc=0.9688, val_mis=25\n",
      "Min SSE: 36.18440193467002\n",
      "Min Misclassifications: 25\n",
      "Epoch 25: train_loss=0.3148, train_acc=0.9877 | val_loss=0.1391, val_acc=0.9800, val_mis=16\n",
      "Min SSE: 25.511942074113964\n",
      "Min Misclassifications: 16\n",
      "Epoch 30: train_loss=0.2741, train_acc=0.9895 | val_loss=0.1151, val_acc=0.9825, val_mis=14\n",
      "Min SSE: 21.208610966976632\n",
      "Min Misclassifications: 14\n",
      "Epoch 35: train_loss=0.2478, train_acc=0.9903 | val_loss=0.1621, val_acc=0.9762, val_mis=19\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 40: train_loss=0.2246, train_acc=0.9913 | val_loss=0.0775, val_acc=0.9850, val_mis=12\n",
      "Min SSE: 15.787882678401772\n",
      "Min Misclassifications: 12\n",
      "Epoch 45: train_loss=0.2066, train_acc=0.9924 | val_loss=0.1141, val_acc=0.9812, val_mis=15\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.1952, train_acc=0.9926 | val_loss=0.0741, val_acc=0.9900, val_mis=8\n",
      "Min SSE: 15.59063185295583\n",
      "Min Misclassifications: 8\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 15.59063185295583\n",
      "Final Min Misclassifications 8\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[0, 1, 3, 7, 2, 4, 2, 2, 0, 3, 7, 2, 6, 4, 2, 2, 0, 7, 3, 2, 2, 2, 6, 7, 4, 0, 0, 1, 2, 6, 6, 4, 3, 3, 1, 1, 6, 3, 6, 7, 3, 5, 0, 6, 7, 5, 5, 1, 6, 4, 7, 0, 2, 3, 5, 0, 1, 5, 7, 2, 0, 4, 3, 5, 1, 1, 0, 5, 0, 0, 6, 1, 2, 1, 2, 3, 5, 2, 2, 6, 3, 3, 4, 0, 4, 7, 7, 4, 1, 2, 7, 1, 7, 3, 3, 1, 5, 3, 6, 0, 0, 3, 2, 6, 7, 2, 5, 1, 4, 1, 2, 1, 6, 7, 6, 6, 4, 3, 1, 0, 1, 4, 3, 4, 4, 2, 0, 3, 2, 6, 5, 5, 5, 2, 3, 2, 1, 0, 5, 4, 1, 1, 1, 4, 1, 6, 7, 0, 1, 1, 0, 2, 2, 0, 5, 0, 1, 5, 2, 0, 2, 1, 4, 7, 2, 7, 5, 5, 3, 5, 4, 2, 3, 0, 1, 6, 6, 5, 4, 0, 4, 2, 1, 6, 7, 3, 2, 6, 5, 3, 3, 4, 3, 4, 3, 6, 2, 3, 2, 2, 0, 3, 5, 4, 7, 1, 7, 4, 2, 6, 4, 4, 2, 2, 4, 4, 2, 3, 4, 2, 6, 2, 0, 4, 5, 1, 6, 0, 3, 7, 2, 3, 7, 7, 5, 7, 5, 5, 4, 6, 7, 2, 4, 5, 4, 2, 3, 7, 1, 6, 5, 7, 3, 5, 4, 0, 0, 2, 7, 6, 2, 0, 1, 6, 1, 7, 2, 3, 7, 3, 5, 5, 2, 4, 4, 7, 3, 6, 6, 6, 4, 5, 1, 6, 4, 2, 3, 4, 6, 4, 6, 4, 4, 4, 0, 2, 2, 3, 0, 2, 7, 2, 7, 7, 4, 0, 5, 6, 6, 6, 7, 0, 6, 1, 0, 5, 3, 7, 2, 6, 7, 2, 5, 6, 6, 7, 5, 5, 3, 5, 1, 4, 5, 7, 3, 1, 5, 3, 3, 6, 2, 6, 5, 6, 0, 7, 4, 2, 5, 7, 4, 3, 0, 4, 0, 4, 4, 0, 6, 0, 4, 0, 4, 7, 1, 7, 2, 7, 4, 2, 1, 3, 0, 0, 2, 6, 7, 6, 5, 6, 5, 1, 5, 2, 5, 1, 1, 2, 0, 2, 4, 5, 6, 1, 4, 3, 2, 3, 6, 4, 6, 2, 0, 0, 6, 3, 7, 6, 0, 2, 5, 4, 1, 6, 3, 6, 7, 6, 5, 3, 4, 7, 0, 7, 4, 3, 7, 5, 0, 6, 4, 2, 7, 2, 0, 3, 1, 4, 1, 0, 0, 6, 7, 2, 2, 2, 6, 0, 0, 5, 7, 0, 2, 0, 2, 4, 4, 2, 2, 3, 0, 3, 0, 6, 4, 1, 2, 7, 3, 2, 6, 4, 7, 2, 0, 3, 7, 1, 6, 1, 2, 0, 1, 3, 7, 4, 2, 1, 4, 1, 7, 3, 0, 4, 2, 5, 7, 5, 7, 6, 6, 0, 4, 6, 3, 1, 7, 1, 7, 0, 2, 5, 6, 5, 4, 0, 3, 2, 1, 1, 6, 0, 0, 0, 4, 0, 5, 2, 1, 6, 1, 2, 2, 0, 4, 0, 4, 2, 5, 6, 6, 4, 2, 4, 6, 5, 1, 0, 4, 2, 1, 6, 0, 4, 0, 5, 4, 1, 7, 6, 6, 0, 5, 6, 3, 1, 4, 4, 1, 0, 6, 6, 0, 6, 7, 4, 4, 3, 3, 6, 2, 1, 6, 4, 2, 6, 3, 4, 7, 4, 0, 6, 7, 4, 5, 6, 2, 1, 1, 3, 7, 6, 1, 0, 5, 5, 2, 7, 6, 7, 4, 4, 6, 6, 6, 4, 0, 2, 5, 1, 0, 4, 4, 3, 4, 6, 6, 2, 4, 3, 6, 1, 7, 4, 0, 5, 4, 1, 7, 6, 1, 0, 7, 6, 1, 4, 2, 3, 2, 0, 5, 7, 5, 5, 5, 7, 2, 7, 5, 5, 7, 3, 5, 2, 2, 3, 3, 7, 3, 2, 2, 7, 7, 0, 2, 7, 1, 3, 7, 0, 3, 3, 5, 4, 0, 5, 1, 1, 1, 1, 1, 5, 3, 4, 3, 2, 7, 6, 1, 6, 2, 1, 4, 1, 4, 6, 0, 5, 0, 6, 4, 5, 4, 6, 3, 2, 4, 7, 5, 4, 2, 7, 4, 5, 6, 2, 4, 7, 1, 5, 1, 3, 3, 0, 6, 4, 3, 7, 6, 0, 0, 7, 4, 0, 7, 3, 6, 1, 0, 6, 7, 1, 3, 5, 2, 1, 2, 2, 1, 6, 0, 4, 6, 4, 0, 5, 6, 0, 7, 0, 3, 5, 1, 0, 1, 1, 0, 6, 1, 6, 7, 0, 4, 0, 7, 0, 5, 4, 3, 7, 3, 1, 3, 7, 5, 0, 2, 0, 7, 2]\n",
      "New best validation accuracy:  0.99\n",
      "Given hidden layer counts and learning rate:  256 256 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 3 ---------\n",
      "h1 = 256\n",
      "h2 = 256\n",
      "{'hidden1': 256, 'hidden2': 256, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.6955, train_acc=0.9697 | val_loss=0.3768, val_acc=0.9300, val_mis=56\n",
      "Min SSE: 70.04570391246659\n",
      "Min Misclassifications: 56\n",
      "Epoch 10: train_loss=0.4181, train_acc=0.9824 | val_loss=0.1920, val_acc=0.9700, val_mis=24\n",
      "Min SSE: 38.20427388999166\n",
      "Min Misclassifications: 24\n",
      "Epoch 15: train_loss=0.3251, train_acc=0.9864 | val_loss=0.1657, val_acc=0.9812, val_mis=15\n",
      "Min SSE: 30.80232409361986\n",
      "Min Misclassifications: 15\n",
      "Epoch 20: train_loss=0.2684, train_acc=0.9887 | val_loss=0.1208, val_acc=0.9850, val_mis=12\n",
      "Min SSE: 21.474797851955465\n",
      "Min Misclassifications: 12\n",
      "Epoch 25: train_loss=0.2379, train_acc=0.9901 | val_loss=0.1346, val_acc=0.9700, val_mis=24\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 30: train_loss=0.2101, train_acc=0.9915 | val_loss=0.0926, val_acc=0.9875, val_mis=10\n",
      "Min SSE: 18.032395366209172\n",
      "Min Misclassifications: 10\n",
      "Epoch 35: train_loss=0.1943, train_acc=0.9923 | val_loss=0.1006, val_acc=0.9900, val_mis=8\n",
      "Min SSE: 15.557670075239294\n",
      "Min Misclassifications: 8\n",
      "Epoch 40: train_loss=0.1906, train_acc=0.9920 | val_loss=0.0688, val_acc=0.9850, val_mis=12\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1636, train_acc=0.9931 | val_loss=0.0857, val_acc=0.9888, val_mis=9\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1634, train_acc=0.9931 | val_loss=0.0768, val_acc=0.9925, val_mis=6\n",
      "Min SSE: 13.296226846009755\n",
      "Min Misclassifications: 6\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 13.296226846009755\n",
      "Final Min Misclassifications 6\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[1, 4, 0, 6, 3, 0, 4, 6, 6, 3, 6, 0, 1, 6, 3, 7, 5, 4, 5, 2, 3, 0, 4, 0, 7, 4, 7, 5, 1, 5, 0, 7, 5, 1, 7, 3, 4, 5, 3, 7, 4, 6, 1, 1, 0, 5, 6, 2, 5, 4, 2, 3, 5, 2, 0, 6, 5, 2, 5, 5, 6, 0, 6, 4, 5, 1, 3, 1, 7, 5, 4, 5, 7, 6, 4, 5, 3, 4, 6, 7, 6, 6, 6, 3, 2, 1, 5, 1, 4, 7, 1, 7, 1, 4, 3, 7, 2, 0, 2, 0, 6, 5, 1, 6, 1, 6, 4, 5, 1, 0, 1, 5, 7, 7, 1, 2, 0, 3, 3, 0, 0, 7, 3, 6, 6, 7, 0, 5, 1, 6, 1, 1, 3, 1, 5, 7, 4, 1, 6, 6, 6, 3, 1, 1, 0, 1, 4, 4, 1, 6, 3, 2, 5, 3, 0, 1, 0, 1, 7, 6, 4, 3, 3, 0, 0, 7, 7, 6, 7, 6, 2, 0, 1, 6, 1, 3, 3, 4, 4, 2, 5, 2, 2, 1, 7, 7, 6, 7, 2, 3, 3, 7, 7, 4, 2, 1, 6, 0, 5, 0, 5, 4, 7, 1, 5, 3, 0, 4, 6, 7, 6, 3, 3, 6, 1, 2, 3, 6, 1, 2, 3, 1, 6, 7, 7, 4, 3, 6, 6, 4, 0, 2, 1, 6, 1, 0, 6, 4, 0, 6, 7, 5, 1, 7, 1, 2, 4, 6, 4, 7, 1, 4, 0, 5, 3, 1, 2, 3, 6, 5, 4, 6, 6, 7, 1, 1, 7, 7, 1, 3, 0, 0, 4, 4, 1, 5, 6, 7, 5, 3, 4, 1, 3, 6, 4, 7, 0, 2, 7, 6, 7, 0, 5, 6, 6, 2, 5, 0, 3, 2, 0, 7, 5, 4, 1, 5, 4, 0, 0, 4, 1, 4, 5, 0, 3, 7, 0, 5, 5, 2, 2, 0, 3, 3, 4, 4, 6, 0, 5, 4, 4, 6, 5, 6, 5, 7, 1, 4, 4, 4, 6, 2, 3, 4, 4, 7, 2, 2, 6, 7, 4, 7, 5, 2, 3, 7, 3, 1, 0, 4, 4, 3, 6, 4, 0, 6, 3, 3, 0, 2, 2, 4, 2, 1, 2, 5, 7, 4, 0, 5, 6, 4, 5, 0, 4, 7, 4, 6, 0, 0, 1, 3, 6, 6, 2, 2, 3, 5, 4, 5, 2, 3, 6, 3, 1, 1, 2, 6, 5, 7, 5, 6, 4, 0, 2, 6, 6, 7, 7, 7, 7, 1, 3, 7, 7, 1, 6, 7, 7, 6, 5, 4, 4, 4, 1, 3, 4, 0, 4, 7, 6, 4, 7, 3, 5, 6, 3, 0, 1, 0, 5, 0, 0, 4, 6, 7, 3, 6, 3, 2, 7, 4, 7, 6, 4, 6, 0, 1, 4, 3, 1, 3, 4, 2, 1, 5, 6, 7, 5, 4, 3, 2, 5, 7, 4, 6, 6, 7, 0, 1, 3, 3, 0, 0, 7, 4, 5, 6, 4, 2, 7, 7, 5, 2, 5, 5, 3, 0, 6, 0, 1, 4, 1, 6, 2, 3, 6, 6, 6, 3, 4, 7, 6, 7, 7, 2, 5, 6, 0, 5, 0, 7, 5, 0, 1, 4, 3, 3, 4, 5, 3, 2, 5, 3, 5, 1, 4, 4, 7, 3, 2, 6, 3, 1, 1, 7, 2, 3, 2, 1, 4, 4, 2, 7, 5, 2, 1, 0, 5, 2, 5, 6, 5, 1, 6, 5, 6, 2, 0, 2, 6, 2, 6, 0, 0, 5, 1, 5, 6, 3, 5, 0, 4, 2, 1, 5, 3, 6, 7, 0, 0, 7, 7, 4, 5, 2, 7, 0, 0, 2, 1, 7, 2, 2, 1, 3, 5, 0, 2, 0, 5, 5, 0, 5, 7, 1, 6, 6, 2, 5, 0, 1, 2, 1, 5, 1, 0, 1, 7, 7, 0, 4, 4, 1, 3, 1, 0, 7, 1, 4, 0, 3, 5, 5, 0, 4, 4, 7, 3, 2, 5, 2, 7, 4, 3, 4, 0, 6, 3, 1, 2, 0, 1, 1, 5, 2, 7, 6, 4, 1, 5, 6, 1, 3, 1, 3, 6, 4, 2, 4, 7, 7, 1, 3, 3, 4, 2, 2, 1, 2, 6, 7, 3, 5, 3, 0, 4, 2, 0, 5, 3, 4, 6, 3, 1, 6, 2, 3, 4, 4, 6, 2, 6, 7, 2, 1, 1, 2, 2, 3, 6, 1, 2, 0, 3, 0, 3, 0, 5, 7, 4, 1, 3, 7, 6, 3, 1, 4, 4, 5, 5, 3, 0, 4, 5, 1, 2, 2, 6, 3, 4, 1, 5, 5, 7, 5, 4, 0, 7, 3, 4, 0, 6, 7, 6, 1, 7, 3, 3, 1, 0, 5, 3, 6, 4, 4, 3, 4, 2, 3, 5, 3, 3, 6, 1, 7, 7, 5, 5, 4]\n",
      "New best validation accuracy:  0.9925\n",
      "Given hidden layer counts and learning rate:  256 256 0.01\n",
      "--------- Config 4 ---------\n",
      "h1 = 256\n",
      "h2 = 128\n",
      "{'hidden1': 256, 'hidden2': 128, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.0930, train_acc=0.8954 | val_loss=1.3312, val_acc=0.7075, val_mis=234\n",
      "Min SSE: 241.68366899474256\n",
      "Min Misclassifications: 234\n",
      "Epoch 10: train_loss=1.6064, train_acc=0.9207 | val_loss=1.0271, val_acc=0.7987, val_mis=161\n",
      "Min SSE: 189.10023749629383\n",
      "Min Misclassifications: 161\n",
      "Epoch 15: train_loss=1.3226, train_acc=0.9344 | val_loss=0.8593, val_acc=0.8187, val_mis=145\n",
      "Min SSE: 157.55408827726347\n",
      "Min Misclassifications: 145\n",
      "Epoch 20: train_loss=1.1213, train_acc=0.9442 | val_loss=0.7181, val_acc=0.8712, val_mis=103\n",
      "Min SSE: 133.5287719667372\n",
      "Min Misclassifications: 103\n",
      "Epoch 25: train_loss=0.9702, train_acc=0.9524 | val_loss=0.6194, val_acc=0.8862, val_mis=91\n",
      "Min SSE: 115.20888969533235\n",
      "Min Misclassifications: 91\n",
      "Epoch 30: train_loss=0.8526, train_acc=0.9610 | val_loss=0.5527, val_acc=0.8975, val_mis=82\n",
      "Min SSE: 101.36699082754735\n",
      "Min Misclassifications: 82\n",
      "Epoch 35: train_loss=0.7650, train_acc=0.9672 | val_loss=0.5246, val_acc=0.9038, val_mis=77\n",
      "Min SSE: 92.62892848860014\n",
      "Min Misclassifications: 77\n",
      "Epoch 40: train_loss=0.6953, train_acc=0.9711 | val_loss=0.4509, val_acc=0.9062, val_mis=75\n",
      "Min SSE: 83.63317589903343\n",
      "Min Misclassifications: 75\n",
      "Epoch 45: train_loss=0.6390, train_acc=0.9738 | val_loss=0.4157, val_acc=0.9175, val_mis=66\n",
      "Min SSE: 76.48301531254307\n",
      "Min Misclassifications: 66\n",
      "Epoch 50: train_loss=0.5909, train_acc=0.9761 | val_loss=0.3894, val_acc=0.9237, val_mis=61\n",
      "Min SSE: 70.79313615434975\n",
      "Min Misclassifications: 61\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 70.79313615434975\n",
      "Final Min Misclassifications 61\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[5, 7, 6, 7, 6, 7, 1, 5, 3, 1, 2, 0, 1, 3, 0, 6, 3, 4, 5, 4, 6, 0, 4, 1, 6, 1, 6, 6, 0, 2, 2, 3, 2, 2, 2, 7, 2, 6, 6, 5, 3, 5, 2, 7, 2, 3, 0, 5, 7, 4, 4, 5, 6, 7, 6, 0, 3, 0, 5, 2, 1, 0, 7, 5, 4, 5, 6, 5, 1, 4, 4, 7, 7, 2, 7, 1, 4, 0, 4, 2, 6, 2, 3, 6, 7, 4, 6, 4, 7, 6, 4, 2, 4, 0, 2, 6, 1, 4, 1, 3, 2, 0, 2, 0, 1, 4, 7, 6, 1, 5, 6, 7, 3, 6, 1, 4, 5, 0, 2, 0, 6, 6, 1, 2, 2, 1, 0, 4, 5, 7, 5, 4, 1, 0, 0, 2, 4, 6, 5, 3, 4, 1, 4, 3, 4, 4, 7, 0, 5, 7, 2, 2, 2, 3, 5, 1, 2, 3, 0, 2, 2, 6, 4, 7, 7, 0, 6, 3, 2, 5, 3, 2, 1, 2, 4, 4, 3, 7, 3, 0, 0, 5, 5, 4, 4, 1, 6, 1, 1, 7, 3, 5, 0, 6, 0, 7, 1, 6, 3, 2, 2, 7, 7, 2, 5, 5, 3, 1, 7, 2, 5, 1, 7, 0, 2, 5, 5, 5, 4, 5, 6, 5, 1, 0, 2, 4, 0, 3, 0, 2, 1, 0, 2, 6, 6, 4, 4, 2, 5, 7, 5, 7, 0, 4, 0, 4, 7, 7, 1, 3, 7, 1, 0, 7, 7, 3, 5, 0, 2, 7, 5, 5, 0, 7, 0, 7, 2, 7, 0, 5, 6, 4, 2, 3, 2, 2, 2, 1, 4, 0, 2, 2, 1, 6, 2, 6, 4, 7, 4, 0, 5, 2, 3, 6, 1, 5, 2, 1, 7, 4, 2, 7, 1, 3, 2, 4, 0, 3, 4, 4, 7, 7, 0, 1, 5, 4, 6, 6, 4, 7, 5, 7, 3, 5, 1, 0, 7, 2, 3, 7, 1, 1, 4, 1, 3, 7, 2, 2, 1, 6, 6, 1, 7, 6, 6, 4, 1, 2, 0, 4, 3, 3, 6, 4, 5, 6, 3, 1, 5, 3, 5, 4, 1, 1, 5, 0, 7, 3, 2, 5, 4, 5, 2, 4, 5, 0, 1, 3, 3, 5, 3, 5, 3, 0, 0, 1, 0, 6, 2, 0, 5, 5, 2, 3, 3, 2, 2, 6, 7, 2, 5, 2, 6, 2, 5, 5, 4, 2, 7, 4, 0, 3, 7, 6, 5, 7, 0, 3, 2, 0, 2, 7, 0, 2, 3, 7, 3, 6, 5, 0, 5, 1, 0, 6, 5, 5, 3, 4, 2, 7, 7, 3, 7, 3, 5, 1, 7, 7, 5, 5, 5, 0, 2, 6, 4, 4, 7, 5, 3, 3, 5, 7, 7, 6, 0, 7, 7, 1, 7, 1, 4, 0, 1, 5, 1, 7, 3, 3, 6, 4, 4, 7, 2, 1, 3, 2, 1, 6, 6, 1, 4, 6, 7, 3, 0, 5, 5, 0, 7, 4, 7, 6, 2, 0, 7, 7, 2, 4, 5, 5, 3, 7, 7, 2, 5, 1, 3, 2, 2, 6, 2, 5, 4, 3, 0, 1, 6, 0, 4, 1, 0, 6, 4, 7, 2, 5, 0, 0, 3, 0, 2, 3, 2, 0, 4, 0, 5, 6, 1, 5, 0, 6, 1, 7, 7, 4, 6, 6, 0, 7, 2, 1, 2, 0, 2, 7, 6, 3, 5, 0, 6, 7, 2, 1, 5, 1, 4, 3, 5, 0, 5, 3, 7, 6, 6, 2, 7, 7, 2, 4, 4, 1, 7, 4, 2, 2, 1, 4, 4, 2, 2, 6, 0, 4, 1, 1, 6, 6, 5, 7, 0, 5, 2, 2, 3, 0, 5, 7, 7, 1, 4, 3, 0, 1, 0, 7, 3, 0, 3, 5, 7, 4, 7, 0, 5, 7, 4, 5, 5, 5, 7, 7, 2, 1, 4, 3, 7, 7, 4, 2, 2, 0, 0, 7, 7, 5, 2, 0, 1, 4, 0, 5, 0, 5, 0, 6, 4, 3, 3, 2, 7, 3, 0, 3, 3, 5, 5, 5, 5, 1, 6, 7, 3, 7, 4, 2, 2, 4, 7, 4, 6, 6, 3, 0, 2, 0, 7, 4, 4, 2, 1, 5, 7, 6, 7, 5, 6, 5, 7, 5, 0, 6, 5, 2, 6, 1, 6, 3, 2, 3, 0, 3, 7, 7, 5, 3, 7, 6, 1, 4, 3, 6, 4, 2, 7, 3, 5, 6, 4, 0, 5, 2, 7, 1, 2, 5, 5, 3, 1, 7, 5, 4, 0, 1, 0, 0, 1, 4, 2, 1, 3, 7, 1, 3, 4, 7, 2, 0, 1, 5, 2, 0, 5, 7, 1, 6, 3, 0, 4, 0, 0, 0, 2, 1, 4, 3, 0, 7, 6, 2, 5, 5, 4, 4, 2, 0, 6, 3, 3, 0]\n",
      "New best training duration:  0:00:55\n",
      "Given hidden layer counts and learning rate:  256 128 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 5 ---------\n",
      "h1 = 256\n",
      "h2 = 128\n",
      "{'hidden1': 256, 'hidden2': 128, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.0794, train_acc=0.9463 | val_loss=0.6323, val_acc=0.8600, val_mis=112\n",
      "Min SSE: 118.82427573563452\n",
      "Min Misclassifications: 112\n",
      "Epoch 10: train_loss=0.6566, train_acc=0.9719 | val_loss=0.3992, val_acc=0.9100, val_mis=72\n",
      "Min SSE: 73.72457480904421\n",
      "Min Misclassifications: 72\n",
      "Epoch 15: train_loss=0.4811, train_acc=0.9808 | val_loss=0.2640, val_acc=0.9475, val_mis=42\n",
      "Min SSE: 50.93889096749545\n",
      "Min Misclassifications: 42\n",
      "Epoch 20: train_loss=0.3798, train_acc=0.9849 | val_loss=0.1913, val_acc=0.9663, val_mis=27\n",
      "Min SSE: 39.1224971785897\n",
      "Min Misclassifications: 27\n",
      "Epoch 25: train_loss=0.3134, train_acc=0.9883 | val_loss=0.1722, val_acc=0.9663, val_mis=27\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 30: train_loss=0.2740, train_acc=0.9892 | val_loss=0.1819, val_acc=0.9788, val_mis=17\n",
      "Min SSE: 28.0814737365713\n",
      "Min Misclassifications: 17\n",
      "Epoch 35: train_loss=0.2428, train_acc=0.9906 | val_loss=0.1346, val_acc=0.9838, val_mis=13\n",
      "Min SSE: 24.36453898901242\n",
      "Min Misclassifications: 13\n",
      "Epoch 40: train_loss=0.2251, train_acc=0.9914 | val_loss=0.1760, val_acc=0.9712, val_mis=23\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1934, train_acc=0.9931 | val_loss=0.1264, val_acc=0.9838, val_mis=13\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1808, train_acc=0.9932 | val_loss=0.1148, val_acc=0.9825, val_mis=14\n",
      "  → no improvement for 3/10 epochs\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 18.081336489200424\n",
      "Final Min Misclassifications 13\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[1, 3, 7, 7, 1, 4, 6, 3, 3, 2, 1, 1, 3, 1, 1, 1, 7, 5, 5, 5, 5, 3, 2, 7, 5, 3, 4, 4, 6, 5, 1, 5, 1, 1, 3, 4, 3, 5, 0, 3, 0, 6, 0, 1, 4, 1, 3, 3, 0, 3, 5, 2, 5, 1, 1, 6, 2, 6, 3, 1, 1, 0, 2, 1, 2, 7, 5, 5, 7, 5, 1, 0, 4, 2, 5, 0, 6, 3, 2, 0, 4, 0, 1, 6, 2, 5, 6, 4, 3, 0, 0, 7, 3, 4, 4, 4, 4, 3, 3, 0, 6, 3, 1, 7, 3, 7, 1, 5, 4, 2, 0, 2, 0, 1, 6, 2, 2, 1, 4, 1, 2, 5, 5, 6, 4, 2, 2, 5, 1, 0, 3, 5, 0, 0, 1, 7, 3, 6, 2, 2, 3, 6, 0, 6, 3, 7, 7, 6, 4, 2, 6, 0, 0, 7, 4, 4, 3, 7, 7, 0, 5, 4, 6, 1, 1, 7, 3, 6, 5, 0, 0, 4, 2, 3, 3, 3, 1, 2, 5, 6, 2, 6, 6, 4, 5, 1, 3, 2, 6, 6, 0, 5, 6, 7, 5, 7, 5, 3, 4, 6, 2, 7, 3, 2, 7, 2, 4, 7, 0, 3, 4, 1, 4, 3, 4, 3, 5, 7, 7, 3, 4, 0, 1, 3, 0, 4, 2, 1, 1, 1, 7, 0, 6, 1, 4, 3, 3, 2, 2, 5, 3, 3, 7, 4, 6, 2, 7, 2, 3, 7, 2, 2, 1, 1, 0, 1, 4, 7, 3, 0, 4, 0, 1, 2, 6, 5, 1, 5, 4, 1, 6, 0, 1, 1, 4, 5, 4, 0, 5, 5, 4, 0, 6, 7, 6, 1, 1, 5, 1, 2, 6, 2, 0, 2, 1, 7, 1, 2, 1, 0, 0, 4, 7, 5, 5, 2, 6, 2, 4, 3, 1, 7, 5, 2, 1, 7, 6, 3, 0, 0, 1, 3, 7, 3, 3, 6, 2, 7, 0, 1, 1, 7, 5, 5, 2, 4, 3, 1, 4, 4, 2, 1, 2, 4, 7, 5, 7, 2, 1, 1, 7, 3, 3, 4, 5, 1, 3, 5, 7, 0, 1, 3, 1, 1, 4, 4, 1, 6, 7, 3, 1, 0, 6, 5, 0, 0, 1, 0, 3, 3, 2, 1, 4, 3, 7, 3, 7, 6, 2, 0, 5, 3, 3, 4, 5, 2, 1, 3, 6, 4, 3, 6, 0, 6, 4, 5, 1, 1, 6, 5, 7, 6, 1, 3, 7, 1, 1, 5, 2, 2, 4, 2, 6, 0, 7, 0, 0, 7, 4, 4, 3, 6, 1, 4, 0, 2, 4, 7, 5, 0, 6, 5, 7, 6, 6, 3, 5, 7, 5, 0, 0, 6, 6, 3, 5, 3, 3, 5, 4, 1, 5, 5, 5, 4, 0, 6, 7, 7, 5, 0, 7, 3, 5, 4, 5, 7, 6, 5, 6, 4, 3, 3, 6, 2, 4, 4, 7, 6, 0, 6, 0, 1, 3, 2, 2, 5, 7, 3, 1, 4, 3, 3, 2, 5, 0, 3, 1, 2, 5, 0, 6, 0, 1, 1, 1, 6, 3, 5, 7, 6, 1, 2, 6, 7, 6, 6, 1, 6, 6, 6, 0, 0, 1, 0, 2, 2, 6, 4, 1, 7, 0, 4, 1, 4, 2, 6, 3, 5, 2, 7, 5, 5, 6, 1, 5, 1, 2, 5, 1, 1, 6, 7, 2, 5, 1, 7, 5, 6, 6, 1, 1, 1, 3, 7, 7, 2, 4, 4, 4, 2, 6, 0, 1, 7, 7, 3, 0, 3, 3, 7, 7, 0, 7, 4, 1, 5, 3, 6, 7, 1, 0, 0, 5, 4, 4, 7, 4, 6, 1, 7, 5, 5, 2, 0, 2, 2, 2, 4, 7, 3, 7, 3, 1, 3, 5, 3, 6, 6, 4, 0, 2, 6, 1, 1, 5, 7, 2, 1, 6, 4, 5, 4, 7, 4, 0, 6, 7, 7, 2, 3, 2, 7, 0, 0, 5, 0, 5, 4, 7, 7, 6, 7, 5, 4, 1, 6, 1, 2, 2, 4, 0, 0, 3, 1, 0, 1, 7, 0, 4, 6, 2, 1, 3, 7, 5, 2, 6, 7, 1, 3, 2, 2, 3, 0, 5, 3, 1, 2, 7, 1, 3, 6, 0, 5, 6, 0, 3, 7, 3, 6, 3, 3, 0, 7, 2, 6, 4, 6, 1, 5, 5, 4, 2, 2, 3, 3, 0, 5, 5, 5, 3, 7, 6, 4, 0, 3, 4, 0, 7, 3, 5, 5, 3, 0, 7, 0, 4, 2, 5, 6, 7, 3, 6, 6, 6, 0, 3, 3, 2, 6, 5, 3, 2, 5, 6, 5, 0, 3, 6, 1, 1, 7, 0, 0, 0, 0, 4, 5, 5, 5, 3, 6, 4, 4, 5, 7, 3, 2, 0, 5, 7, 3, 2, 5, 7, 4, 0, 7, 6, 6]\n",
      "--------- Config 6 ---------\n",
      "h1 = 256\n",
      "h2 = 128\n",
      "{'hidden1': 256, 'hidden2': 128, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.7110, train_acc=0.9695 | val_loss=0.3248, val_acc=0.9437, val_mis=45\n",
      "Min SSE: 61.29084370964958\n",
      "Min Misclassifications: 45\n",
      "Epoch 10: train_loss=0.4309, train_acc=0.9820 | val_loss=0.2247, val_acc=0.9775, val_mis=18\n",
      "Min SSE: 39.628130843906746\n",
      "Min Misclassifications: 18\n",
      "Epoch 15: train_loss=0.3127, train_acc=0.9874 | val_loss=0.1311, val_acc=0.9750, val_mis=20\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 20: train_loss=0.2547, train_acc=0.9900 | val_loss=0.1117, val_acc=0.9838, val_mis=13\n",
      "Min SSE: 22.24509356163549\n",
      "Min Misclassifications: 13\n",
      "Epoch 25: train_loss=0.2262, train_acc=0.9905 | val_loss=0.0968, val_acc=0.9825, val_mis=14\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 30: train_loss=0.2060, train_acc=0.9915 | val_loss=0.0844, val_acc=0.9750, val_mis=20\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 35: train_loss=0.1735, train_acc=0.9930 | val_loss=0.0766, val_acc=0.9825, val_mis=14\n",
      "  → no improvement for 3/10 epochs\n",
      "Epoch 40: train_loss=0.1569, train_acc=0.9938 | val_loss=0.1746, val_acc=0.9812, val_mis=15\n",
      "  → no improvement for 4/10 epochs\n",
      "Epoch 45: train_loss=0.1446, train_acc=0.9944 | val_loss=0.0901, val_acc=0.9850, val_mis=12\n",
      "Min SSE: 15.214567478466748\n",
      "Min Misclassifications: 12\n",
      "Epoch 50: train_loss=0.1417, train_acc=0.9942 | val_loss=0.0591, val_acc=0.9850, val_mis=12\n",
      "  → no improvement for 1/10 epochs\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 13.558811566322056\n",
      "Final Min Misclassifications 12\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[6, 1, 1, 5, 1, 6, 0, 1, 2, 4, 7, 2, 5, 3, 7, 2, 6, 4, 0, 2, 3, 0, 0, 7, 7, 6, 0, 7, 1, 3, 5, 4, 2, 5, 2, 4, 3, 6, 5, 0, 6, 1, 0, 5, 7, 4, 3, 1, 7, 3, 4, 3, 0, 7, 7, 2, 0, 4, 2, 7, 7, 2, 0, 1, 0, 1, 5, 0, 0, 5, 3, 5, 4, 4, 7, 3, 2, 0, 1, 7, 0, 3, 0, 0, 2, 5, 6, 6, 4, 0, 4, 6, 1, 3, 0, 7, 6, 7, 2, 7, 3, 1, 2, 7, 4, 0, 2, 5, 3, 1, 6, 7, 6, 7, 0, 4, 0, 5, 6, 7, 3, 1, 5, 7, 5, 0, 0, 2, 1, 3, 4, 7, 0, 7, 6, 3, 5, 4, 0, 7, 1, 5, 5, 2, 5, 0, 4, 6, 6, 7, 0, 4, 6, 0, 7, 3, 5, 4, 5, 0, 2, 2, 1, 0, 0, 5, 3, 5, 2, 5, 4, 3, 6, 3, 0, 1, 2, 4, 6, 6, 6, 2, 0, 1, 3, 0, 6, 0, 6, 7, 6, 5, 4, 4, 4, 4, 0, 4, 5, 1, 2, 4, 7, 1, 3, 7, 7, 3, 5, 2, 2, 4, 5, 5, 2, 4, 2, 5, 5, 4, 7, 7, 4, 5, 3, 7, 5, 2, 2, 7, 5, 3, 2, 3, 0, 1, 7, 5, 7, 4, 1, 5, 7, 5, 1, 4, 4, 4, 6, 7, 1, 5, 4, 3, 0, 2, 5, 2, 2, 7, 7, 4, 4, 6, 4, 5, 0, 3, 3, 3, 4, 1, 1, 5, 1, 1, 2, 5, 4, 5, 3, 1, 5, 2, 7, 7, 0, 2, 5, 7, 5, 5, 5, 7, 0, 5, 5, 2, 2, 2, 1, 2, 3, 4, 4, 0, 4, 0, 1, 0, 0, 5, 7, 0, 5, 6, 5, 5, 7, 1, 1, 2, 2, 0, 4, 6, 6, 2, 6, 1, 3, 6, 2, 3, 2, 0, 4, 6, 7, 6, 2, 2, 4, 3, 6, 4, 0, 0, 7, 6, 5, 5, 7, 1, 4, 0, 5, 1, 4, 5, 0, 6, 0, 6, 4, 4, 2, 5, 4, 1, 3, 0, 2, 4, 1, 7, 2, 3, 0, 3, 2, 1, 1, 0, 3, 3, 4, 4, 0, 2, 5, 3, 1, 4, 5, 3, 3, 1, 0, 0, 2, 6, 1, 1, 5, 4, 7, 0, 6, 3, 2, 2, 7, 4, 4, 4, 0, 3, 6, 2, 5, 6, 1, 4, 6, 4, 1, 5, 5, 2, 5, 5, 4, 4, 2, 4, 6, 2, 4, 1, 3, 3, 3, 1, 0, 6, 3, 0, 4, 5, 3, 3, 7, 1, 7, 7, 1, 6, 4, 3, 0, 1, 5, 4, 3, 1, 1, 4, 0, 0, 2, 0, 7, 2, 7, 6, 1, 2, 5, 2, 1, 7, 7, 4, 1, 3, 4, 4, 3, 1, 3, 4, 7, 1, 7, 3, 1, 6, 0, 1, 2, 6, 6, 5, 1, 0, 1, 5, 6, 4, 1, 4, 7, 1, 2, 0, 3, 1, 6, 2, 5, 1, 3, 7, 1, 0, 7, 7, 6, 1, 2, 2, 3, 4, 4, 3, 5, 0, 1, 2, 3, 4, 3, 5, 1, 5, 4, 5, 7, 5, 0, 5, 6, 7, 5, 2, 0, 4, 5, 4, 7, 4, 7, 0, 7, 7, 7, 2, 6, 0, 2, 3, 3, 0, 7, 5, 5, 5, 0, 6, 6, 3, 1, 2, 1, 5, 4, 4, 2, 6, 0, 4, 4, 0, 1, 3, 2, 6, 7, 2, 3, 6, 1, 4, 4, 2, 0, 2, 3, 2, 4, 5, 3, 4, 6, 6, 3, 2, 1, 2, 2, 1, 3, 4, 4, 5, 3, 0, 4, 0, 2, 4, 7, 3, 4, 0, 6, 1, 3, 4, 5, 0, 3, 4, 4, 6, 7, 0, 0, 4, 2, 7, 4, 3, 1, 1, 2, 2, 4, 2, 6, 5, 4, 0, 7, 5, 1, 2, 0, 4, 3, 5, 7, 0, 2, 3, 3, 3, 1, 6, 4, 4, 0, 7, 5, 5, 1, 2, 0, 7, 7, 1, 3, 4, 4, 5, 7, 4, 7, 0, 7, 0, 7, 6, 1, 0, 7, 7, 7, 6, 2, 5, 1, 5, 1, 4, 5, 4, 1, 4, 4, 7, 2, 2, 4, 5, 1, 7, 4, 4, 2, 4, 1, 3, 2, 2, 2, 1, 3, 1, 7, 4, 7, 4, 7, 7, 3, 6, 4, 1, 6, 5, 0, 1, 5, 6, 3, 0, 3, 7, 1, 1, 2, 4, 2, 4, 0, 3, 2, 5, 2, 4, 0, 4, 2, 5, 0, 4, 2, 1, 3, 0, 1, 2, 4, 1, 3, 6, 0, 3, 0, 3, 5, 6, 1, 7, 2, 4, 6, 3]\n",
      "--------- Config 7 ---------\n",
      "h1 = 256\n",
      "h2 = 64\n",
      "{'hidden1': 256, 'hidden2': 64, 'learning_rate': 0.001}\n",
      "---------            ---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5: train_loss=2.1198, train_acc=0.8947 | val_loss=1.3236, val_acc=0.6450, val_mis=284\n",
      "Min SSE: 243.9249088229009\n",
      "Min Misclassifications: 284\n",
      "Epoch 10: train_loss=1.6486, train_acc=0.9179 | val_loss=1.0140, val_acc=0.7925, val_mis=166\n",
      "Min SSE: 189.52429309904335\n",
      "Min Misclassifications: 166\n",
      "Epoch 15: train_loss=1.3641, train_acc=0.9348 | val_loss=0.8329, val_acc=0.8337, val_mis=133\n",
      "Min SSE: 157.27089374382825\n",
      "Min Misclassifications: 133\n",
      "Epoch 20: train_loss=1.1666, train_acc=0.9430 | val_loss=0.7005, val_acc=0.8775, val_mis=98\n",
      "Min SSE: 134.27900957587582\n",
      "Min Misclassifications: 98\n",
      "Epoch 25: train_loss=1.0109, train_acc=0.9498 | val_loss=0.5831, val_acc=0.8888, val_mis=89\n",
      "Min SSE: 114.4305231764552\n",
      "Min Misclassifications: 89\n",
      "Epoch 30: train_loss=0.8851, train_acc=0.9584 | val_loss=0.5109, val_acc=0.9012, val_mis=79\n",
      "Min SSE: 99.13935857455158\n",
      "Min Misclassifications: 79\n",
      "Epoch 35: train_loss=0.7861, train_acc=0.9653 | val_loss=0.4418, val_acc=0.9012, val_mis=79\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 40: train_loss=0.7084, train_acc=0.9703 | val_loss=0.4009, val_acc=0.9263, val_mis=59\n",
      "Min SSE: 78.36370691959874\n",
      "Min Misclassifications: 59\n",
      "Epoch 45: train_loss=0.6474, train_acc=0.9734 | val_loss=0.3729, val_acc=0.9250, val_mis=60\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.5963, train_acc=0.9760 | val_loss=0.3380, val_acc=0.9363, val_mis=51\n",
      "Min SSE: 66.23369565375143\n",
      "Min Misclassifications: 51\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 66.23369565375143\n",
      "Final Min Misclassifications 51\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[6, 3, 1, 7, 2, 2, 5, 5, 4, 4, 5, 3, 2, 4, 7, 1, 7, 6, 5, 4, 3, 1, 3, 7, 4, 7, 5, 6, 2, 6, 0, 3, 3, 7, 6, 3, 2, 1, 2, 0, 0, 0, 3, 0, 4, 5, 2, 0, 5, 5, 7, 7, 0, 4, 3, 0, 2, 1, 2, 6, 1, 3, 6, 1, 1, 5, 7, 3, 7, 4, 6, 2, 3, 0, 1, 4, 5, 5, 1, 3, 4, 6, 5, 5, 0, 0, 6, 7, 3, 7, 2, 0, 2, 7, 7, 4, 1, 2, 6, 1, 4, 0, 0, 4, 3, 6, 4, 6, 7, 5, 3, 0, 1, 3, 0, 4, 0, 5, 1, 3, 6, 3, 7, 7, 4, 1, 1, 4, 0, 6, 0, 1, 5, 4, 0, 5, 3, 3, 7, 6, 7, 6, 5, 2, 5, 7, 3, 6, 1, 7, 4, 5, 3, 4, 1, 5, 1, 1, 3, 2, 5, 6, 2, 7, 1, 2, 7, 5, 2, 5, 3, 0, 1, 2, 3, 5, 4, 5, 7, 3, 5, 6, 2, 0, 6, 6, 5, 7, 7, 3, 4, 3, 4, 6, 6, 3, 7, 7, 7, 4, 1, 6, 0, 5, 3, 5, 1, 4, 0, 0, 7, 7, 7, 3, 5, 5, 5, 1, 5, 3, 0, 0, 3, 0, 0, 1, 3, 4, 3, 2, 7, 2, 5, 4, 3, 5, 6, 2, 6, 3, 4, 6, 3, 3, 7, 5, 7, 4, 0, 2, 5, 0, 0, 5, 1, 5, 6, 7, 7, 7, 3, 4, 6, 5, 0, 4, 2, 3, 3, 7, 1, 5, 6, 1, 5, 4, 0, 5, 5, 6, 5, 4, 1, 4, 7, 4, 3, 6, 0, 2, 1, 2, 3, 4, 4, 4, 2, 1, 5, 0, 1, 7, 1, 2, 4, 5, 6, 3, 2, 4, 6, 3, 7, 5, 3, 5, 3, 4, 3, 5, 3, 1, 7, 6, 5, 3, 2, 7, 7, 5, 0, 7, 5, 2, 7, 2, 3, 0, 3, 6, 2, 6, 7, 1, 4, 7, 3, 1, 7, 7, 6, 3, 1, 6, 0, 3, 3, 1, 3, 3, 2, 6, 7, 1, 6, 3, 3, 7, 0, 2, 0, 1, 1, 5, 0, 4, 4, 7, 4, 1, 5, 0, 7, 0, 6, 6, 2, 0, 2, 1, 2, 7, 1, 1, 3, 7, 5, 3, 2, 7, 1, 5, 1, 7, 5, 5, 5, 7, 2, 3, 3, 1, 0, 2, 6, 2, 0, 6, 2, 3, 0, 0, 7, 3, 5, 7, 0, 1, 5, 4, 5, 2, 7, 3, 6, 1, 6, 6, 6, 3, 6, 0, 0, 6, 5, 7, 1, 5, 3, 6, 1, 7, 5, 0, 5, 0, 1, 0, 0, 2, 1, 1, 2, 3, 2, 0, 3, 2, 7, 1, 6, 2, 0, 1, 7, 2, 2, 0, 3, 6, 3, 3, 1, 4, 0, 0, 0, 0, 0, 3, 7, 6, 5, 5, 1, 6, 0, 7, 4, 5, 2, 7, 3, 6, 5, 0, 5, 2, 6, 4, 7, 5, 1, 2, 0, 5, 7, 7, 2, 0, 5, 0, 6, 3, 7, 5, 0, 0, 6, 3, 6, 3, 2, 2, 3, 1, 6, 7, 3, 2, 0, 1, 3, 5, 7, 6, 7, 7, 1, 3, 5, 0, 3, 4, 1, 4, 1, 6, 2, 4, 1, 6, 1, 5, 3, 4, 0, 2, 4, 7, 0, 5, 3, 5, 3, 4, 1, 7, 3, 3, 4, 3, 6, 0, 0, 1, 6, 3, 1, 5, 2, 7, 1, 3, 5, 5, 2, 3, 4, 5, 5, 1, 1, 3, 5, 1, 1, 5, 3, 6, 0, 1, 7, 4, 0, 6, 7, 7, 4, 0, 2, 1, 1, 6, 7, 5, 0, 4, 7, 4, 0, 0, 4, 2, 7, 7, 6, 2, 0, 3, 4, 7, 7, 7, 2, 3, 4, 5, 2, 2, 5, 0, 1, 6, 6, 6, 2, 6, 3, 0, 1, 2, 7, 7, 5, 0, 5, 0, 6, 3, 0, 5, 4, 4, 3, 1, 2, 5, 0, 6, 3, 1, 7, 2, 6, 1, 7, 6, 3, 7, 4, 2, 0, 0, 0, 3, 1, 4, 5, 6, 3, 6, 7, 0, 5, 0, 1, 4, 2, 5, 6, 2, 0, 3, 1, 1, 4, 7, 6, 0, 1, 3, 3, 3, 5, 3, 4, 6, 1, 2, 4, 2, 0, 3, 7, 0, 2, 7, 7, 7, 4, 6, 5, 5, 6, 3, 4, 5, 3, 1, 1, 6, 7, 3, 1, 2, 5, 1, 4, 6, 0, 0, 3, 0, 0, 2, 0, 6, 4, 3, 4, 5, 6, 1, 7, 6, 2, 4, 2, 0, 7, 3, 3, 3, 3, 7, 5, 5, 2, 7, 5, 4, 5, 7, 7, 0, 7, 3, 6, 4]\n",
      "New best training duration:  0:00:47\n",
      "Given hidden layer counts and learning rate:  256 64 0.001\n",
      "--------- Config 8 ---------\n",
      "h1 = 256\n",
      "h2 = 64\n",
      "{'hidden1': 256, 'hidden2': 64, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.0666, train_acc=0.9484 | val_loss=0.5793, val_acc=0.8762, val_mis=99\n",
      "Min SSE: 109.85168164575336\n",
      "Min Misclassifications: 99\n",
      "Epoch 10: train_loss=0.6470, train_acc=0.9731 | val_loss=0.3653, val_acc=0.9225, val_mis=62\n",
      "Min SSE: 66.77787150252342\n",
      "Min Misclassifications: 62\n",
      "Epoch 15: train_loss=0.4770, train_acc=0.9812 | val_loss=0.2788, val_acc=0.9500, val_mis=40\n",
      "Min SSE: 47.93533012956391\n",
      "Min Misclassifications: 40\n",
      "Epoch 20: train_loss=0.3784, train_acc=0.9847 | val_loss=0.2223, val_acc=0.9663, val_mis=27\n",
      "Min SSE: 36.843122231883214\n",
      "Min Misclassifications: 27\n",
      "Epoch 25: train_loss=0.3123, train_acc=0.9877 | val_loss=0.1709, val_acc=0.9750, val_mis=20\n",
      "Min SSE: 29.64289931918966\n",
      "Min Misclassifications: 20\n",
      "Epoch 30: train_loss=0.2696, train_acc=0.9898 | val_loss=0.1208, val_acc=0.9788, val_mis=17\n",
      "Min SSE: 23.58062567095572\n",
      "Min Misclassifications: 17\n",
      "Epoch 35: train_loss=0.2371, train_acc=0.9908 | val_loss=0.1179, val_acc=0.9862, val_mis=11\n",
      "Min SSE: 20.734441987635964\n",
      "Min Misclassifications: 11\n",
      "Epoch 40: train_loss=0.2150, train_acc=0.9916 | val_loss=0.1535, val_acc=0.9663, val_mis=27\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1955, train_acc=0.9924 | val_loss=0.0770, val_acc=0.9900, val_mis=8\n",
      "Min SSE: 15.380890418340448\n",
      "Min Misclassifications: 8\n",
      "Epoch 50: train_loss=0.1792, train_acc=0.9933 | val_loss=0.0845, val_acc=0.9888, val_mis=9\n",
      "  → no improvement for 1/10 epochs\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 15.380890418340448\n",
      "Final Min Misclassifications 8\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[7, 5, 0, 5, 2, 1, 4, 0, 6, 6, 5, 1, 2, 6, 0, 3, 2, 1, 2, 4, 2, 1, 5, 0, 4, 6, 2, 0, 2, 0, 5, 3, 7, 1, 0, 4, 7, 7, 3, 2, 4, 7, 4, 2, 3, 7, 3, 7, 3, 2, 0, 2, 4, 1, 2, 1, 5, 4, 7, 1, 0, 3, 3, 7, 4, 7, 3, 4, 1, 3, 4, 4, 1, 6, 3, 3, 5, 4, 5, 3, 4, 6, 7, 5, 4, 1, 7, 0, 2, 3, 1, 0, 4, 6, 4, 3, 0, 1, 5, 6, 7, 2, 7, 1, 4, 4, 4, 5, 1, 4, 1, 6, 7, 1, 7, 6, 3, 6, 7, 3, 2, 4, 3, 3, 4, 2, 6, 2, 2, 1, 4, 6, 7, 5, 5, 2, 2, 6, 3, 7, 4, 4, 2, 1, 0, 5, 0, 3, 3, 4, 0, 1, 0, 5, 7, 4, 7, 1, 0, 2, 0, 6, 6, 1, 6, 3, 4, 1, 1, 5, 1, 1, 5, 1, 3, 7, 4, 5, 5, 4, 2, 3, 7, 7, 5, 4, 7, 3, 0, 1, 5, 0, 6, 2, 2, 2, 1, 6, 1, 1, 2, 0, 4, 3, 1, 1, 1, 4, 0, 7, 5, 3, 4, 1, 4, 1, 6, 4, 3, 3, 3, 2, 1, 0, 1, 7, 5, 4, 3, 1, 1, 0, 6, 6, 5, 6, 5, 5, 2, 0, 7, 5, 2, 4, 0, 5, 1, 5, 6, 6, 3, 2, 3, 6, 2, 7, 5, 4, 3, 5, 0, 5, 2, 0, 0, 0, 6, 7, 7, 6, 6, 7, 2, 7, 2, 3, 3, 1, 3, 7, 4, 4, 4, 7, 5, 2, 1, 5, 7, 5, 3, 4, 6, 2, 0, 1, 6, 2, 1, 0, 4, 6, 2, 0, 1, 4, 1, 1, 3, 1, 6, 2, 3, 5, 3, 4, 2, 6, 0, 1, 6, 7, 0, 6, 5, 3, 6, 3, 3, 3, 6, 6, 0, 5, 0, 4, 1, 3, 3, 3, 6, 2, 6, 3, 5, 1, 3, 4, 1, 0, 2, 2, 0, 7, 2, 6, 6, 4, 7, 6, 2, 6, 1, 6, 2, 1, 2, 1, 3, 4, 3, 4, 6, 7, 7, 1, 1, 3, 4, 3, 7, 6, 7, 6, 2, 5, 6, 1, 6, 5, 5, 0, 5, 2, 3, 1, 2, 5, 3, 5, 1, 4, 5, 5, 0, 1, 3, 6, 0, 6, 4, 0, 6, 1, 1, 1, 0, 2, 1, 5, 2, 0, 4, 0, 0, 0, 1, 1, 5, 1, 0, 2, 6, 2, 5, 4, 6, 4, 6, 6, 2, 5, 7, 0, 0, 5, 5, 4, 6, 5, 6, 3, 0, 7, 3, 4, 3, 3, 1, 2, 7, 7, 6, 5, 7, 1, 1, 3, 2, 7, 5, 7, 4, 0, 2, 7, 0, 0, 6, 5, 5, 6, 5, 1, 2, 6, 7, 5, 3, 7, 6, 2, 5, 7, 1, 3, 6, 5, 5, 7, 3, 0, 2, 0, 1, 2, 1, 0, 1, 1, 5, 0, 5, 2, 2, 5, 7, 7, 0, 5, 1, 1, 0, 3, 6, 6, 5, 6, 1, 0, 1, 4, 7, 5, 5, 7, 3, 7, 1, 2, 7, 7, 2, 1, 7, 2, 5, 5, 2, 1, 4, 6, 1, 4, 0, 0, 0, 6, 6, 0, 3, 2, 7, 1, 4, 7, 5, 1, 7, 2, 7, 2, 1, 3, 2, 5, 1, 7, 1, 2, 7, 6, 6, 5, 7, 6, 7, 3, 7, 7, 6, 6, 2, 5, 1, 2, 5, 5, 7, 6, 1, 0, 2, 7, 7, 6, 6, 5, 5, 0, 1, 1, 3, 2, 6, 0, 7, 5, 4, 3, 0, 7, 2, 4, 5, 5, 6, 7, 7, 1, 3, 3, 3, 2, 3, 3, 2, 6, 0, 4, 4, 3, 1, 5, 2, 3, 2, 0, 0, 2, 6, 0, 2, 2, 0, 7, 2, 5, 7, 2, 3, 2, 5, 4, 6, 2, 7, 2, 5, 0, 1, 5, 3, 7, 2, 6, 5, 2, 5, 7, 7, 7, 0, 6, 2, 3, 2, 5, 6, 1, 2, 3, 6, 6, 6, 7, 4, 1, 3, 7, 6, 3, 4, 2, 3, 6, 6, 1, 3, 0, 5, 5, 5, 6, 3, 6, 4, 6, 0, 2, 1, 1, 0, 1, 0, 0, 6, 5, 0, 5, 1, 4, 4, 4, 3, 0, 2, 7, 3, 2, 1, 4, 5, 1, 4, 5, 5, 1, 4, 1, 7, 7, 6, 6, 1, 6, 6, 4, 5, 1, 1, 1, 7, 1, 1, 1, 2, 5, 7, 4, 5, 0, 3, 3, 4, 6, 4, 2, 2, 6, 3, 1, 2, 5, 1, 5, 0, 7, 1, 6, 4, 1, 0, 4, 0, 0, 7, 7, 3, 6]\n",
      "New best training duration:  0:00:46\n",
      "Given hidden layer counts and learning rate:  256 64 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 9 ---------\n",
      "h1 = 256\n",
      "h2 = 64\n",
      "{'hidden1': 256, 'hidden2': 64, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.7190, train_acc=0.9687 | val_loss=0.3652, val_acc=0.9525, val_mis=38\n",
      "Min SSE: 61.16860329132834\n",
      "Min Misclassifications: 38\n",
      "Epoch 10: train_loss=0.4184, train_acc=0.9830 | val_loss=0.1954, val_acc=0.9637, val_mis=29\n",
      "Min SSE: 35.91203972405043\n",
      "Min Misclassifications: 29\n",
      "Epoch 15: train_loss=0.3039, train_acc=0.9878 | val_loss=0.1184, val_acc=0.9600, val_mis=32\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 20: train_loss=0.2626, train_acc=0.9891 | val_loss=0.0740, val_acc=0.9875, val_mis=10\n",
      "Min SSE: 16.341516461403636\n",
      "Min Misclassifications: 10\n",
      "Epoch 25: train_loss=0.2069, train_acc=0.9919 | val_loss=0.0690, val_acc=0.9875, val_mis=10\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 30: train_loss=0.1935, train_acc=0.9921 | val_loss=0.2634, val_acc=0.9413, val_mis=47\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 35: train_loss=0.1617, train_acc=0.9938 | val_loss=0.0539, val_acc=0.9925, val_mis=6\n",
      "Min SSE: 10.014786239123804\n",
      "Min Misclassifications: 6\n",
      "Epoch 40: train_loss=0.1516, train_acc=0.9940 | val_loss=0.0336, val_acc=0.9912, val_mis=7\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1308, train_acc=0.9949 | val_loss=0.0556, val_acc=0.9888, val_mis=9\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1329, train_acc=0.9947 | val_loss=0.0459, val_acc=0.9938, val_mis=5\n",
      "Min SSE: 7.864794579016\n",
      "Min Misclassifications: 5\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 7.864794579016\n",
      "Final Min Misclassifications 5\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[0, 4, 6, 0, 7, 6, 3, 7, 2, 0, 7, 2, 4, 1, 2, 6, 6, 6, 3, 7, 4, 5, 3, 1, 2, 0, 7, 0, 6, 4, 4, 1, 0, 2, 1, 6, 6, 0, 7, 4, 6, 2, 4, 5, 0, 6, 2, 1, 5, 3, 7, 3, 2, 4, 0, 6, 1, 4, 2, 5, 6, 6, 1, 2, 1, 1, 5, 3, 6, 6, 5, 1, 4, 2, 3, 6, 2, 2, 4, 0, 7, 6, 5, 4, 2, 5, 3, 4, 1, 3, 1, 4, 5, 2, 0, 6, 0, 6, 7, 4, 1, 0, 3, 1, 0, 4, 2, 7, 7, 2, 3, 4, 6, 7, 4, 4, 6, 5, 1, 6, 4, 2, 1, 5, 3, 6, 7, 5, 3, 4, 7, 1, 3, 1, 6, 4, 6, 1, 2, 5, 1, 5, 3, 0, 5, 3, 1, 0, 3, 2, 0, 0, 1, 1, 0, 1, 3, 4, 4, 0, 0, 1, 4, 6, 6, 3, 1, 3, 2, 4, 4, 5, 4, 6, 2, 2, 1, 2, 2, 1, 7, 6, 7, 3, 2, 4, 3, 7, 0, 0, 7, 2, 6, 0, 0, 4, 5, 5, 0, 2, 1, 2, 2, 5, 7, 0, 3, 6, 7, 1, 4, 5, 5, 3, 7, 3, 1, 5, 1, 1, 4, 0, 0, 3, 1, 3, 4, 4, 7, 0, 6, 3, 7, 4, 5, 6, 2, 6, 5, 4, 2, 4, 7, 3, 5, 6, 6, 2, 2, 4, 4, 3, 3, 1, 1, 6, 0, 5, 4, 2, 1, 5, 4, 4, 2, 0, 2, 3, 3, 0, 4, 6, 2, 6, 0, 3, 2, 5, 1, 0, 5, 7, 1, 5, 7, 7, 4, 5, 4, 0, 4, 6, 6, 0, 5, 5, 3, 7, 6, 3, 6, 6, 5, 7, 5, 0, 0, 0, 1, 0, 0, 7, 5, 0, 7, 5, 1, 4, 5, 6, 2, 5, 3, 0, 2, 4, 1, 5, 1, 7, 3, 1, 0, 4, 2, 6, 2, 0, 5, 2, 3, 6, 5, 5, 4, 1, 5, 3, 3, 0, 0, 5, 1, 0, 0, 0, 2, 5, 2, 4, 3, 4, 1, 2, 6, 1, 3, 2, 2, 7, 7, 6, 4, 6, 7, 7, 4, 6, 6, 4, 7, 5, 4, 4, 6, 0, 6, 7, 1, 0, 0, 1, 5, 3, 1, 5, 1, 7, 6, 3, 1, 2, 0, 5, 1, 6, 1, 1, 1, 2, 3, 7, 1, 2, 7, 5, 1, 7, 7, 0, 7, 2, 2, 5, 1, 2, 5, 2, 5, 1, 7, 2, 3, 1, 0, 3, 0, 2, 2, 1, 0, 6, 4, 4, 4, 4, 1, 0, 5, 2, 1, 6, 0, 7, 2, 5, 6, 4, 5, 2, 7, 4, 7, 2, 1, 2, 3, 2, 2, 5, 7, 6, 0, 1, 3, 4, 4, 7, 2, 0, 1, 5, 3, 5, 2, 3, 6, 4, 1, 4, 3, 3, 6, 2, 3, 3, 2, 6, 6, 1, 1, 2, 5, 2, 3, 4, 5, 0, 5, 6, 1, 3, 7, 2, 4, 6, 4, 3, 2, 5, 3, 7, 6, 1, 4, 7, 1, 0, 4, 5, 2, 0, 4, 3, 0, 3, 3, 6, 4, 5, 6, 1, 2, 7, 1, 2, 6, 6, 3, 1, 1, 7, 5, 5, 0, 2, 2, 1, 5, 2, 5, 3, 5, 3, 6, 0, 7, 4, 6, 3, 0, 2, 4, 7, 1, 7, 0, 5, 2, 0, 2, 2, 3, 0, 3, 6, 5, 0, 6, 4, 2, 1, 3, 7, 7, 4, 6, 3, 0, 4, 1, 6, 3, 1, 6, 6, 6, 4, 5, 4, 5, 7, 3, 0, 0, 3, 2, 2, 4, 4, 2, 2, 5, 5, 5, 0, 2, 0, 7, 1, 1, 0, 7, 7, 6, 3, 6, 1, 4, 0, 7, 3, 7, 6, 4, 1, 2, 7, 1, 3, 6, 5, 2, 0, 5, 3, 0, 1, 7, 2, 0, 6, 1, 4, 1, 5, 7, 5, 7, 2, 1, 0, 0, 5, 1, 0, 5, 7, 3, 7, 1, 2, 6, 7, 0, 7, 6, 4, 2, 2, 5, 6, 0, 3, 0, 5, 1, 1, 2, 0, 6, 3, 1, 5, 5, 7, 1, 0, 5, 0, 4, 3, 4, 1, 4, 3, 2, 0, 6, 0, 2, 2, 2, 3, 2, 5, 5, 7, 4, 0, 2, 6, 1, 1, 0, 1, 0, 0, 4, 1, 7, 2, 4, 4, 5, 3, 5, 7, 5, 0, 6, 7, 7, 5, 1, 0, 0, 0, 7, 2, 1, 5, 3, 7, 5, 0, 7, 7, 6, 1, 2, 6, 7, 0, 4, 2, 0, 6, 6, 4, 2, 4, 5, 3, 7, 5, 3, 6, 2, 1, 4, 0, 6, 7, 6, 2, 0, 3, 4, 1]\n",
      "New best validation accuracy:  0.99375\n",
      "Given hidden layer counts and learning rate:  256 64 0.01\n",
      "--------- Config 10 ---------\n",
      "h1 = 256\n",
      "h2 = 32\n",
      "{'hidden1': 256, 'hidden2': 32, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.1190, train_acc=0.8936 | val_loss=1.2902, val_acc=0.7037, val_mis=237\n",
      "Min SSE: 237.54314698516902\n",
      "Min Misclassifications: 237\n",
      "Epoch 10: train_loss=1.6500, train_acc=0.9166 | val_loss=0.9597, val_acc=0.7875, val_mis=170\n",
      "Min SSE: 183.50722991140185\n",
      "Min Misclassifications: 170\n",
      "Epoch 15: train_loss=1.3742, train_acc=0.9319 | val_loss=0.7908, val_acc=0.8462, val_mis=123\n",
      "Min SSE: 149.69884298160474\n",
      "Min Misclassifications: 123\n",
      "Epoch 20: train_loss=1.1773, train_acc=0.9412 | val_loss=0.6472, val_acc=0.8725, val_mis=102\n",
      "Min SSE: 125.79002453426442\n",
      "Min Misclassifications: 102\n",
      "Epoch 25: train_loss=1.0201, train_acc=0.9493 | val_loss=0.5460, val_acc=0.8938, val_mis=85\n",
      "Min SSE: 106.71464655845875\n",
      "Min Misclassifications: 85\n",
      "Epoch 30: train_loss=0.8963, train_acc=0.9579 | val_loss=0.4836, val_acc=0.9075, val_mis=74\n",
      "Min SSE: 92.48788778246606\n",
      "Min Misclassifications: 74\n",
      "Epoch 35: train_loss=0.7985, train_acc=0.9652 | val_loss=0.4434, val_acc=0.9187, val_mis=65\n",
      "Min SSE: 81.81524403522248\n",
      "Min Misclassifications: 65\n",
      "Epoch 40: train_loss=0.7225, train_acc=0.9697 | val_loss=0.3926, val_acc=0.9275, val_mis=58\n",
      "Min SSE: 72.98305226024125\n",
      "Min Misclassifications: 58\n",
      "Epoch 45: train_loss=0.6612, train_acc=0.9730 | val_loss=0.3631, val_acc=0.9325, val_mis=54\n",
      "Min SSE: 66.40621051488131\n",
      "Min Misclassifications: 54\n",
      "Epoch 50: train_loss=0.6083, train_acc=0.9754 | val_loss=0.3192, val_acc=0.9350, val_mis=52\n",
      "Min SSE: 60.358806509499516\n",
      "Min Misclassifications: 52\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 60.358806509499516\n",
      "Final Min Misclassifications 52\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[1, 7, 1, 7, 4, 4, 3, 6, 0, 2, 2, 2, 2, 1, 5, 6, 4, 5, 4, 6, 3, 7, 4, 1, 7, 1, 3, 7, 0, 4, 2, 6, 1, 6, 5, 4, 3, 5, 6, 3, 7, 7, 7, 7, 0, 2, 4, 5, 1, 1, 0, 2, 1, 2, 2, 0, 0, 5, 0, 6, 2, 5, 5, 6, 7, 7, 4, 3, 6, 5, 2, 2, 3, 6, 0, 3, 3, 2, 3, 3, 5, 3, 6, 6, 6, 5, 4, 6, 2, 6, 5, 1, 3, 0, 5, 1, 3, 0, 2, 0, 2, 0, 2, 6, 5, 5, 0, 7, 0, 2, 1, 0, 7, 7, 3, 4, 2, 0, 3, 0, 7, 0, 2, 6, 6, 3, 4, 3, 0, 0, 2, 3, 0, 4, 5, 6, 6, 6, 7, 3, 0, 6, 5, 4, 7, 0, 6, 4, 4, 5, 1, 1, 4, 2, 1, 7, 7, 2, 7, 6, 5, 7, 0, 3, 3, 4, 4, 5, 7, 7, 4, 7, 3, 4, 4, 0, 3, 0, 5, 7, 2, 5, 3, 7, 1, 4, 7, 2, 7, 5, 6, 0, 4, 4, 7, 1, 1, 7, 0, 2, 7, 1, 7, 7, 7, 3, 5, 0, 6, 3, 4, 2, 2, 1, 0, 6, 6, 6, 6, 4, 6, 3, 1, 1, 4, 3, 4, 2, 2, 5, 4, 0, 5, 7, 3, 5, 3, 5, 4, 4, 1, 5, 7, 3, 6, 6, 5, 3, 3, 7, 0, 2, 3, 3, 2, 4, 7, 3, 4, 3, 7, 2, 1, 1, 6, 2, 3, 5, 2, 7, 6, 5, 5, 1, 1, 4, 0, 0, 5, 2, 6, 6, 2, 0, 1, 2, 0, 5, 1, 7, 5, 0, 3, 5, 1, 7, 6, 0, 3, 1, 0, 1, 2, 0, 6, 3, 1, 7, 4, 4, 7, 5, 0, 3, 6, 1, 7, 1, 3, 4, 6, 1, 3, 1, 0, 6, 2, 0, 0, 5, 0, 2, 4, 0, 3, 4, 5, 7, 7, 2, 5, 7, 4, 7, 6, 3, 4, 6, 3, 2, 6, 4, 6, 5, 4, 7, 0, 3, 4, 4, 0, 3, 1, 4, 5, 1, 2, 3, 5, 6, 5, 3, 5, 5, 4, 3, 1, 1, 7, 2, 3, 4, 4, 5, 7, 5, 2, 1, 0, 2, 7, 2, 5, 2, 7, 4, 5, 2, 7, 1, 3, 5, 1, 1, 2, 7, 6, 6, 0, 2, 2, 7, 7, 6, 5, 0, 3, 3, 1, 7, 1, 7, 2, 0, 4, 4, 4, 2, 4, 6, 3, 3, 0, 4, 0, 2, 0, 0, 4, 1, 2, 4, 7, 1, 0, 4, 1, 6, 7, 7, 6, 7, 6, 2, 1, 2, 3, 4, 3, 7, 0, 0, 7, 6, 5, 5, 5, 5, 1, 0, 5, 0, 3, 2, 5, 7, 4, 7, 7, 6, 4, 4, 4, 6, 0, 4, 1, 1, 1, 4, 0, 0, 4, 0, 7, 0, 3, 5, 0, 3, 5, 2, 1, 0, 3, 0, 3, 2, 1, 5, 6, 4, 5, 1, 5, 7, 2, 6, 1, 1, 4, 4, 0, 1, 5, 7, 0, 5, 1, 4, 2, 5, 6, 7, 5, 7, 1, 3, 6, 1, 0, 3, 4, 7, 6, 5, 6, 0, 3, 1, 0, 3, 7, 7, 1, 3, 3, 5, 2, 5, 6, 2, 1, 2, 5, 5, 2, 6, 7, 6, 5, 6, 1, 2, 4, 0, 7, 1, 5, 4, 1, 4, 1, 7, 2, 7, 4, 3, 3, 1, 7, 1, 1, 7, 4, 6, 5, 6, 5, 4, 6, 1, 5, 2, 4, 2, 0, 0, 1, 2, 7, 1, 6, 0, 5, 0, 0, 5, 6, 3, 3, 6, 3, 0, 0, 5, 6, 3, 6, 7, 6, 7, 2, 6, 1, 6, 7, 4, 7, 7, 4, 3, 2, 1, 6, 0, 3, 5, 5, 0, 2, 0, 0, 1, 4, 6, 6, 7, 3, 1, 5, 2, 2, 2, 6, 5, 5, 1, 1, 4, 3, 0, 3, 0, 4, 2, 7, 3, 3, 1, 4, 7, 5, 3, 4, 6, 2, 4, 1, 0, 6, 0, 3, 4, 3, 5, 5, 1, 3, 7, 6, 6, 0, 3, 0, 0, 0, 2, 5, 3, 2, 4, 5, 0, 6, 2, 1, 0, 7, 7, 0, 3, 6, 4, 2, 4, 3, 6, 0, 3, 3, 0, 6, 1, 1, 0, 2, 5, 7, 3, 6, 0, 1, 7, 5, 0, 5, 1, 2, 7, 3, 6, 3, 5, 6, 5, 3, 0, 6, 4, 0, 1, 2, 7, 7, 1, 1, 3, 0, 3, 7, 0, 1, 0, 0, 3, 2, 7, 6, 6, 0, 4, 0, 3, 4, 0, 4, 6, 2, 1, 7, 7, 1, 4, 4, 6, 0, 5, 3, 5]\n",
      "New best training duration:  0:00:42\n",
      "Given hidden layer counts and learning rate:  256 32 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 11 ---------\n",
      "h1 = 256\n",
      "h2 = 32\n",
      "{'hidden1': 256, 'hidden2': 32, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.1369, train_acc=0.9448 | val_loss=0.6193, val_acc=0.8750, val_mis=100\n",
      "Min SSE: 117.66216316982366\n",
      "Min Misclassifications: 100\n",
      "Epoch 10: train_loss=0.6737, train_acc=0.9721 | val_loss=0.3941, val_acc=0.9450, val_mis=44\n",
      "Min SSE: 68.22452133628586\n",
      "Min Misclassifications: 44\n",
      "Epoch 15: train_loss=0.4876, train_acc=0.9810 | val_loss=0.2635, val_acc=0.9625, val_mis=30\n",
      "Min SSE: 46.050125001667084\n",
      "Min Misclassifications: 30\n",
      "Epoch 20: train_loss=0.3890, train_acc=0.9848 | val_loss=0.1718, val_acc=0.9613, val_mis=31\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 25: train_loss=0.3200, train_acc=0.9879 | val_loss=0.1919, val_acc=0.9725, val_mis=22\n",
      "Min SSE: 32.57924344893432\n",
      "Min Misclassifications: 22\n",
      "Epoch 30: train_loss=0.2761, train_acc=0.9893 | val_loss=0.1201, val_acc=0.9762, val_mis=19\n",
      "Min SSE: 24.652410167774953\n",
      "Min Misclassifications: 19\n",
      "Epoch 35: train_loss=0.2431, train_acc=0.9911 | val_loss=0.0906, val_acc=0.9812, val_mis=15\n",
      "Min SSE: 21.739501311282645\n",
      "Min Misclassifications: 15\n",
      "Epoch 40: train_loss=0.2192, train_acc=0.9919 | val_loss=0.1138, val_acc=0.9862, val_mis=11\n",
      "Min SSE: 19.15481534896051\n",
      "Min Misclassifications: 11\n",
      "Epoch 45: train_loss=0.2007, train_acc=0.9928 | val_loss=0.0898, val_acc=0.9862, val_mis=11\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.1828, train_acc=0.9930 | val_loss=0.0993, val_acc=0.9862, val_mis=11\n",
      "  → no improvement for 2/10 epochs\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 15.847859893361623\n",
      "Final Min Misclassifications 11\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[5, 3, 5, 1, 5, 4, 2, 4, 0, 3, 7, 7, 0, 7, 7, 4, 5, 0, 3, 0, 4, 5, 6, 2, 0, 5, 7, 2, 0, 0, 7, 5, 3, 7, 4, 2, 4, 6, 0, 4, 2, 0, 1, 4, 1, 1, 4, 3, 3, 3, 2, 5, 7, 1, 6, 3, 3, 3, 1, 5, 3, 6, 4, 0, 3, 1, 3, 3, 1, 5, 2, 3, 0, 7, 1, 2, 1, 1, 6, 4, 2, 6, 0, 3, 0, 4, 3, 5, 6, 4, 7, 7, 4, 1, 0, 1, 7, 1, 4, 7, 3, 4, 5, 5, 5, 7, 3, 3, 2, 2, 5, 7, 7, 2, 3, 4, 1, 6, 2, 1, 2, 4, 5, 5, 5, 5, 6, 0, 2, 2, 3, 0, 5, 3, 0, 4, 3, 7, 0, 7, 5, 6, 7, 5, 5, 0, 3, 5, 2, 1, 4, 6, 6, 2, 6, 5, 0, 1, 5, 2, 7, 4, 4, 7, 0, 4, 2, 1, 2, 4, 4, 4, 1, 4, 7, 2, 5, 6, 7, 6, 0, 1, 3, 4, 3, 2, 2, 3, 5, 3, 0, 6, 2, 4, 0, 7, 6, 3, 5, 6, 1, 2, 2, 7, 6, 1, 6, 0, 1, 7, 2, 0, 4, 4, 3, 0, 5, 3, 5, 7, 7, 2, 3, 5, 5, 3, 6, 7, 6, 7, 1, 0, 5, 1, 0, 0, 0, 3, 1, 7, 3, 6, 4, 2, 6, 6, 3, 1, 2, 1, 5, 6, 2, 3, 6, 1, 7, 2, 6, 1, 0, 5, 6, 2, 1, 5, 0, 3, 6, 0, 0, 4, 5, 1, 0, 6, 0, 1, 2, 0, 6, 5, 5, 7, 5, 4, 3, 0, 6, 0, 3, 4, 3, 7, 6, 5, 1, 6, 5, 5, 6, 2, 2, 1, 4, 3, 0, 1, 2, 0, 4, 6, 4, 4, 2, 6, 1, 4, 0, 0, 4, 1, 5, 5, 0, 3, 1, 1, 2, 6, 7, 5, 0, 2, 5, 2, 0, 4, 7, 1, 3, 3, 1, 2, 6, 0, 3, 4, 5, 6, 2, 5, 6, 3, 1, 4, 1, 3, 6, 4, 4, 3, 2, 7, 0, 3, 1, 6, 6, 1, 0, 7, 0, 6, 6, 5, 4, 6, 4, 7, 0, 2, 3, 6, 2, 1, 5, 4, 7, 6, 3, 7, 3, 3, 4, 5, 7, 0, 6, 5, 3, 4, 2, 6, 6, 0, 0, 6, 5, 6, 5, 1, 0, 5, 5, 6, 6, 2, 6, 4, 7, 6, 5, 2, 5, 4, 6, 5, 7, 4, 4, 4, 7, 5, 0, 5, 0, 2, 2, 3, 2, 6, 0, 7, 4, 2, 3, 6, 1, 3, 4, 0, 2, 2, 4, 1, 1, 3, 7, 4, 4, 4, 7, 5, 2, 2, 4, 0, 2, 6, 7, 1, 1, 5, 3, 1, 1, 0, 4, 6, 7, 6, 2, 5, 2, 2, 6, 6, 3, 0, 5, 2, 1, 4, 0, 2, 3, 4, 5, 7, 2, 1, 1, 6, 6, 3, 0, 3, 1, 6, 2, 6, 3, 6, 1, 4, 4, 5, 2, 6, 1, 5, 4, 0, 1, 7, 6, 5, 0, 2, 1, 7, 7, 2, 4, 7, 0, 0, 2, 3, 2, 6, 4, 4, 0, 7, 2, 1, 7, 4, 3, 6, 4, 3, 1, 3, 4, 5, 1, 0, 1, 1, 7, 2, 2, 1, 7, 3, 4, 0, 2, 2, 7, 3, 3, 4, 7, 7, 2, 4, 3, 4, 5, 5, 7, 5, 0, 6, 1, 4, 7, 1, 0, 7, 0, 3, 1, 7, 3, 3, 1, 7, 6, 2, 5, 2, 3, 4, 5, 7, 7, 7, 2, 1, 4, 4, 2, 7, 5, 5, 3, 0, 6, 2, 4, 0, 0, 4, 0, 2, 4, 3, 0, 3, 2, 3, 0, 0, 6, 0, 5, 0, 5, 1, 7, 6, 0, 5, 1, 5, 0, 0, 5, 1, 2, 4, 6, 1, 2, 5, 7, 7, 4, 2, 7, 2, 2, 1, 7, 1, 2, 1, 4, 4, 5, 6, 7, 6, 6, 4, 7, 7, 6, 4, 6, 6, 7, 3, 5, 6, 1, 2, 0, 5, 1, 4, 5, 5, 3, 2, 6, 1, 3, 2, 7, 2, 3, 1, 4, 3, 0, 4, 6, 7, 7, 2, 4, 3, 3, 0, 6, 6, 6, 2, 5, 7, 0, 2, 7, 7, 3, 5, 0, 3, 3, 7, 1, 7, 4, 6, 4, 4, 7, 6, 3, 6, 3, 7, 1, 5, 3, 7, 0, 6, 6, 5, 5, 1, 4, 6, 3, 7, 2, 4, 6, 4, 0, 7, 7, 1, 3, 1, 6, 7, 3, 6, 0, 2, 7, 1, 1, 3, 6, 3, 4, 0, 4, 1, 7, 0, 7, 5, 7, 6, 6, 0, 4, 1, 0, 2]\n",
      "New best training duration:  0:00:41\n",
      "Given hidden layer counts and learning rate:  256 32 0.005\n",
      "--------- Config 12 ---------\n",
      "h1 = 256\n",
      "h2 = 32\n",
      "{'hidden1': 256, 'hidden2': 32, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.7197, train_acc=0.9690 | val_loss=0.3971, val_acc=0.8912, val_mis=87\n",
      "Min SSE: 81.78306263997098\n",
      "Min Misclassifications: 87\n",
      "Epoch 10: train_loss=0.4110, train_acc=0.9828 | val_loss=0.2086, val_acc=0.9600, val_mis=32\n",
      "Min SSE: 38.01467022197997\n",
      "Min Misclassifications: 32\n",
      "Epoch 15: train_loss=0.3031, train_acc=0.9876 | val_loss=0.1830, val_acc=0.9675, val_mis=26\n",
      "Min SSE: 30.326124576575666\n",
      "Min Misclassifications: 26\n",
      "Epoch 20: train_loss=0.2379, train_acc=0.9906 | val_loss=0.1399, val_acc=0.9788, val_mis=17\n",
      "Min SSE: 21.752619223207525\n",
      "Min Misclassifications: 17\n",
      "Epoch 25: train_loss=0.1953, train_acc=0.9924 | val_loss=0.1054, val_acc=0.9825, val_mis=14\n",
      "Min SSE: 15.90204800731708\n",
      "Min Misclassifications: 14\n",
      "Epoch 30: train_loss=0.1725, train_acc=0.9930 | val_loss=0.0762, val_acc=0.9825, val_mis=14\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 35: train_loss=0.1436, train_acc=0.9946 | val_loss=0.0860, val_acc=0.9875, val_mis=10\n",
      "Min SSE: 12.296329391902631\n",
      "Min Misclassifications: 10\n",
      "Epoch 40: train_loss=0.1358, train_acc=0.9948 | val_loss=0.0772, val_acc=0.9850, val_mis=12\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1216, train_acc=0.9954 | val_loss=0.0843, val_acc=0.9762, val_mis=19\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1108, train_acc=0.9957 | val_loss=0.0683, val_acc=0.9862, val_mis=11\n",
      "  → no improvement for 3/10 epochs\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 12.098405311613913\n",
      "Final Min Misclassifications 10\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[5, 0, 4, 2, 2, 6, 3, 0, 7, 1, 6, 0, 0, 6, 1, 5, 7, 3, 1, 7, 1, 6, 1, 1, 4, 1, 7, 7, 2, 4, 6, 3, 4, 3, 2, 4, 7, 1, 5, 3, 7, 5, 3, 2, 6, 0, 1, 7, 2, 0, 7, 1, 3, 7, 2, 1, 3, 5, 3, 4, 2, 2, 3, 0, 2, 6, 5, 6, 6, 0, 4, 7, 0, 1, 0, 3, 6, 1, 7, 5, 0, 4, 2, 5, 5, 1, 7, 2, 7, 0, 2, 1, 3, 5, 7, 3, 1, 1, 2, 5, 5, 4, 0, 2, 2, 5, 2, 4, 3, 1, 1, 4, 2, 0, 3, 2, 5, 1, 3, 2, 4, 5, 0, 4, 2, 0, 3, 0, 5, 6, 3, 7, 0, 0, 5, 2, 0, 4, 2, 5, 2, 0, 7, 5, 4, 2, 5, 6, 0, 2, 6, 6, 6, 0, 1, 6, 4, 4, 2, 0, 7, 6, 6, 5, 4, 3, 2, 0, 1, 3, 0, 3, 4, 2, 3, 7, 3, 6, 1, 4, 7, 1, 5, 0, 1, 2, 3, 5, 2, 4, 2, 3, 4, 2, 5, 0, 1, 1, 6, 0, 3, 1, 1, 5, 3, 7, 1, 2, 2, 4, 4, 1, 0, 0, 3, 5, 5, 2, 5, 7, 4, 5, 0, 4, 4, 5, 0, 2, 7, 3, 0, 6, 2, 3, 6, 7, 2, 6, 4, 4, 2, 2, 0, 5, 0, 7, 3, 3, 1, 2, 2, 5, 7, 7, 0, 4, 6, 2, 5, 2, 7, 5, 0, 1, 1, 5, 0, 4, 1, 2, 2, 3, 1, 4, 7, 6, 6, 3, 1, 4, 7, 4, 5, 4, 3, 2, 5, 0, 2, 7, 5, 1, 6, 2, 5, 7, 7, 2, 6, 1, 0, 2, 3, 1, 1, 2, 2, 0, 1, 2, 6, 3, 2, 4, 6, 7, 3, 3, 0, 5, 5, 4, 2, 5, 6, 7, 7, 6, 7, 6, 7, 6, 5, 5, 6, 1, 6, 3, 4, 5, 1, 0, 1, 4, 0, 3, 2, 5, 1, 7, 5, 4, 2, 6, 3, 1, 3, 4, 4, 4, 4, 3, 4, 5, 6, 7, 6, 2, 5, 1, 7, 6, 6, 7, 4, 3, 7, 3, 0, 5, 3, 6, 5, 6, 6, 6, 3, 1, 6, 3, 5, 0, 4, 1, 0, 1, 3, 3, 5, 6, 5, 4, 2, 1, 6, 6, 3, 6, 2, 3, 3, 5, 2, 0, 5, 3, 1, 0, 5, 4, 5, 5, 7, 3, 2, 4, 1, 4, 5, 3, 0, 5, 7, 7, 5, 3, 7, 3, 7, 0, 4, 2, 1, 3, 6, 2, 1, 0, 7, 7, 1, 7, 2, 4, 1, 3, 2, 2, 0, 3, 1, 7, 2, 4, 3, 5, 2, 5, 1, 4, 2, 0, 2, 3, 7, 2, 3, 3, 2, 4, 2, 1, 5, 3, 4, 0, 5, 1, 1, 1, 3, 3, 3, 0, 0, 2, 5, 6, 1, 1, 3, 3, 1, 6, 3, 1, 4, 6, 6, 5, 3, 7, 7, 3, 6, 0, 1, 7, 1, 2, 0, 3, 1, 4, 3, 1, 7, 3, 7, 1, 0, 3, 7, 3, 5, 0, 4, 1, 1, 0, 1, 3, 7, 4, 4, 3, 2, 6, 2, 2, 0, 2, 2, 2, 7, 2, 2, 6, 1, 7, 2, 3, 6, 0, 7, 2, 7, 4, 5, 0, 2, 5, 1, 5, 3, 7, 5, 6, 1, 5, 7, 0, 7, 3, 2, 1, 4, 0, 5, 7, 6, 5, 2, 4, 7, 7, 4, 7, 1, 6, 3, 2, 0, 3, 1, 2, 2, 5, 6, 1, 7, 0, 0, 1, 1, 7, 0, 3, 5, 5, 2, 7, 3, 0, 6, 5, 1, 2, 6, 0, 7, 6, 6, 2, 3, 3, 1, 5, 0, 3, 3, 7, 1, 5, 0, 3, 3, 5, 4, 6, 7, 2, 0, 6, 5, 6, 7, 0, 7, 0, 2, 4, 6, 6, 6, 7, 2, 2, 4, 0, 0, 0, 1, 1, 4, 3, 6, 2, 7, 2, 5, 6, 2, 5, 6, 6, 6, 3, 5, 4, 2, 7, 4, 6, 2, 7, 3, 6, 6, 3, 7, 7, 0, 6, 3, 1, 0, 6, 5, 0, 1, 4, 5, 1, 5, 6, 5, 0, 3, 6, 5, 0, 6, 7, 1, 6, 2, 1, 2, 3, 4, 6, 1, 6, 2, 3, 3, 2, 0, 6, 1, 3, 2, 3, 0, 2, 4, 6, 4, 2, 5, 1, 1, 7, 1, 2, 7, 0, 6, 4, 0, 0, 0, 2, 1, 4, 5, 0, 5, 4, 7, 3, 6, 5, 7, 5, 3, 2, 5, 1, 0, 2, 3, 4, 5, 4, 7, 3, 2, 2, 6, 2, 7, 4, 0, 3, 4, 3, 7, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 13 ---------\n",
      "h1 = 256\n",
      "h2 = 16\n",
      "{'hidden1': 256, 'hidden2': 16, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.2949, train_acc=0.8908 | val_loss=1.4038, val_acc=0.6525, val_mis=278\n",
      "Min SSE: 256.0351286747962\n",
      "Min Misclassifications: 278\n",
      "Epoch 10: train_loss=1.7941, train_acc=0.9110 | val_loss=1.0577, val_acc=0.7837, val_mis=173\n",
      "Min SSE: 198.54899465367265\n",
      "Min Misclassifications: 173\n",
      "Epoch 15: train_loss=1.4915, train_acc=0.9277 | val_loss=0.8773, val_acc=0.8087, val_mis=153\n",
      "Min SSE: 163.65849674686507\n",
      "Min Misclassifications: 153\n",
      "Epoch 20: train_loss=1.2666, train_acc=0.9395 | val_loss=0.7434, val_acc=0.8438, val_mis=125\n",
      "Min SSE: 139.58935077013496\n",
      "Min Misclassifications: 125\n",
      "Epoch 25: train_loss=1.0889, train_acc=0.9475 | val_loss=0.6326, val_acc=0.8812, val_mis=95\n",
      "Min SSE: 117.57874149255265\n",
      "Min Misclassifications: 95\n",
      "Epoch 30: train_loss=0.9473, train_acc=0.9553 | val_loss=0.5216, val_acc=0.9025, val_mis=78\n",
      "Min SSE: 100.40806336301398\n",
      "Min Misclassifications: 78\n",
      "Epoch 35: train_loss=0.8381, train_acc=0.9630 | val_loss=0.4633, val_acc=0.9163, val_mis=67\n",
      "Min SSE: 88.24290373760904\n",
      "Min Misclassifications: 67\n",
      "Epoch 40: train_loss=0.7527, train_acc=0.9693 | val_loss=0.4289, val_acc=0.9237, val_mis=61\n",
      "Min SSE: 79.42532329340864\n",
      "Min Misclassifications: 61\n",
      "Epoch 45: train_loss=0.6849, train_acc=0.9731 | val_loss=0.3808, val_acc=0.9275, val_mis=58\n",
      "Min SSE: 72.26754568939992\n",
      "Min Misclassifications: 58\n",
      "Epoch 50: train_loss=0.6302, train_acc=0.9757 | val_loss=0.3488, val_acc=0.9337, val_mis=53\n",
      "Min SSE: 66.61772374157161\n",
      "Min Misclassifications: 53\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 66.61772374157161\n",
      "Final Min Misclassifications 53\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[7, 1, 3, 3, 3, 1, 5, 5, 2, 5, 7, 1, 7, 3, 6, 6, 5, 7, 1, 6, 4, 6, 6, 2, 3, 6, 3, 1, 4, 5, 1, 2, 7, 3, 1, 2, 4, 0, 4, 0, 1, 7, 0, 1, 5, 5, 0, 5, 7, 6, 7, 6, 0, 7, 2, 4, 2, 6, 5, 4, 7, 0, 2, 6, 3, 4, 7, 6, 1, 2, 5, 4, 2, 0, 0, 6, 1, 1, 3, 3, 5, 2, 1, 1, 4, 5, 1, 5, 1, 4, 1, 7, 5, 5, 7, 0, 0, 7, 1, 3, 1, 7, 3, 1, 3, 4, 1, 4, 1, 3, 7, 2, 5, 1, 0, 5, 3, 7, 5, 7, 7, 7, 0, 3, 2, 5, 4, 7, 5, 5, 6, 3, 6, 6, 3, 7, 0, 5, 4, 3, 7, 6, 4, 6, 3, 5, 1, 4, 1, 0, 1, 0, 3, 7, 4, 2, 7, 4, 7, 6, 3, 7, 2, 3, 4, 3, 3, 4, 1, 2, 0, 6, 2, 1, 0, 1, 1, 1, 5, 2, 1, 1, 6, 4, 0, 0, 0, 4, 7, 6, 2, 1, 4, 3, 3, 6, 6, 7, 6, 4, 2, 5, 5, 0, 2, 3, 0, 4, 5, 1, 7, 1, 6, 0, 0, 1, 0, 0, 3, 2, 3, 7, 3, 4, 4, 3, 3, 3, 3, 4, 7, 1, 0, 6, 5, 4, 3, 5, 5, 2, 3, 0, 5, 5, 6, 0, 3, 4, 0, 3, 7, 0, 5, 7, 0, 1, 4, 7, 1, 4, 7, 1, 0, 5, 4, 6, 7, 0, 1, 4, 3, 1, 4, 3, 2, 4, 1, 3, 0, 2, 1, 6, 3, 2, 3, 4, 3, 2, 1, 2, 1, 7, 2, 6, 4, 0, 2, 5, 4, 0, 1, 3, 0, 0, 1, 6, 6, 1, 1, 4, 5, 0, 7, 5, 6, 5, 1, 5, 6, 1, 2, 5, 2, 3, 2, 6, 5, 6, 6, 2, 7, 5, 7, 0, 6, 4, 1, 3, 2, 3, 7, 1, 1, 1, 7, 0, 4, 6, 3, 3, 3, 5, 7, 4, 5, 1, 4, 6, 2, 5, 1, 3, 4, 6, 2, 2, 6, 1, 3, 2, 1, 3, 3, 7, 0, 7, 2, 4, 7, 1, 1, 6, 2, 4, 2, 1, 5, 5, 0, 2, 6, 4, 0, 6, 4, 0, 7, 1, 7, 4, 7, 1, 4, 3, 5, 2, 1, 0, 5, 4, 3, 4, 7, 1, 7, 1, 0, 2, 4, 0, 2, 7, 0, 2, 7, 7, 2, 6, 2, 4, 6, 0, 0, 0, 6, 6, 4, 4, 5, 4, 5, 1, 3, 1, 4, 3, 1, 5, 1, 2, 5, 7, 3, 7, 7, 6, 3, 7, 0, 4, 3, 1, 3, 6, 6, 7, 6, 5, 4, 3, 5, 3, 7, 6, 1, 3, 4, 0, 5, 1, 7, 5, 7, 7, 2, 6, 2, 1, 2, 4, 7, 1, 4, 0, 2, 1, 1, 6, 5, 5, 0, 6, 1, 6, 4, 0, 0, 4, 7, 4, 6, 6, 2, 6, 5, 0, 4, 4, 2, 1, 5, 7, 5, 3, 4, 7, 1, 7, 1, 3, 7, 4, 5, 4, 2, 7, 1, 5, 4, 3, 6, 4, 7, 2, 6, 2, 0, 6, 0, 6, 0, 5, 6, 2, 7, 2, 3, 1, 6, 5, 2, 5, 0, 3, 3, 0, 4, 6, 0, 4, 2, 7, 1, 0, 3, 2, 7, 1, 0, 2, 6, 4, 6, 7, 3, 5, 1, 7, 2, 0, 2, 3, 5, 3, 6, 3, 1, 5, 2, 0, 2, 0, 6, 4, 5, 0, 1, 2, 3, 6, 5, 4, 5, 4, 1, 4, 3, 0, 5, 4, 1, 1, 7, 3, 2, 5, 4, 4, 3, 1, 7, 1, 5, 6, 1, 5, 2, 4, 4, 3, 7, 2, 0, 7, 5, 4, 4, 3, 4, 4, 5, 2, 4, 5, 1, 5, 4, 7, 7, 0, 4, 4, 7, 2, 2, 6, 6, 1, 2, 2, 0, 7, 5, 7, 5, 3, 0, 3, 3, 4, 1, 1, 5, 0, 2, 0, 6, 0, 0, 0, 4, 6, 1, 0, 6, 2, 1, 3, 6, 3, 7, 4, 2, 6, 4, 1, 3, 1, 0, 4, 7, 0, 7, 0, 1, 6, 5, 4, 2, 1, 3, 1, 3, 3, 4, 2, 4, 4, 2, 7, 6, 1, 5, 0, 0, 2, 3, 4, 5, 7, 2, 2, 2, 7, 3, 0, 2, 3, 6, 1, 4, 3, 4, 0, 1, 0, 0, 5, 5, 1, 1, 1, 5, 0, 4, 7, 3, 2, 7, 5, 2, 0, 1, 5, 5, 1, 1, 7, 7, 4, 4, 1, 7, 3, 6, 0, 2, 3, 4, 3, 5, 1, 5, 3, 5, 3, 0, 2, 5, 1]\n",
      "--------- Config 14 ---------\n",
      "h1 = 256\n",
      "h2 = 16\n",
      "{'hidden1': 256, 'hidden2': 16, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.2809, train_acc=0.9386 | val_loss=0.6948, val_acc=0.8325, val_mis=134\n",
      "Min SSE: 131.98920821778273\n",
      "Min Misclassifications: 134\n",
      "Epoch 10: train_loss=0.7448, train_acc=0.9668 | val_loss=0.3596, val_acc=0.9175, val_mis=66\n",
      "Min SSE: 72.11922848488564\n",
      "Min Misclassifications: 66\n",
      "Epoch 15: train_loss=0.5173, train_acc=0.9787 | val_loss=0.2847, val_acc=0.9487, val_mis=41\n",
      "Min SSE: 51.4395979799787\n",
      "Min Misclassifications: 41\n",
      "Epoch 20: train_loss=0.3928, train_acc=0.9845 | val_loss=0.2044, val_acc=0.9537, val_mis=37\n",
      "Min SSE: 38.84053894575845\n",
      "Min Misclassifications: 37\n",
      "Epoch 25: train_loss=0.3200, train_acc=0.9879 | val_loss=0.1702, val_acc=0.9700, val_mis=24\n",
      "Min SSE: 31.543210350961054\n",
      "Min Misclassifications: 24\n",
      "Epoch 30: train_loss=0.2692, train_acc=0.9903 | val_loss=0.1161, val_acc=0.9762, val_mis=19\n",
      "Min SSE: 23.401755712750003\n",
      "Min Misclassifications: 19\n",
      "Epoch 35: train_loss=0.2385, train_acc=0.9914 | val_loss=0.0929, val_acc=0.9800, val_mis=16\n",
      "Min SSE: 20.058704421313717\n",
      "Min Misclassifications: 16\n",
      "Epoch 40: train_loss=0.2179, train_acc=0.9922 | val_loss=0.1161, val_acc=0.9800, val_mis=16\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1928, train_acc=0.9930 | val_loss=0.1056, val_acc=0.9825, val_mis=14\n",
      "Min SSE: 17.26970178321366\n",
      "Min Misclassifications: 14\n",
      "Epoch 50: train_loss=0.1799, train_acc=0.9936 | val_loss=0.0862, val_acc=0.9812, val_mis=15\n",
      "  → no improvement for 1/10 epochs\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 17.26970178321366\n",
      "Final Min Misclassifications 14\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[6, 4, 2, 5, 6, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 4, 3, 2, 2, 7, 2, 0, 0, 3, 0, 0, 6, 0, 3, 4, 2, 0, 5, 0, 7, 5, 1, 7, 5, 1, 5, 7, 3, 1, 4, 6, 3, 4, 6, 0, 4, 4, 3, 7, 2, 6, 7, 5, 5, 6, 1, 3, 7, 4, 4, 7, 4, 7, 6, 4, 0, 4, 5, 5, 1, 4, 1, 0, 0, 5, 6, 1, 6, 2, 7, 3, 3, 0, 1, 6, 1, 4, 6, 0, 0, 1, 1, 1, 4, 7, 2, 1, 1, 6, 1, 7, 0, 0, 5, 5, 5, 6, 2, 4, 4, 0, 4, 2, 0, 5, 6, 6, 5, 4, 4, 0, 1, 3, 1, 3, 5, 6, 4, 1, 6, 5, 1, 1, 7, 3, 3, 5, 1, 7, 5, 3, 6, 5, 4, 6, 5, 5, 7, 6, 6, 3, 6, 2, 5, 5, 0, 0, 0, 3, 6, 0, 1, 0, 3, 0, 1, 1, 4, 2, 7, 0, 0, 4, 4, 7, 2, 0, 2, 5, 4, 2, 2, 5, 6, 4, 0, 3, 3, 6, 3, 3, 7, 5, 6, 1, 6, 6, 5, 2, 0, 2, 5, 3, 2, 0, 3, 0, 4, 3, 6, 5, 4, 0, 6, 0, 3, 7, 1, 3, 6, 3, 3, 6, 5, 6, 6, 5, 6, 4, 6, 0, 5, 7, 0, 3, 1, 7, 7, 4, 1, 6, 2, 4, 2, 4, 2, 4, 3, 3, 7, 2, 6, 3, 6, 0, 7, 6, 6, 7, 4, 7, 1, 3, 7, 6, 7, 7, 1, 7, 4, 6, 0, 4, 5, 3, 4, 7, 1, 5, 7, 7, 2, 5, 7, 6, 7, 2, 2, 5, 0, 3, 3, 6, 1, 0, 7, 6, 2, 1, 5, 5, 3, 6, 5, 5, 7, 2, 5, 7, 3, 1, 0, 5, 3, 5, 3, 2, 2, 2, 5, 2, 0, 5, 3, 0, 5, 6, 0, 0, 6, 5, 0, 7, 0, 7, 6, 6, 3, 5, 7, 2, 7, 0, 0, 7, 6, 2, 4, 5, 7, 5, 1, 1, 4, 1, 4, 6, 4, 5, 0, 6, 6, 0, 1, 3, 6, 3, 6, 3, 5, 7, 6, 1, 4, 3, 7, 5, 0, 7, 6, 7, 1, 7, 3, 4, 2, 0, 4, 2, 0, 5, 7, 2, 7, 7, 7, 2, 6, 4, 1, 0, 6, 7, 2, 1, 6, 4, 6, 0, 2, 0, 4, 6, 4, 1, 0, 0, 0, 4, 3, 3, 7, 2, 1, 2, 1, 7, 1, 2, 4, 1, 1, 6, 7, 2, 5, 0, 2, 1, 4, 0, 5, 2, 5, 1, 4, 3, 0, 1, 5, 7, 5, 0, 3, 4, 0, 3, 7, 6, 7, 7, 0, 4, 6, 6, 7, 5, 1, 4, 3, 7, 3, 6, 1, 6, 6, 3, 0, 0, 2, 5, 1, 1, 2, 3, 4, 0, 0, 5, 6, 0, 4, 6, 4, 4, 7, 0, 2, 3, 6, 5, 7, 5, 0, 1, 4, 2, 2, 7, 1, 5, 5, 1, 5, 0, 1, 0, 2, 0, 4, 5, 4, 3, 4, 5, 2, 6, 1, 0, 6, 5, 1, 4, 6, 3, 6, 2, 2, 5, 3, 1, 6, 3, 4, 2, 2, 0, 0, 0, 0, 0, 1, 3, 0, 7, 1, 2, 6, 4, 1, 5, 2, 3, 0, 3, 4, 1, 0, 3, 0, 6, 5, 6, 3, 3, 5, 6, 1, 7, 7, 2, 1, 0, 3, 7, 2, 2, 5, 2, 2, 3, 4, 6, 4, 3, 7, 6, 5, 0, 2, 5, 3, 7, 0, 6, 3, 3, 0, 3, 6, 1, 3, 7, 2, 0, 2, 7, 5, 2, 3, 0, 5, 5, 3, 6, 1, 4, 6, 6, 3, 2, 3, 4, 6, 1, 4, 2, 2, 1, 0, 6, 0, 7, 2, 2, 1, 6, 5, 2, 3, 6, 0, 0, 5, 4, 7, 4, 3, 4, 7, 4, 4, 4, 0, 1, 2, 4, 2, 6, 1, 5, 2, 6, 4, 6, 6, 0, 3, 7, 5, 1, 1, 7, 0, 1, 3, 1, 3, 5, 6, 2, 6, 3, 7, 2, 3, 7, 6, 2, 3, 2, 6, 1, 5, 5, 0, 4, 0, 0, 7, 5, 5, 1, 1, 0, 3, 1, 2, 7, 0, 2, 6, 7, 7, 0, 0, 7, 4, 0, 1, 2, 4, 5, 0, 4, 2, 3, 4, 4, 6, 7, 1, 6, 1, 2, 7, 7, 6, 5, 0, 7, 0, 2, 2, 6, 5, 5, 2, 1, 2, 2, 1, 6, 6, 2, 5, 3, 1, 6, 3, 7, 7, 7, 5, 5, 6, 1, 3, 2, 4, 1, 0, 1, 6, 1, 3, 4, 1, 3, 1, 4, 1, 0, 7, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 15 ---------\n",
      "h1 = 256\n",
      "h2 = 16\n",
      "{'hidden1': 256, 'hidden2': 16, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.7459, train_acc=0.9682 | val_loss=0.4432, val_acc=0.9113, val_mis=71\n",
      "Min SSE: 80.70376309200873\n",
      "Min Misclassifications: 71\n",
      "Epoch 10: train_loss=0.4293, train_acc=0.9828 | val_loss=0.2051, val_acc=0.9525, val_mis=38\n",
      "Min SSE: 44.65377616082422\n",
      "Min Misclassifications: 38\n",
      "Epoch 15: train_loss=0.3119, train_acc=0.9873 | val_loss=0.1781, val_acc=0.9563, val_mis=35\n",
      "Min SSE: 34.497349077424886\n",
      "Min Misclassifications: 35\n",
      "Epoch 20: train_loss=0.2441, train_acc=0.9900 | val_loss=0.1438, val_acc=0.9613, val_mis=31\n",
      "Min SSE: 28.151948299288485\n",
      "Min Misclassifications: 31\n",
      "Epoch 25: train_loss=0.2023, train_acc=0.9921 | val_loss=0.1533, val_acc=0.9725, val_mis=22\n",
      "Min SSE: 26.45325977706988\n",
      "Min Misclassifications: 22\n",
      "Epoch 30: train_loss=0.1767, train_acc=0.9934 | val_loss=0.1054, val_acc=0.9775, val_mis=18\n",
      "Min SSE: 20.1437723440162\n",
      "Min Misclassifications: 18\n",
      "Epoch 35: train_loss=0.1549, train_acc=0.9939 | val_loss=0.0849, val_acc=0.9800, val_mis=16\n",
      "Min SSE: 16.151762677287707\n",
      "Min Misclassifications: 16\n",
      "Epoch 40: train_loss=0.1375, train_acc=0.9947 | val_loss=0.0941, val_acc=0.9788, val_mis=17\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1215, train_acc=0.9953 | val_loss=0.1046, val_acc=0.9712, val_mis=23\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1141, train_acc=0.9957 | val_loss=0.1079, val_acc=0.9825, val_mis=14\n",
      "Min SSE: 16.151762677287707\n",
      "Min Misclassifications: 14\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 16.151762677287707\n",
      "Final Min Misclassifications 14\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[3, 0, 5, 0, 3, 6, 7, 2, 5, 5, 6, 0, 7, 3, 2, 2, 3, 6, 2, 6, 4, 5, 4, 4, 7, 5, 7, 7, 0, 6, 1, 2, 5, 7, 4, 4, 3, 6, 2, 7, 5, 6, 1, 5, 2, 7, 2, 2, 4, 4, 6, 4, 7, 6, 4, 3, 4, 3, 7, 6, 0, 7, 4, 2, 4, 3, 3, 6, 2, 3, 4, 1, 6, 4, 5, 5, 5, 6, 4, 6, 1, 0, 4, 6, 6, 6, 6, 4, 4, 1, 3, 4, 4, 2, 6, 7, 2, 1, 3, 4, 6, 4, 7, 2, 2, 7, 1, 3, 2, 7, 4, 2, 6, 6, 5, 0, 3, 0, 6, 1, 1, 2, 0, 7, 5, 2, 4, 6, 4, 5, 3, 7, 2, 3, 0, 0, 1, 4, 3, 6, 4, 1, 6, 6, 0, 3, 7, 5, 6, 3, 4, 3, 3, 3, 1, 4, 3, 6, 0, 6, 0, 5, 0, 7, 2, 4, 5, 6, 1, 4, 4, 4, 6, 4, 3, 6, 7, 4, 7, 1, 2, 3, 3, 3, 2, 3, 3, 3, 7, 0, 2, 2, 3, 6, 0, 7, 7, 5, 1, 3, 4, 7, 0, 4, 1, 1, 4, 6, 7, 4, 0, 3, 4, 4, 7, 1, 1, 6, 2, 5, 5, 7, 1, 4, 0, 3, 7, 4, 6, 2, 7, 4, 1, 6, 4, 6, 1, 3, 3, 2, 7, 5, 3, 4, 2, 2, 4, 5, 2, 5, 2, 0, 0, 0, 0, 6, 6, 6, 5, 6, 4, 2, 1, 2, 7, 0, 0, 5, 4, 3, 7, 0, 3, 3, 3, 2, 6, 3, 2, 6, 7, 4, 2, 2, 4, 5, 2, 1, 7, 7, 3, 3, 2, 6, 7, 7, 2, 0, 5, 7, 5, 4, 0, 2, 1, 0, 6, 6, 4, 6, 2, 5, 6, 4, 1, 5, 0, 4, 0, 0, 4, 4, 3, 5, 7, 7, 4, 7, 3, 2, 3, 3, 6, 6, 4, 4, 5, 0, 5, 7, 5, 3, 7, 7, 4, 1, 7, 5, 2, 0, 4, 4, 7, 3, 0, 0, 5, 0, 5, 7, 4, 5, 3, 0, 2, 1, 2, 0, 5, 3, 1, 7, 6, 1, 1, 2, 0, 7, 0, 0, 6, 5, 1, 6, 1, 0, 2, 3, 6, 2, 4, 1, 6, 0, 7, 2, 4, 3, 5, 1, 4, 5, 6, 6, 3, 0, 4, 4, 5, 7, 2, 7, 2, 0, 1, 5, 1, 0, 1, 7, 6, 4, 5, 4, 5, 3, 3, 5, 5, 4, 6, 4, 0, 7, 5, 2, 4, 3, 0, 6, 5, 6, 3, 0, 1, 0, 2, 2, 5, 7, 0, 5, 4, 1, 4, 0, 5, 7, 5, 6, 0, 6, 4, 6, 5, 4, 5, 2, 2, 7, 1, 5, 5, 5, 0, 1, 0, 4, 2, 3, 3, 5, 6, 4, 3, 6, 0, 2, 7, 0, 4, 7, 6, 0, 5, 7, 3, 5, 3, 3, 7, 4, 0, 4, 1, 0, 2, 3, 7, 3, 4, 3, 7, 0, 4, 0, 1, 0, 5, 7, 5, 0, 7, 2, 5, 6, 0, 6, 0, 6, 1, 3, 1, 2, 1, 0, 2, 3, 0, 7, 0, 7, 4, 1, 5, 2, 0, 7, 7, 3, 7, 7, 7, 4, 1, 4, 4, 3, 3, 0, 5, 3, 6, 5, 3, 5, 4, 1, 5, 7, 3, 4, 0, 2, 0, 5, 3, 1, 0, 1, 2, 4, 2, 1, 7, 7, 5, 1, 1, 2, 7, 3, 0, 6, 7, 6, 6, 3, 7, 7, 6, 7, 5, 3, 6, 0, 7, 6, 7, 7, 4, 0, 2, 7, 5, 6, 7, 2, 2, 7, 4, 1, 0, 6, 7, 7, 5, 3, 1, 3, 5, 0, 3, 3, 6, 5, 0, 0, 5, 5, 5, 5, 3, 3, 4, 5, 7, 5, 2, 7, 5, 0, 2, 3, 2, 2, 2, 4, 0, 0, 7, 7, 5, 7, 4, 3, 3, 1, 2, 2, 4, 2, 3, 4, 2, 7, 3, 0, 5, 2, 0, 5, 0, 1, 0, 1, 4, 0, 1, 3, 0, 6, 5, 4, 2, 0, 3, 4, 1, 5, 6, 5, 4, 1, 3, 0, 4, 5, 2, 6, 1, 2, 7, 4, 1, 2, 7, 5, 0, 4, 7, 6, 6, 0, 5, 7, 0, 4, 2, 0, 7, 6, 2, 2, 4, 7, 0, 3, 2, 3, 3, 7, 4, 4, 6, 4, 6, 6, 3, 0, 3, 2, 6, 4, 0, 0, 5, 4, 7, 2, 5, 7, 7, 0, 0, 1, 1, 4, 6, 1, 3, 2, 3, 3, 5, 7, 6, 5, 2, 1, 4, 6, 5, 4, 6, 6, 7, 6, 6, 4, 7, 1, 7, 3, 7, 0, 0, 7, 1, 0]\n",
      "New best training duration:  0:00:39\n",
      "Given hidden layer counts and learning rate:  256 16 0.01\n",
      "--------- Config 16 ---------\n",
      "h1 = 128\n",
      "h2 = 64\n",
      "{'hidden1': 128, 'hidden2': 64, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.1918, train_acc=0.8911 | val_loss=1.3219, val_acc=0.7150, val_mis=228\n",
      "Min SSE: 245.98718956995447\n",
      "Min Misclassifications: 228\n",
      "Epoch 10: train_loss=1.7188, train_acc=0.9154 | val_loss=1.0101, val_acc=0.7963, val_mis=163\n",
      "Min SSE: 189.35166232448785\n",
      "Min Misclassifications: 163\n",
      "Epoch 15: train_loss=1.4319, train_acc=0.9310 | val_loss=0.8380, val_acc=0.8625, val_mis=110\n",
      "Min SSE: 155.65092463140533\n",
      "Min Misclassifications: 110\n",
      "Epoch 20: train_loss=1.2211, train_acc=0.9399 | val_loss=0.6857, val_acc=0.8900, val_mis=88\n",
      "Min SSE: 128.8690339231132\n",
      "Min Misclassifications: 88\n",
      "Epoch 25: train_loss=1.0571, train_acc=0.9467 | val_loss=0.5730, val_acc=0.9050, val_mis=76\n",
      "Min SSE: 108.4767807140285\n",
      "Min Misclassifications: 76\n",
      "Epoch 30: train_loss=0.9256, train_acc=0.9556 | val_loss=0.4948, val_acc=0.9263, val_mis=59\n",
      "Min SSE: 93.1102324902354\n",
      "Min Misclassifications: 59\n",
      "Epoch 35: train_loss=0.8217, train_acc=0.9631 | val_loss=0.4330, val_acc=0.9350, val_mis=52\n",
      "Min SSE: 80.7402516009622\n",
      "Min Misclassifications: 52\n",
      "Epoch 40: train_loss=0.7401, train_acc=0.9684 | val_loss=0.3871, val_acc=0.9437, val_mis=45\n",
      "Min SSE: 71.68457555450327\n",
      "Min Misclassifications: 45\n",
      "Epoch 45: train_loss=0.6764, train_acc=0.9718 | val_loss=0.3306, val_acc=0.9400, val_mis=48\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.6231, train_acc=0.9749 | val_loss=0.3261, val_acc=0.9363, val_mis=51\n",
      "  → no improvement for 2/10 epochs\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 60.752787469870015\n",
      "Final Min Misclassifications 45\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[7, 0, 2, 6, 5, 7, 6, 0, 1, 5, 5, 7, 3, 4, 2, 0, 2, 4, 2, 6, 1, 1, 3, 1, 0, 0, 2, 7, 6, 0, 1, 1, 4, 5, 4, 0, 5, 6, 6, 2, 7, 2, 2, 0, 7, 1, 7, 2, 5, 1, 7, 0, 5, 7, 1, 7, 0, 5, 4, 1, 1, 2, 7, 1, 5, 2, 7, 1, 6, 0, 5, 6, 2, 2, 6, 7, 3, 6, 0, 3, 2, 4, 4, 1, 7, 2, 6, 3, 1, 6, 6, 0, 2, 2, 6, 0, 6, 7, 5, 6, 6, 0, 3, 2, 5, 3, 4, 3, 4, 4, 1, 2, 0, 1, 7, 6, 0, 6, 7, 0, 7, 4, 3, 1, 4, 6, 2, 7, 3, 3, 0, 6, 1, 6, 1, 5, 5, 1, 1, 1, 5, 0, 5, 1, 6, 6, 6, 4, 0, 3, 3, 1, 3, 4, 1, 2, 4, 4, 7, 2, 2, 5, 7, 0, 4, 5, 6, 3, 4, 4, 7, 0, 6, 4, 5, 1, 0, 0, 2, 2, 7, 2, 7, 7, 1, 3, 0, 2, 4, 2, 7, 0, 2, 2, 6, 5, 6, 0, 1, 7, 5, 3, 6, 4, 3, 3, 4, 0, 1, 6, 4, 4, 3, 4, 2, 1, 5, 3, 4, 6, 4, 2, 2, 2, 1, 2, 2, 6, 2, 1, 6, 7, 0, 7, 4, 6, 2, 5, 6, 0, 2, 0, 2, 2, 7, 4, 0, 6, 0, 7, 4, 1, 0, 7, 4, 1, 5, 4, 7, 2, 3, 1, 6, 3, 7, 3, 2, 5, 5, 7, 0, 3, 7, 3, 3, 1, 0, 2, 5, 4, 2, 7, 7, 0, 7, 4, 2, 1, 6, 3, 7, 6, 4, 0, 6, 5, 0, 0, 4, 7, 5, 3, 5, 4, 1, 3, 6, 7, 0, 0, 4, 6, 1, 2, 5, 3, 6, 3, 0, 4, 4, 4, 0, 1, 7, 2, 1, 4, 7, 7, 5, 4, 3, 4, 3, 6, 0, 7, 1, 2, 0, 2, 5, 6, 0, 2, 3, 7, 0, 5, 4, 6, 4, 4, 3, 2, 3, 3, 7, 2, 1, 1, 2, 7, 0, 6, 3, 2, 0, 4, 5, 5, 6, 5, 7, 3, 1, 0, 5, 6, 1, 5, 6, 6, 6, 3, 1, 1, 5, 0, 4, 0, 3, 3, 2, 0, 6, 3, 1, 1, 1, 6, 2, 1, 6, 2, 5, 1, 6, 0, 0, 7, 4, 3, 7, 5, 3, 3, 7, 2, 5, 7, 5, 0, 4, 3, 0, 5, 1, 5, 0, 4, 0, 2, 5, 4, 4, 0, 0, 0, 4, 1, 6, 4, 5, 2, 7, 3, 6, 4, 4, 3, 6, 1, 4, 7, 4, 3, 5, 7, 2, 0, 5, 3, 7, 0, 7, 0, 0, 4, 5, 4, 6, 6, 2, 3, 3, 5, 6, 4, 5, 7, 2, 3, 5, 4, 5, 1, 6, 4, 3, 3, 4, 5, 0, 2, 6, 4, 4, 6, 7, 4, 2, 4, 7, 1, 7, 1, 7, 5, 7, 2, 1, 2, 1, 7, 3, 0, 5, 2, 5, 0, 1, 0, 5, 0, 5, 3, 2, 7, 7, 4, 1, 2, 4, 0, 5, 1, 7, 5, 0, 2, 0, 4, 6, 1, 7, 1, 0, 3, 1, 5, 7, 7, 5, 4, 4, 4, 5, 7, 1, 6, 5, 1, 6, 7, 3, 5, 5, 3, 6, 2, 0, 1, 2, 1, 4, 3, 1, 4, 0, 4, 5, 6, 2, 4, 4, 2, 7, 1, 7, 1, 7, 6, 4, 2, 6, 0, 5, 1, 7, 4, 2, 0, 1, 6, 6, 2, 1, 7, 5, 0, 7, 4, 4, 7, 7, 2, 2, 0, 4, 3, 7, 2, 6, 7, 7, 1, 2, 7, 0, 7, 3, 1, 6, 7, 7, 4, 5, 4, 4, 3, 4, 6, 0, 3, 2, 4, 5, 2, 2, 2, 0, 7, 4, 7, 7, 1, 5, 2, 6, 2, 0, 1, 3, 3, 2, 5, 0, 5, 1, 2, 6, 5, 7, 1, 1, 5, 3, 7, 2, 6, 0, 3, 1, 2, 3, 4, 4, 3, 5, 7, 6, 6, 2, 1, 3, 0, 7, 4, 3, 2, 7, 7, 3, 1, 6, 5, 2, 6, 5, 1, 4, 3, 3, 2, 5, 5, 2, 6, 7, 3, 3, 4, 7, 6, 4, 3, 2, 0, 0, 2, 5, 6, 2, 6, 1, 4, 1, 5, 4, 4, 6, 5, 2, 5, 6, 7, 1, 0, 5, 0, 6, 6, 5, 4, 3, 5, 1, 2, 7, 0, 5, 3, 5, 6, 4, 3, 1, 5, 2, 1, 7, 7, 3, 0, 1, 2, 5, 2, 6, 6, 0, 5, 5, 3, 3, 7, 0, 2, 4, 7, 0, 7, 1, 2, 6, 7, 6, 0]\n",
      "New best training duration:  0:00:26\n",
      "Given hidden layer counts and learning rate:  128 64 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 17 ---------\n",
      "h1 = 128\n",
      "h2 = 64\n",
      "{'hidden1': 128, 'hidden2': 64, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.1459, train_acc=0.9440 | val_loss=0.6100, val_acc=0.8988, val_mis=81\n",
      "Min SSE: 119.68637068920378\n",
      "Min Misclassifications: 81\n",
      "Epoch 10: train_loss=0.6792, train_acc=0.9709 | val_loss=0.3558, val_acc=0.9313, val_mis=55\n",
      "Min SSE: 69.79465564889409\n",
      "Min Misclassifications: 55\n",
      "Epoch 15: train_loss=0.4831, train_acc=0.9805 | val_loss=0.2392, val_acc=0.9413, val_mis=47\n",
      "Min SSE: 49.09845991476793\n",
      "Min Misclassifications: 47\n",
      "Epoch 20: train_loss=0.3815, train_acc=0.9851 | val_loss=0.1700, val_acc=0.9637, val_mis=29\n",
      "Min SSE: 36.262948219977474\n",
      "Min Misclassifications: 29\n",
      "Epoch 25: train_loss=0.3125, train_acc=0.9877 | val_loss=0.1773, val_acc=0.9725, val_mis=22\n",
      "Min SSE: 30.55630379542127\n",
      "Min Misclassifications: 22\n",
      "Epoch 30: train_loss=0.2695, train_acc=0.9896 | val_loss=0.1639, val_acc=0.9738, val_mis=21\n",
      "Min SSE: 27.3047510323086\n",
      "Min Misclassifications: 21\n",
      "Epoch 35: train_loss=0.2406, train_acc=0.9910 | val_loss=0.1503, val_acc=0.9825, val_mis=14\n",
      "Min SSE: 23.996724636734584\n",
      "Min Misclassifications: 14\n",
      "Epoch 40: train_loss=0.2120, train_acc=0.9919 | val_loss=0.1173, val_acc=0.9800, val_mis=16\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1907, train_acc=0.9929 | val_loss=0.1030, val_acc=0.9800, val_mis=16\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1778, train_acc=0.9933 | val_loss=0.1130, val_acc=0.9812, val_mis=15\n",
      "  → no improvement for 3/10 epochs\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 18.53458167322715\n",
      "Final Min Misclassifications 14\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[6, 7, 4, 1, 1, 6, 3, 2, 4, 4, 4, 2, 5, 0, 1, 7, 1, 5, 7, 5, 6, 6, 4, 3, 1, 2, 3, 6, 1, 2, 5, 1, 0, 2, 6, 3, 1, 0, 1, 7, 5, 0, 1, 4, 5, 5, 3, 1, 0, 0, 7, 0, 3, 4, 4, 5, 4, 2, 5, 0, 6, 3, 2, 7, 1, 6, 5, 3, 6, 2, 7, 4, 0, 6, 7, 6, 6, 7, 4, 1, 3, 4, 0, 4, 7, 5, 2, 3, 1, 2, 1, 2, 4, 3, 0, 1, 5, 1, 5, 5, 2, 0, 5, 6, 7, 2, 6, 6, 2, 3, 4, 1, 3, 0, 2, 5, 2, 7, 3, 7, 2, 5, 0, 3, 5, 7, 3, 2, 7, 1, 5, 6, 6, 4, 2, 6, 4, 7, 4, 4, 4, 2, 7, 7, 2, 5, 1, 0, 7, 6, 5, 3, 0, 4, 3, 4, 3, 6, 0, 7, 5, 4, 5, 1, 4, 3, 7, 0, 4, 0, 6, 7, 1, 0, 1, 0, 0, 1, 5, 5, 0, 7, 4, 6, 2, 6, 0, 1, 0, 4, 1, 1, 0, 1, 0, 1, 6, 0, 3, 1, 2, 1, 6, 4, 5, 4, 6, 2, 4, 2, 4, 6, 0, 3, 2, 1, 1, 5, 4, 7, 1, 0, 7, 4, 1, 7, 0, 4, 0, 2, 5, 6, 3, 5, 1, 1, 5, 3, 7, 7, 2, 3, 3, 7, 0, 3, 1, 2, 3, 3, 7, 7, 0, 4, 4, 3, 5, 6, 0, 0, 6, 3, 5, 0, 5, 4, 4, 5, 7, 5, 2, 1, 7, 2, 1, 5, 0, 2, 3, 5, 2, 2, 6, 7, 3, 6, 1, 0, 2, 0, 5, 7, 3, 0, 7, 1, 3, 2, 1, 1, 6, 0, 0, 2, 5, 5, 3, 0, 7, 4, 6, 1, 0, 1, 6, 0, 1, 4, 7, 0, 3, 6, 4, 7, 2, 0, 6, 4, 7, 1, 4, 7, 0, 5, 5, 3, 6, 6, 3, 7, 7, 7, 2, 3, 1, 0, 7, 2, 1, 2, 7, 4, 7, 2, 5, 1, 6, 3, 5, 7, 5, 4, 2, 1, 5, 0, 7, 5, 3, 1, 2, 6, 7, 6, 6, 4, 3, 4, 5, 7, 6, 2, 3, 7, 6, 0, 2, 7, 6, 7, 5, 6, 0, 4, 5, 1, 7, 2, 2, 6, 4, 5, 6, 6, 2, 4, 3, 3, 2, 0, 6, 3, 3, 3, 5, 0, 1, 3, 6, 3, 2, 6, 0, 6, 1, 1, 5, 6, 3, 0, 2, 7, 3, 3, 2, 5, 1, 3, 7, 6, 0, 1, 1, 4, 6, 6, 0, 1, 2, 5, 5, 2, 3, 6, 6, 4, 4, 3, 7, 4, 0, 7, 3, 7, 2, 2, 6, 1, 7, 7, 3, 4, 7, 0, 3, 3, 0, 7, 4, 3, 1, 2, 4, 7, 6, 5, 1, 5, 5, 7, 5, 0, 3, 3, 5, 4, 6, 7, 3, 6, 7, 3, 4, 0, 4, 2, 2, 3, 6, 0, 5, 7, 0, 2, 0, 5, 7, 5, 0, 0, 7, 5, 3, 3, 6, 3, 2, 7, 1, 5, 3, 7, 5, 6, 1, 5, 5, 7, 1, 4, 0, 2, 4, 3, 0, 4, 7, 4, 1, 3, 7, 0, 0, 7, 4, 2, 3, 1, 5, 5, 7, 0, 2, 3, 3, 0, 5, 0, 1, 7, 6, 5, 2, 3, 4, 5, 5, 6, 5, 1, 0, 5, 1, 2, 7, 3, 7, 7, 0, 7, 2, 0, 2, 7, 6, 6, 5, 3, 5, 3, 0, 4, 0, 0, 0, 4, 7, 0, 1, 2, 0, 2, 6, 4, 2, 7, 7, 6, 0, 6, 5, 2, 5, 6, 1, 7, 7, 4, 5, 5, 1, 5, 5, 4, 1, 3, 2, 7, 0, 0, 0, 0, 4, 3, 3, 6, 7, 6, 4, 3, 0, 3, 0, 7, 4, 2, 2, 4, 2, 1, 5, 3, 2, 5, 4, 6, 4, 1, 0, 6, 7, 0, 5, 6, 5, 5, 3, 5, 6, 0, 1, 3, 4, 2, 4, 7, 2, 5, 0, 0, 7, 7, 7, 5, 3, 3, 4, 1, 6, 1, 2, 5, 7, 5, 0, 2, 3, 5, 2, 1, 2, 3, 2, 6, 1, 4, 4, 2, 2, 2, 5, 4, 1, 2, 3, 2, 0, 0, 5, 7, 7, 5, 7, 0, 4, 2, 0, 2, 6, 6, 7, 5, 2, 6, 2, 1, 7, 7, 7, 0, 1, 2, 1, 4, 7, 6, 4, 4, 2, 3, 2, 4, 2, 3, 3, 7, 6, 0, 0, 1, 1, 3, 5, 5, 1, 7, 0, 4, 5, 7, 6, 2, 1, 2, 2, 2, 4, 6, 4, 6, 4, 6, 4, 4, 2, 6, 5, 5, 3, 5]\n",
      "New best training duration:  0:00:25\n",
      "Given hidden layer counts and learning rate:  128 64 0.005\n",
      "--------- Config 18 ---------\n",
      "h1 = 128\n",
      "h2 = 64\n",
      "{'hidden1': 128, 'hidden2': 64, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.7475, train_acc=0.9676 | val_loss=0.4110, val_acc=0.9250, val_mis=60\n",
      "Min SSE: 76.53942372294239\n",
      "Min Misclassifications: 60\n",
      "Epoch 10: train_loss=0.4400, train_acc=0.9816 | val_loss=0.2404, val_acc=0.9525, val_mis=38\n",
      "Min SSE: 45.27856826224126\n",
      "Min Misclassifications: 38\n",
      "Epoch 15: train_loss=0.3192, train_acc=0.9875 | val_loss=0.2088, val_acc=0.9625, val_mis=30\n",
      "Min SSE: 38.26984950205571\n",
      "Min Misclassifications: 30\n",
      "Epoch 20: train_loss=0.2618, train_acc=0.9894 | val_loss=0.2107, val_acc=0.9688, val_mis=25\n",
      "Min SSE: 33.88454572676505\n",
      "Min Misclassifications: 25\n",
      "Epoch 25: train_loss=0.2184, train_acc=0.9910 | val_loss=0.0938, val_acc=0.9788, val_mis=17\n",
      "Min SSE: 19.44228161526337\n",
      "Min Misclassifications: 17\n",
      "Epoch 30: train_loss=0.1957, train_acc=0.9920 | val_loss=0.0932, val_acc=0.9862, val_mis=11\n",
      "Min SSE: 15.102614856434347\n",
      "Min Misclassifications: 11\n",
      "Epoch 35: train_loss=0.1728, train_acc=0.9930 | val_loss=0.0588, val_acc=0.9875, val_mis=10\n",
      "Min SSE: 13.563370716159174\n",
      "Min Misclassifications: 10\n",
      "Epoch 40: train_loss=0.1572, train_acc=0.9936 | val_loss=0.0631, val_acc=0.9925, val_mis=6\n",
      "Min SSE: 11.069715212550243\n",
      "Min Misclassifications: 6\n",
      "Epoch 45: train_loss=0.1383, train_acc=0.9945 | val_loss=0.0903, val_acc=0.9825, val_mis=14\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.1353, train_acc=0.9945 | val_loss=0.0893, val_acc=0.9762, val_mis=19\n",
      "  → no improvement for 2/10 epochs\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 11.069715212550243\n",
      "Final Min Misclassifications 6\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[4, 3, 0, 4, 4, 5, 6, 7, 4, 2, 4, 1, 0, 7, 5, 6, 4, 2, 2, 4, 4, 1, 5, 0, 4, 5, 1, 0, 0, 4, 5, 2, 2, 4, 5, 4, 2, 6, 6, 0, 4, 0, 3, 4, 2, 3, 7, 5, 0, 1, 6, 4, 2, 3, 0, 7, 0, 7, 6, 7, 0, 2, 1, 4, 6, 2, 2, 5, 6, 2, 4, 3, 7, 6, 5, 1, 6, 3, 5, 4, 2, 6, 0, 0, 2, 6, 1, 7, 0, 3, 4, 3, 3, 3, 0, 4, 2, 4, 6, 3, 4, 0, 7, 7, 0, 1, 4, 6, 6, 0, 1, 3, 4, 2, 1, 2, 2, 3, 6, 6, 7, 6, 2, 7, 0, 2, 3, 2, 2, 3, 7, 5, 1, 2, 4, 5, 5, 7, 5, 6, 2, 2, 5, 2, 5, 3, 4, 7, 2, 0, 6, 7, 4, 5, 0, 1, 0, 6, 4, 2, 2, 2, 3, 7, 6, 7, 6, 5, 2, 7, 7, 1, 5, 2, 4, 5, 0, 1, 0, 7, 6, 1, 0, 7, 7, 4, 5, 4, 0, 1, 3, 5, 4, 4, 5, 1, 4, 2, 7, 6, 7, 1, 5, 0, 4, 3, 5, 1, 2, 4, 0, 2, 2, 6, 4, 3, 1, 1, 0, 7, 0, 3, 7, 1, 0, 0, 5, 4, 6, 4, 4, 0, 7, 1, 7, 1, 5, 6, 3, 1, 7, 3, 5, 0, 4, 0, 6, 2, 0, 4, 5, 7, 7, 2, 5, 7, 4, 4, 3, 5, 5, 6, 4, 1, 7, 5, 7, 6, 6, 5, 1, 1, 1, 1, 5, 1, 4, 0, 4, 5, 3, 6, 3, 1, 1, 3, 3, 6, 5, 5, 6, 5, 3, 2, 2, 0, 0, 6, 2, 1, 1, 1, 3, 6, 3, 1, 7, 5, 0, 7, 5, 7, 7, 7, 5, 0, 2, 7, 7, 3, 2, 6, 2, 5, 6, 2, 5, 0, 2, 3, 4, 1, 3, 7, 5, 5, 5, 5, 6, 0, 6, 3, 5, 1, 4, 0, 2, 5, 0, 1, 0, 6, 0, 7, 6, 4, 1, 0, 7, 1, 0, 3, 7, 2, 7, 2, 1, 5, 5, 5, 0, 4, 2, 4, 7, 4, 5, 5, 0, 1, 3, 7, 0, 3, 0, 4, 7, 7, 5, 4, 2, 1, 4, 0, 1, 1, 3, 4, 1, 6, 0, 3, 0, 3, 3, 4, 4, 0, 7, 3, 6, 2, 0, 4, 4, 5, 2, 6, 6, 5, 4, 1, 7, 1, 6, 3, 6, 7, 2, 7, 6, 5, 2, 0, 5, 0, 4, 7, 5, 2, 2, 0, 5, 6, 5, 4, 7, 6, 4, 5, 3, 5, 0, 0, 2, 2, 2, 7, 6, 4, 1, 2, 1, 4, 6, 7, 0, 6, 5, 1, 0, 6, 4, 1, 1, 5, 6, 7, 7, 0, 3, 7, 0, 2, 7, 6, 7, 6, 4, 7, 7, 1, 3, 2, 5, 6, 1, 3, 3, 5, 0, 5, 5, 5, 4, 1, 0, 1, 5, 7, 3, 1, 2, 3, 4, 1, 3, 3, 0, 4, 5, 3, 2, 6, 3, 7, 7, 0, 1, 1, 7, 3, 4, 3, 4, 2, 1, 7, 1, 2, 7, 1, 2, 6, 5, 2, 2, 7, 4, 2, 3, 6, 7, 6, 2, 4, 7, 5, 1, 5, 0, 2, 0, 1, 4, 1, 7, 7, 5, 3, 6, 0, 5, 7, 2, 4, 5, 2, 0, 0, 4, 0, 5, 6, 4, 7, 7, 0, 5, 4, 4, 0, 6, 3, 1, 2, 7, 3, 1, 7, 6, 5, 7, 3, 5, 0, 3, 5, 3, 6, 3, 2, 5, 5, 2, 2, 3, 0, 1, 5, 4, 2, 7, 1, 0, 3, 6, 4, 4, 2, 6, 5, 7, 2, 7, 7, 2, 0, 2, 2, 4, 4, 2, 5, 2, 3, 2, 4, 6, 2, 7, 6, 2, 0, 7, 2, 7, 7, 1, 5, 0, 5, 0, 0, 5, 3, 5, 2, 7, 2, 6, 5, 7, 6, 5, 3, 3, 1, 4, 7, 7, 2, 0, 7, 3, 1, 3, 7, 7, 5, 2, 4, 6, 1, 7, 5, 3, 5, 1, 6, 0, 6, 6, 7, 5, 3, 0, 6, 2, 4, 7, 1, 2, 7, 6, 6, 0, 7, 1, 2, 5, 4, 6, 3, 7, 2, 5, 0, 0, 2, 0, 2, 0, 3, 2, 4, 1, 3, 5, 3, 4, 5, 0, 3, 6, 6, 2, 2, 4, 6, 4, 1, 1, 7, 2, 5, 0, 7, 7, 5, 7, 0, 5, 1, 5, 1, 7, 6, 2, 7, 0, 7, 6, 1, 1, 2, 1, 4, 1, 4, 0, 5, 0, 7, 1, 4, 0, 3, 1, 7, 6, 7, 0, 2, 6, 3, 1, 7, 7, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 19 ---------\n",
      "h1 = 128\n",
      "h2 = 16\n",
      "{'hidden1': 128, 'hidden2': 16, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.3292, train_acc=0.8905 | val_loss=1.4491, val_acc=0.6425, val_mis=286\n",
      "Min SSE: 263.6842233658922\n",
      "Min Misclassifications: 286\n",
      "Epoch 10: train_loss=1.8861, train_acc=0.9036 | val_loss=1.1365, val_acc=0.7850, val_mis=172\n",
      "Min SSE: 214.06794934683697\n",
      "Min Misclassifications: 172\n",
      "Epoch 15: train_loss=1.5562, train_acc=0.9224 | val_loss=0.9275, val_acc=0.8013, val_mis=159\n",
      "Min SSE: 174.58199852439748\n",
      "Min Misclassifications: 159\n",
      "Epoch 20: train_loss=1.3132, train_acc=0.9368 | val_loss=0.7779, val_acc=0.8500, val_mis=120\n",
      "Min SSE: 146.37292645616816\n",
      "Min Misclassifications: 120\n",
      "Epoch 25: train_loss=1.1272, train_acc=0.9453 | val_loss=0.6584, val_acc=0.8750, val_mis=100\n",
      "Min SSE: 124.4556421878243\n",
      "Min Misclassifications: 100\n",
      "Epoch 30: train_loss=0.9799, train_acc=0.9528 | val_loss=0.5301, val_acc=0.9087, val_mis=73\n",
      "Min SSE: 104.49794027209826\n",
      "Min Misclassifications: 73\n",
      "Epoch 35: train_loss=0.8632, train_acc=0.9605 | val_loss=0.5099, val_acc=0.9187, val_mis=65\n",
      "Min SSE: 93.66005502741467\n",
      "Min Misclassifications: 65\n",
      "Epoch 40: train_loss=0.7718, train_acc=0.9669 | val_loss=0.4381, val_acc=0.9263, val_mis=59\n",
      "Min SSE: 81.73924862788232\n",
      "Min Misclassifications: 59\n",
      "Epoch 45: train_loss=0.7006, train_acc=0.9708 | val_loss=0.4026, val_acc=0.9387, val_mis=49\n",
      "Min SSE: 73.91935846699222\n",
      "Min Misclassifications: 49\n",
      "Epoch 50: train_loss=0.6438, train_acc=0.9739 | val_loss=0.3734, val_acc=0.9413, val_mis=47\n",
      "Min SSE: 68.81694765572877\n",
      "Min Misclassifications: 47\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 68.81694765572877\n",
      "Final Min Misclassifications 47\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[3, 5, 5, 5, 1, 6, 6, 4, 4, 5, 6, 3, 2, 4, 4, 1, 0, 1, 2, 3, 5, 0, 4, 0, 2, 1, 7, 1, 0, 5, 7, 6, 7, 1, 2, 2, 0, 0, 1, 2, 2, 4, 2, 2, 1, 7, 3, 2, 7, 1, 1, 7, 2, 6, 0, 5, 2, 3, 0, 0, 3, 6, 2, 5, 2, 0, 5, 0, 6, 4, 4, 3, 6, 2, 7, 7, 0, 4, 5, 4, 3, 1, 7, 1, 7, 7, 7, 0, 0, 2, 3, 6, 5, 7, 5, 3, 7, 3, 4, 3, 2, 0, 2, 0, 0, 7, 3, 5, 7, 4, 3, 6, 0, 3, 5, 0, 7, 5, 7, 4, 1, 3, 5, 0, 0, 4, 4, 3, 6, 2, 7, 5, 5, 6, 5, 0, 1, 0, 2, 6, 2, 0, 6, 5, 5, 4, 6, 6, 4, 6, 2, 1, 0, 0, 4, 7, 6, 1, 6, 5, 7, 7, 6, 6, 0, 3, 1, 7, 2, 6, 2, 1, 7, 6, 6, 6, 5, 5, 0, 3, 7, 1, 0, 0, 3, 0, 3, 4, 0, 4, 5, 5, 5, 4, 6, 7, 3, 3, 5, 5, 7, 6, 6, 5, 0, 6, 4, 2, 5, 7, 3, 1, 4, 3, 2, 2, 0, 5, 1, 5, 2, 0, 3, 1, 6, 6, 5, 2, 7, 1, 7, 2, 3, 2, 2, 6, 5, 0, 6, 1, 2, 4, 1, 2, 3, 3, 5, 4, 1, 2, 5, 5, 1, 2, 0, 4, 7, 0, 2, 3, 5, 6, 0, 4, 2, 5, 3, 1, 0, 5, 3, 6, 2, 1, 5, 3, 6, 3, 2, 3, 2, 1, 3, 4, 4, 6, 7, 6, 1, 4, 5, 0, 4, 0, 1, 0, 6, 6, 0, 0, 5, 6, 7, 5, 2, 7, 6, 3, 7, 0, 1, 1, 4, 4, 3, 0, 6, 0, 2, 3, 5, 0, 5, 0, 1, 1, 0, 0, 2, 6, 6, 5, 7, 7, 2, 1, 0, 5, 1, 5, 5, 3, 5, 5, 3, 6, 7, 6, 7, 6, 3, 5, 2, 6, 0, 1, 3, 5, 6, 5, 7, 0, 7, 2, 0, 3, 5, 6, 5, 4, 5, 1, 2, 2, 4, 7, 2, 5, 6, 4, 3, 0, 6, 7, 2, 7, 3, 6, 0, 7, 5, 3, 4, 0, 7, 7, 0, 4, 4, 4, 6, 4, 7, 4, 0, 7, 4, 1, 3, 5, 4, 4, 0, 5, 3, 2, 5, 2, 4, 2, 1, 7, 4, 4, 2, 7, 5, 4, 6, 7, 5, 0, 0, 4, 4, 4, 4, 3, 4, 5, 4, 4, 0, 2, 7, 5, 0, 2, 7, 4, 1, 3, 0, 7, 5, 4, 0, 0, 3, 4, 6, 5, 7, 3, 4, 3, 7, 1, 6, 7, 0, 0, 1, 0, 0, 5, 1, 3, 0, 5, 2, 3, 2, 1, 0, 0, 0, 6, 4, 7, 1, 2, 2, 4, 6, 5, 5, 5, 3, 4, 0, 2, 4, 6, 3, 0, 1, 7, 5, 7, 5, 1, 6, 6, 4, 6, 4, 3, 4, 3, 7, 5, 3, 2, 5, 2, 1, 1, 4, 2, 2, 6, 3, 5, 4, 4, 1, 0, 0, 4, 4, 4, 4, 1, 4, 4, 7, 5, 5, 3, 3, 6, 5, 6, 1, 3, 0, 3, 7, 2, 5, 6, 5, 2, 7, 1, 0, 5, 6, 0, 6, 4, 1, 4, 2, 2, 2, 3, 7, 4, 7, 5, 5, 1, 6, 0, 7, 0, 3, 4, 1, 1, 5, 4, 5, 7, 6, 1, 3, 3, 4, 2, 4, 1, 7, 1, 6, 1, 4, 5, 3, 1, 6, 2, 3, 7, 0, 6, 0, 4, 2, 2, 6, 3, 3, 7, 6, 1, 6, 1, 1, 4, 2, 1, 2, 6, 6, 5, 0, 0, 7, 2, 0, 7, 5, 1, 1, 7, 0, 3, 7, 0, 7, 1, 0, 6, 7, 7, 5, 1, 4, 2, 2, 0, 1, 3, 7, 1, 7, 0, 4, 5, 7, 4, 3, 2, 1, 1, 7, 3, 5, 2, 3, 7, 2, 6, 7, 3, 0, 3, 3, 0, 5, 1, 4, 5, 6, 5, 3, 0, 6, 3, 3, 4, 4, 3, 5, 1, 5, 4, 6, 1, 2, 5, 4, 6, 3, 1, 0, 4, 1, 5, 3, 2, 0, 5, 3, 5, 1, 2, 3, 5, 2, 7, 6, 2, 0, 7, 0, 4, 5, 6, 4, 2, 7, 1, 6, 2, 6, 1, 3, 6, 7, 0, 3, 6, 3, 4, 2, 2, 3, 0, 2, 6, 5, 7, 5, 1, 5, 4, 1, 4, 3, 4, 3, 5, 2, 1, 7, 4, 6, 3, 6, 0, 3, 4, 7, 0, 3, 0, 4, 0, 7, 4, 2, 2, 0, 4, 0, 5]\n",
      "New best training duration:  0:00:24\n",
      "Given hidden layer counts and learning rate:  128 16 0.001\n",
      "--------- Config 20 ---------\n",
      "h1 = 128\n",
      "h2 = 16\n",
      "{'hidden1': 128, 'hidden2': 16, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.2694, train_acc=0.9394 | val_loss=0.6712, val_acc=0.8462, val_mis=123\n",
      "Min SSE: 131.24346430631297\n",
      "Min Misclassifications: 123\n",
      "Epoch 10: train_loss=0.7345, train_acc=0.9691 | val_loss=0.4114, val_acc=0.9137, val_mis=69\n",
      "Min SSE: 73.7836363534424\n",
      "Min Misclassifications: 69\n",
      "Epoch 15: train_loss=0.5296, train_acc=0.9785 | val_loss=0.3124, val_acc=0.9375, val_mis=50\n",
      "Min SSE: 53.363944730187654\n",
      "Min Misclassifications: 50\n",
      "Epoch 20: train_loss=0.4119, train_acc=0.9839 | val_loss=0.2277, val_acc=0.9487, val_mis=41\n",
      "Min SSE: 41.83775590067625\n",
      "Min Misclassifications: 41\n",
      "Epoch 25: train_loss=0.3401, train_acc=0.9868 | val_loss=0.1787, val_acc=0.9613, val_mis=31\n",
      "Min SSE: 31.141742346511258\n",
      "Min Misclassifications: 31\n",
      "Epoch 30: train_loss=0.2843, train_acc=0.9895 | val_loss=0.1731, val_acc=0.9675, val_mis=26\n",
      "Min SSE: 28.813806395978304\n",
      "Min Misclassifications: 26\n",
      "Epoch 35: train_loss=0.2473, train_acc=0.9911 | val_loss=0.1356, val_acc=0.9738, val_mis=21\n",
      "Min SSE: 24.607549861343152\n",
      "Min Misclassifications: 21\n",
      "Epoch 40: train_loss=0.2258, train_acc=0.9917 | val_loss=0.1395, val_acc=0.9750, val_mis=20\n",
      "Min SSE: 22.296159285353447\n",
      "Min Misclassifications: 20\n",
      "Epoch 45: train_loss=0.1994, train_acc=0.9928 | val_loss=0.1157, val_acc=0.9762, val_mis=19\n",
      "Min SSE: 19.3019417301146\n",
      "Min Misclassifications: 19\n",
      "Epoch 50: train_loss=0.1801, train_acc=0.9936 | val_loss=0.1133, val_acc=0.9800, val_mis=16\n",
      "Min SSE: 18.14276896815818\n",
      "Min Misclassifications: 16\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 18.14276896815818\n",
      "Final Min Misclassifications 16\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[2, 4, 3, 2, 4, 6, 4, 5, 1, 0, 2, 3, 1, 4, 6, 2, 7, 4, 4, 1, 5, 3, 5, 0, 6, 2, 6, 5, 0, 6, 0, 7, 0, 6, 6, 7, 7, 6, 2, 2, 6, 1, 2, 7, 5, 1, 7, 7, 7, 2, 1, 2, 3, 5, 5, 2, 7, 6, 0, 6, 2, 2, 2, 7, 0, 7, 2, 3, 6, 0, 4, 5, 6, 7, 6, 7, 6, 5, 5, 4, 2, 4, 2, 7, 5, 0, 3, 7, 6, 3, 1, 4, 0, 0, 4, 0, 6, 4, 7, 3, 3, 5, 3, 2, 5, 1, 5, 2, 1, 1, 0, 6, 7, 7, 4, 7, 4, 0, 0, 6, 3, 1, 1, 2, 1, 7, 2, 4, 5, 1, 3, 0, 5, 4, 0, 4, 7, 6, 6, 3, 0, 4, 5, 1, 3, 1, 7, 3, 2, 4, 5, 4, 3, 4, 0, 6, 7, 0, 0, 6, 2, 3, 3, 4, 7, 6, 7, 6, 5, 5, 2, 1, 7, 6, 1, 4, 7, 1, 7, 5, 1, 5, 6, 6, 1, 6, 7, 6, 0, 7, 2, 6, 0, 4, 2, 6, 3, 3, 1, 3, 6, 1, 5, 1, 0, 5, 7, 3, 4, 3, 7, 6, 6, 5, 2, 7, 2, 0, 7, 4, 2, 4, 3, 0, 0, 1, 3, 6, 1, 3, 1, 0, 2, 2, 0, 1, 6, 3, 3, 4, 5, 5, 7, 6, 7, 4, 7, 1, 3, 0, 2, 2, 7, 4, 7, 0, 1, 2, 4, 4, 1, 2, 5, 6, 0, 3, 5, 7, 5, 0, 2, 5, 0, 7, 3, 6, 0, 5, 6, 5, 0, 6, 7, 7, 5, 1, 5, 7, 7, 7, 7, 1, 1, 5, 4, 2, 7, 4, 7, 4, 7, 7, 3, 3, 1, 1, 3, 2, 7, 1, 1, 4, 0, 4, 2, 1, 2, 2, 7, 6, 3, 5, 3, 0, 3, 2, 2, 5, 3, 2, 5, 7, 0, 5, 4, 1, 7, 3, 0, 0, 0, 6, 2, 1, 1, 2, 2, 0, 3, 3, 1, 4, 4, 1, 2, 4, 6, 6, 1, 5, 1, 5, 7, 0, 7, 0, 3, 6, 4, 2, 1, 2, 2, 4, 4, 5, 0, 6, 6, 6, 3, 4, 6, 7, 4, 4, 2, 2, 0, 7, 3, 3, 5, 6, 4, 5, 6, 3, 7, 7, 1, 2, 0, 4, 3, 1, 1, 0, 4, 0, 7, 2, 1, 3, 4, 0, 5, 2, 4, 0, 4, 6, 0, 0, 0, 4, 1, 1, 0, 1, 1, 2, 0, 6, 4, 6, 7, 4, 3, 0, 2, 6, 5, 1, 2, 0, 5, 7, 3, 7, 4, 0, 2, 2, 6, 0, 3, 2, 4, 5, 5, 1, 5, 5, 7, 6, 4, 7, 6, 0, 5, 6, 5, 2, 5, 1, 4, 2, 0, 0, 1, 6, 7, 6, 4, 4, 2, 5, 0, 1, 3, 0, 7, 7, 4, 6, 6, 5, 1, 2, 2, 5, 1, 1, 3, 3, 3, 5, 5, 4, 2, 0, 3, 1, 5, 6, 4, 4, 3, 1, 2, 5, 5, 4, 6, 5, 3, 3, 7, 5, 7, 3, 1, 4, 7, 3, 5, 1, 6, 4, 0, 2, 1, 1, 6, 7, 0, 2, 0, 4, 7, 4, 7, 5, 5, 6, 2, 3, 1, 3, 1, 4, 0, 7, 6, 1, 7, 4, 4, 0, 5, 1, 4, 2, 7, 5, 6, 3, 0, 4, 4, 4, 3, 1, 1, 3, 6, 2, 2, 4, 0, 2, 1, 0, 4, 6, 2, 6, 6, 0, 1, 3, 1, 2, 4, 1, 0, 2, 2, 2, 4, 3, 3, 1, 7, 0, 4, 5, 4, 6, 4, 4, 1, 6, 7, 7, 1, 4, 6, 4, 3, 7, 5, 1, 2, 7, 4, 3, 4, 0, 3, 0, 5, 7, 6, 6, 6, 4, 4, 2, 3, 0, 3, 2, 4, 4, 0, 4, 4, 4, 7, 2, 0, 0, 1, 2, 0, 4, 5, 3, 5, 5, 2, 3, 7, 2, 4, 4, 1, 5, 7, 6, 6, 4, 6, 2, 0, 3, 7, 6, 3, 3, 4, 5, 0, 1, 5, 6, 5, 6, 7, 4, 5, 2, 6, 7, 6, 7, 3, 5, 6, 4, 2, 6, 2, 1, 3, 0, 2, 6, 7, 2, 0, 5, 0, 7, 0, 7, 3, 6, 7, 4, 7, 5, 2, 7, 1, 6, 1, 2, 4, 4, 2, 3, 2, 2, 1, 7, 6, 4, 1, 5, 0, 5, 1, 3, 0, 7, 5, 5, 3, 5, 3, 4, 0, 1, 5, 0, 0, 0, 0, 1, 7, 5, 7, 6, 5, 7, 4, 3, 0, 3, 0, 5, 0, 1, 6, 6, 2, 4, 2, 4, 2, 7, 6, 6, 0, 1, 4, 2]\n",
      "New best training duration:  0:00:23\n",
      "Given hidden layer counts and learning rate:  128 16 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 21 ---------\n",
      "h1 = 128\n",
      "h2 = 16\n",
      "{'hidden1': 128, 'hidden2': 16, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.8282, train_acc=0.9631 | val_loss=0.4358, val_acc=0.9025, val_mis=78\n",
      "Min SSE: 82.48727826359477\n",
      "Min Misclassifications: 78\n",
      "Epoch 10: train_loss=0.4467, train_acc=0.9817 | val_loss=0.2639, val_acc=0.9350, val_mis=52\n",
      "Min SSE: 50.18404520129719\n",
      "Min Misclassifications: 52\n",
      "Epoch 15: train_loss=0.3082, train_acc=0.9882 | val_loss=0.2438, val_acc=0.9337, val_mis=53\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 20: train_loss=0.2439, train_acc=0.9904 | val_loss=0.1603, val_acc=0.9650, val_mis=28\n",
      "Min SSE: 28.16311705086367\n",
      "Min Misclassifications: 28\n",
      "Epoch 25: train_loss=0.2125, train_acc=0.9916 | val_loss=0.1418, val_acc=0.9762, val_mis=19\n",
      "Min SSE: 23.400286244400082\n",
      "Min Misclassifications: 19\n",
      "Epoch 30: train_loss=0.1764, train_acc=0.9932 | val_loss=0.1600, val_acc=0.9587, val_mis=33\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 35: train_loss=0.1584, train_acc=0.9937 | val_loss=0.1049, val_acc=0.9812, val_mis=15\n",
      "Min SSE: 16.56720756408985\n",
      "Min Misclassifications: 15\n",
      "Epoch 40: train_loss=0.1447, train_acc=0.9943 | val_loss=0.1315, val_acc=0.9788, val_mis=17\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1332, train_acc=0.9950 | val_loss=0.1119, val_acc=0.9788, val_mis=17\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1124, train_acc=0.9961 | val_loss=0.0979, val_acc=0.9800, val_mis=16\n",
      "  → no improvement for 3/10 epochs\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 14.298437562917567\n",
      "Final Min Misclassifications 15\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[1, 3, 0, 0, 3, 3, 5, 6, 0, 3, 6, 3, 6, 5, 0, 4, 1, 0, 4, 3, 2, 6, 0, 0, 5, 4, 7, 2, 4, 0, 4, 6, 4, 7, 3, 6, 0, 0, 1, 3, 7, 6, 6, 1, 4, 4, 4, 5, 2, 7, 4, 4, 4, 4, 4, 6, 7, 2, 1, 5, 2, 7, 2, 4, 3, 7, 2, 4, 0, 5, 5, 3, 7, 4, 0, 2, 7, 4, 0, 4, 1, 5, 5, 5, 2, 3, 5, 7, 2, 5, 1, 6, 4, 7, 2, 2, 5, 6, 7, 7, 4, 4, 0, 2, 7, 7, 3, 0, 6, 6, 1, 0, 5, 3, 0, 6, 7, 3, 0, 2, 6, 2, 7, 7, 3, 7, 0, 5, 3, 2, 5, 0, 7, 4, 1, 0, 7, 5, 5, 2, 6, 1, 7, 0, 0, 7, 6, 0, 4, 6, 7, 5, 4, 1, 6, 0, 3, 3, 5, 3, 4, 6, 3, 1, 1, 0, 3, 4, 6, 6, 0, 0, 2, 4, 0, 5, 1, 5, 5, 7, 2, 7, 6, 4, 1, 4, 3, 3, 4, 4, 7, 5, 7, 1, 6, 0, 0, 5, 2, 0, 2, 3, 3, 2, 7, 0, 1, 2, 1, 5, 5, 5, 1, 5, 0, 6, 7, 0, 7, 5, 2, 5, 4, 5, 3, 3, 6, 7, 7, 2, 6, 7, 0, 7, 2, 3, 1, 7, 6, 1, 6, 7, 4, 7, 7, 5, 1, 6, 0, 2, 0, 7, 4, 7, 6, 1, 7, 6, 5, 1, 4, 5, 3, 3, 7, 4, 0, 3, 2, 6, 0, 1, 7, 1, 3, 3, 4, 2, 3, 6, 3, 7, 4, 3, 3, 5, 6, 2, 2, 0, 5, 2, 0, 6, 4, 6, 6, 2, 6, 7, 3, 2, 1, 0, 4, 6, 6, 2, 7, 7, 4, 5, 0, 6, 7, 7, 6, 3, 5, 0, 6, 7, 2, 3, 6, 5, 1, 3, 6, 1, 2, 7, 0, 7, 5, 6, 5, 6, 4, 0, 4, 7, 2, 3, 0, 6, 5, 5, 3, 3, 1, 3, 0, 7, 6, 4, 4, 2, 0, 3, 0, 0, 7, 7, 3, 5, 6, 6, 7, 1, 3, 3, 7, 4, 1, 1, 2, 1, 4, 2, 1, 3, 5, 6, 7, 0, 6, 0, 6, 0, 6, 4, 3, 2, 5, 0, 7, 7, 0, 1, 7, 7, 6, 7, 5, 2, 6, 4, 5, 0, 2, 3, 5, 0, 4, 2, 2, 2, 0, 1, 3, 6, 0, 5, 1, 3, 1, 4, 1, 4, 3, 2, 0, 1, 4, 5, 4, 2, 1, 7, 3, 2, 7, 1, 1, 2, 2, 6, 7, 7, 1, 0, 6, 0, 5, 5, 7, 3, 2, 2, 4, 6, 5, 2, 3, 1, 5, 1, 1, 4, 1, 1, 3, 2, 5, 6, 2, 1, 5, 0, 0, 7, 2, 6, 7, 3, 2, 7, 4, 6, 7, 4, 0, 2, 5, 1, 3, 4, 2, 4, 0, 3, 4, 6, 4, 2, 1, 3, 6, 0, 5, 4, 4, 0, 6, 7, 4, 5, 1, 0, 4, 4, 3, 3, 3, 4, 4, 3, 6, 3, 0, 0, 2, 1, 6, 7, 1, 7, 4, 0, 3, 5, 0, 2, 4, 4, 7, 0, 2, 4, 5, 5, 5, 0, 7, 4, 4, 0, 6, 0, 5, 3, 0, 1, 1, 7, 3, 1, 7, 4, 5, 4, 1, 0, 6, 5, 0, 2, 4, 5, 1, 6, 3, 4, 4, 7, 4, 5, 6, 5, 7, 0, 0, 0, 3, 5, 5, 3, 0, 2, 7, 7, 2, 7, 3, 1, 0, 3, 0, 4, 5, 0, 3, 2, 2, 5, 0, 5, 2, 4, 1, 4, 1, 6, 1, 4, 7, 2, 3, 6, 4, 7, 4, 0, 4, 6, 1, 4, 5, 1, 4, 1, 7, 6, 3, 0, 6, 6, 1, 5, 0, 5, 5, 7, 2, 3, 5, 2, 3, 5, 4, 0, 7, 1, 5, 5, 0, 7, 3, 4, 7, 5, 1, 2, 0, 1, 6, 0, 6, 6, 6, 5, 3, 3, 4, 0, 4, 7, 4, 7, 6, 6, 2, 7, 2, 0, 1, 4, 7, 2, 4, 6, 4, 7, 0, 3, 6, 0, 6, 1, 4, 7, 6, 2, 0, 2, 3, 6, 4, 5, 3, 0, 3, 6, 0, 5, 0, 4, 1, 0, 0, 4, 2, 2, 1, 3, 6, 1, 7, 5, 6, 1, 4, 7, 0, 7, 4, 7, 4, 7, 7, 5, 1, 1, 4, 6, 4, 6, 4, 4, 0, 2, 5, 5, 3, 4, 5, 7, 4, 7, 1, 4, 5, 5, 3, 0, 2, 7, 4, 2, 4, 1, 0, 6, 1, 5, 2, 5, 3, 4, 2, 0, 5, 0, 7, 4, 7, 0, 0, 3]\n",
      "--------- Config 22 ---------\n",
      "h1 = 32\n",
      "h2 = 16\n",
      "{'hidden1': 32, 'hidden2': 16, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.5228, train_acc=0.8794 | val_loss=1.6187, val_acc=0.6088, val_mis=313\n",
      "Min SSE: 292.59489749436204\n",
      "Min Misclassifications: 313\n",
      "Epoch 10: train_loss=1.9902, train_acc=0.8996 | val_loss=1.2302, val_acc=0.6887, val_mis=249\n",
      "Min SSE: 235.96232001834568\n",
      "Min Misclassifications: 249\n",
      "Epoch 15: train_loss=1.6725, train_acc=0.9160 | val_loss=1.0345, val_acc=0.7462, val_mis=203\n",
      "Min SSE: 201.3125408106124\n",
      "Min Misclassifications: 203\n",
      "Epoch 20: train_loss=1.4579, train_acc=0.9281 | val_loss=0.8997, val_acc=0.7987, val_mis=161\n",
      "Min SSE: 175.870688077554\n",
      "Min Misclassifications: 161\n",
      "Epoch 25: train_loss=1.2837, train_acc=0.9385 | val_loss=0.7874, val_acc=0.8225, val_mis=142\n",
      "Min SSE: 153.00819257660493\n",
      "Min Misclassifications: 142\n",
      "Epoch 30: train_loss=1.1374, train_acc=0.9460 | val_loss=0.6899, val_acc=0.8550, val_mis=116\n",
      "Min SSE: 134.20437567415593\n",
      "Min Misclassifications: 116\n",
      "Epoch 35: train_loss=1.0149, train_acc=0.9538 | val_loss=0.6273, val_acc=0.8812, val_mis=95\n",
      "Min SSE: 118.6663794468939\n",
      "Min Misclassifications: 95\n",
      "Epoch 40: train_loss=0.9121, train_acc=0.9600 | val_loss=0.5455, val_acc=0.9025, val_mis=78\n",
      "Min SSE: 105.08894735066048\n",
      "Min Misclassifications: 78\n",
      "Epoch 45: train_loss=0.8279, train_acc=0.9650 | val_loss=0.4778, val_acc=0.9175, val_mis=66\n",
      "Min SSE: 93.73508074874695\n",
      "Min Misclassifications: 66\n",
      "Epoch 50: train_loss=0.7580, train_acc=0.9694 | val_loss=0.4617, val_acc=0.9163, val_mis=67\n",
      "  → no improvement for 1/10 epochs\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 86.62975096592376\n",
      "Final Min Misclassifications 66\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[4, 7, 4, 5, 7, 6, 7, 3, 4, 0, 2, 0, 4, 7, 4, 7, 6, 3, 5, 0, 5, 0, 0, 1, 4, 5, 0, 1, 7, 5, 7, 1, 7, 3, 6, 0, 1, 7, 6, 7, 5, 4, 3, 1, 6, 4, 7, 0, 1, 0, 1, 3, 1, 4, 7, 1, 4, 0, 3, 2, 6, 4, 6, 0, 6, 1, 4, 4, 6, 4, 5, 3, 2, 5, 7, 4, 3, 1, 7, 4, 2, 2, 2, 4, 2, 0, 3, 3, 3, 0, 0, 1, 4, 5, 5, 0, 4, 2, 0, 6, 4, 6, 7, 4, 4, 0, 3, 7, 3, 2, 1, 7, 0, 6, 0, 0, 7, 4, 2, 4, 2, 2, 2, 7, 7, 3, 4, 4, 5, 0, 5, 3, 2, 7, 1, 1, 1, 6, 0, 1, 2, 6, 4, 1, 4, 2, 5, 4, 7, 6, 7, 2, 1, 6, 4, 0, 6, 2, 0, 5, 6, 2, 3, 0, 3, 4, 1, 2, 4, 3, 3, 3, 1, 4, 2, 2, 3, 2, 1, 7, 5, 6, 5, 6, 0, 3, 7, 6, 4, 1, 4, 3, 6, 2, 3, 7, 0, 1, 4, 7, 3, 0, 1, 5, 6, 4, 2, 0, 5, 6, 4, 3, 0, 6, 0, 4, 1, 2, 2, 3, 3, 3, 3, 6, 3, 0, 5, 5, 5, 6, 2, 2, 1, 2, 4, 6, 1, 5, 6, 4, 3, 5, 3, 3, 5, 1, 5, 6, 3, 5, 2, 7, 0, 7, 6, 1, 6, 3, 2, 0, 2, 2, 5, 7, 1, 3, 0, 3, 3, 0, 7, 0, 2, 1, 2, 5, 5, 5, 0, 2, 2, 0, 4, 2, 2, 0, 1, 3, 7, 4, 1, 5, 5, 4, 3, 5, 5, 6, 5, 5, 3, 7, 4, 2, 3, 3, 2, 7, 2, 5, 5, 2, 1, 5, 3, 5, 7, 3, 5, 6, 2, 3, 3, 3, 5, 3, 3, 7, 2, 3, 4, 1, 7, 6, 3, 3, 7, 7, 2, 6, 2, 2, 5, 5, 3, 3, 7, 4, 7, 7, 7, 0, 0, 6, 7, 7, 4, 4, 2, 2, 5, 6, 6, 7, 1, 2, 4, 5, 7, 3, 5, 7, 6, 6, 7, 5, 4, 6, 3, 0, 1, 2, 6, 2, 7, 5, 5, 5, 7, 4, 7, 6, 2, 1, 6, 3, 3, 5, 4, 0, 5, 2, 3, 2, 4, 2, 3, 4, 6, 5, 0, 2, 2, 1, 7, 7, 2, 7, 5, 2, 7, 7, 6, 0, 1, 4, 7, 6, 4, 5, 7, 3, 3, 1, 3, 3, 0, 1, 1, 3, 2, 7, 5, 1, 0, 5, 4, 7, 1, 4, 0, 6, 7, 1, 4, 7, 5, 4, 4, 2, 1, 7, 5, 5, 2, 6, 2, 1, 4, 6, 5, 6, 4, 6, 4, 7, 6, 2, 6, 5, 2, 6, 0, 7, 7, 1, 5, 4, 3, 4, 2, 6, 2, 5, 0, 7, 3, 2, 7, 3, 2, 1, 1, 7, 7, 6, 7, 2, 4, 1, 6, 4, 4, 0, 3, 2, 7, 3, 4, 7, 7, 0, 1, 5, 6, 3, 1, 0, 5, 1, 1, 3, 1, 4, 4, 1, 3, 3, 0, 0, 1, 3, 6, 0, 0, 6, 1, 1, 7, 4, 3, 0, 2, 7, 5, 6, 5, 1, 6, 0, 0, 4, 6, 1, 3, 5, 6, 1, 7, 1, 4, 6, 2, 1, 1, 3, 0, 7, 2, 5, 3, 7, 6, 3, 7, 0, 4, 1, 2, 7, 1, 1, 2, 5, 6, 7, 1, 7, 3, 6, 1, 4, 6, 6, 1, 3, 4, 5, 5, 1, 7, 5, 5, 3, 5, 4, 5, 4, 5, 1, 4, 3, 4, 5, 5, 7, 1, 5, 7, 5, 4, 6, 0, 7, 5, 4, 7, 2, 4, 3, 3, 0, 2, 0, 7, 5, 6, 4, 5, 0, 6, 7, 6, 6, 3, 1, 4, 7, 5, 2, 6, 5, 0, 0, 1, 0, 7, 2, 2, 4, 3, 6, 6, 7, 5, 2, 6, 5, 7, 7, 1, 5, 7, 0, 7, 7, 7, 5, 6, 0, 6, 7, 4, 7, 7, 6, 0, 6, 6, 5, 4, 0, 0, 3, 5, 3, 3, 3, 3, 0, 7, 0, 7, 6, 1, 7, 1, 2, 6, 2, 2, 4, 5, 3, 0, 7, 6, 6, 0, 6, 6, 7, 0, 4, 6, 1, 5, 1, 2, 5, 3, 7, 6, 7, 7, 5, 3, 5, 6, 2, 6, 3, 0, 2, 7, 2, 5, 6, 4, 2, 2, 6, 3, 3, 1, 5, 7, 5, 0, 3, 5, 4, 2, 0, 5, 0, 1, 1, 7, 6, 6, 1, 4, 3, 1, 6, 3, 7, 1, 1, 3, 4, 4, 4, 7, 4, 0, 7, 2, 0]\n",
      "New best training duration:  0:00:15\n",
      "Given hidden layer counts and learning rate:  32 16 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 23 ---------\n",
      "h1 = 32\n",
      "h2 = 16\n",
      "{'hidden1': 32, 'hidden2': 16, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.3220, train_acc=0.9372 | val_loss=0.7501, val_acc=0.8425, val_mis=126\n",
      "Min SSE: 142.42762239718166\n",
      "Min Misclassifications: 126\n",
      "Epoch 10: train_loss=0.7722, train_acc=0.9678 | val_loss=0.4515, val_acc=0.9237, val_mis=61\n",
      "Min SSE: 82.0661256216851\n",
      "Min Misclassifications: 61\n",
      "Epoch 15: train_loss=0.5463, train_acc=0.9785 | val_loss=0.3270, val_acc=0.9550, val_mis=36\n",
      "Min SSE: 58.39690995005908\n",
      "Min Misclassifications: 36\n",
      "Epoch 20: train_loss=0.4156, train_acc=0.9839 | val_loss=0.2653, val_acc=0.9675, val_mis=26\n",
      "Min SSE: 45.83941198333619\n",
      "Min Misclassifications: 26\n",
      "Epoch 25: train_loss=0.3369, train_acc=0.9877 | val_loss=0.1917, val_acc=0.9688, val_mis=25\n",
      "Min SSE: 35.7082975132877\n",
      "Min Misclassifications: 25\n",
      "Epoch 30: train_loss=0.2819, train_acc=0.9893 | val_loss=0.1868, val_acc=0.9700, val_mis=24\n",
      "Min SSE: 28.973687560974604\n",
      "Min Misclassifications: 24\n",
      "Epoch 35: train_loss=0.2492, train_acc=0.9908 | val_loss=0.1367, val_acc=0.9688, val_mis=25\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 40: train_loss=0.2219, train_acc=0.9912 | val_loss=0.1437, val_acc=0.9762, val_mis=19\n",
      "Min SSE: 23.65823944016175\n",
      "Min Misclassifications: 19\n",
      "Epoch 45: train_loss=0.1969, train_acc=0.9928 | val_loss=0.1376, val_acc=0.9700, val_mis=24\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.1758, train_acc=0.9938 | val_loss=0.1357, val_acc=0.9700, val_mis=24\n",
      "  → no improvement for 2/10 epochs\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 23.385485455756445\n",
      "Final Min Misclassifications 19\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[7, 0, 6, 5, 3, 5, 0, 7, 2, 1, 6, 5, 7, 0, 6, 1, 3, 4, 4, 3, 1, 0, 6, 2, 4, 2, 0, 5, 5, 7, 3, 3, 2, 4, 4, 0, 1, 3, 4, 6, 2, 1, 5, 3, 7, 3, 4, 1, 0, 7, 6, 5, 2, 5, 0, 3, 1, 2, 1, 6, 5, 5, 3, 3, 1, 5, 5, 2, 6, 4, 3, 2, 2, 6, 5, 2, 2, 1, 4, 0, 4, 7, 0, 5, 4, 2, 3, 2, 1, 4, 1, 2, 0, 0, 4, 0, 5, 6, 4, 7, 5, 5, 4, 7, 2, 7, 5, 6, 2, 1, 5, 2, 1, 3, 7, 1, 6, 7, 0, 3, 0, 1, 7, 4, 5, 0, 6, 7, 1, 4, 4, 4, 0, 0, 2, 5, 1, 6, 5, 2, 4, 6, 6, 7, 5, 0, 5, 4, 2, 0, 2, 1, 4, 6, 5, 2, 0, 4, 5, 3, 6, 0, 5, 4, 5, 5, 0, 6, 1, 2, 1, 1, 1, 7, 5, 2, 4, 5, 1, 6, 2, 6, 2, 0, 3, 0, 5, 6, 7, 7, 4, 3, 6, 0, 4, 7, 5, 2, 0, 2, 5, 3, 3, 7, 4, 5, 1, 1, 2, 2, 1, 6, 5, 5, 7, 4, 0, 0, 5, 7, 2, 6, 1, 1, 1, 6, 2, 5, 2, 1, 3, 4, 5, 5, 1, 6, 2, 2, 0, 7, 0, 0, 3, 2, 2, 2, 4, 5, 0, 6, 6, 5, 0, 4, 5, 6, 1, 2, 1, 1, 0, 4, 3, 7, 0, 6, 7, 5, 1, 2, 1, 3, 3, 7, 2, 7, 3, 4, 4, 1, 5, 4, 2, 4, 1, 2, 3, 0, 3, 4, 0, 3, 2, 2, 3, 0, 3, 6, 5, 4, 4, 2, 6, 2, 2, 7, 0, 4, 6, 7, 1, 4, 5, 6, 0, 4, 1, 5, 3, 2, 1, 2, 0, 5, 1, 2, 6, 0, 3, 6, 0, 6, 2, 4, 6, 4, 6, 1, 2, 5, 4, 3, 3, 0, 7, 6, 4, 4, 3, 2, 5, 1, 6, 0, 1, 0, 3, 6, 1, 2, 0, 3, 2, 7, 1, 2, 1, 3, 1, 6, 0, 6, 1, 2, 3, 1, 4, 3, 2, 2, 1, 0, 6, 1, 2, 7, 7, 2, 6, 0, 6, 3, 6, 1, 2, 4, 1, 6, 1, 2, 4, 6, 3, 2, 6, 5, 2, 0, 7, 6, 6, 5, 6, 4, 4, 6, 4, 2, 1, 1, 6, 2, 2, 3, 3, 6, 5, 1, 4, 4, 3, 2, 3, 3, 1, 1, 3, 4, 3, 2, 4, 6, 0, 2, 6, 1, 1, 5, 6, 4, 7, 6, 4, 4, 1, 6, 5, 3, 0, 3, 3, 3, 5, 4, 0, 5, 6, 4, 5, 5, 2, 4, 7, 1, 3, 2, 2, 2, 3, 7, 6, 7, 6, 6, 6, 0, 3, 4, 4, 7, 1, 5, 4, 7, 6, 6, 1, 1, 1, 6, 4, 3, 4, 7, 0, 5, 6, 7, 4, 3, 4, 2, 5, 3, 7, 0, 2, 2, 5, 0, 3, 0, 1, 5, 7, 2, 2, 3, 6, 7, 5, 1, 4, 3, 6, 6, 6, 4, 0, 0, 6, 6, 2, 0, 1, 0, 5, 4, 3, 5, 7, 0, 6, 6, 5, 6, 0, 4, 4, 3, 5, 0, 6, 7, 1, 0, 0, 0, 3, 7, 0, 7, 1, 2, 3, 3, 2, 2, 4, 5, 2, 5, 1, 2, 5, 6, 3, 5, 7, 5, 7, 5, 3, 7, 2, 5, 1, 4, 7, 5, 0, 1, 5, 6, 3, 7, 0, 4, 2, 5, 6, 7, 2, 3, 1, 4, 5, 5, 5, 4, 4, 4, 5, 6, 7, 7, 4, 5, 0, 3, 4, 5, 4, 4, 5, 4, 6, 0, 2, 0, 6, 3, 6, 1, 0, 0, 6, 2, 5, 4, 4, 3, 1, 7, 4, 6, 0, 7, 1, 4, 7, 3, 2, 1, 7, 0, 1, 7, 4, 3, 2, 6, 1, 4, 5, 7, 6, 3, 6, 2, 5, 1, 4, 3, 4, 0, 7, 3, 3, 5, 5, 7, 7, 7, 7, 3, 2, 6, 1, 4, 6, 6, 1, 0, 6, 5, 0, 7, 2, 5, 4, 6, 0, 5, 6, 1, 2, 3, 3, 6, 7, 0, 5, 6, 1, 0, 2, 4, 7, 0, 3, 3, 0, 7, 6, 5, 0, 6, 1, 2, 0, 4, 3, 2, 1, 5, 2, 2, 1, 3, 5, 7, 5, 1, 3, 0, 7, 2, 5, 6, 2, 6, 1, 1, 4, 0, 5, 1, 1, 0, 6, 2, 2, 7, 7, 0, 3, 5, 1, 1, 3, 7, 6, 6, 0, 6, 1, 5, 4, 2, 6, 0, 5, 3, 0, 7, 3, 5, 6, 7]\n",
      "--------- Config 24 ---------\n",
      "h1 = 32\n",
      "h2 = 16\n",
      "{'hidden1': 32, 'hidden2': 16, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.9788, train_acc=0.9541 | val_loss=0.5300, val_acc=0.8750, val_mis=100\n",
      "Min SSE: 101.0659482442482\n",
      "Min Misclassifications: 100\n",
      "Epoch 10: train_loss=0.5012, train_acc=0.9797 | val_loss=0.2691, val_acc=0.9437, val_mis=45\n",
      "Min SSE: 48.745583920841874\n",
      "Min Misclassifications: 45\n",
      "Epoch 15: train_loss=0.3421, train_acc=0.9864 | val_loss=0.2675, val_acc=0.9550, val_mis=36\n",
      "Min SSE: 43.2128784770878\n",
      "Min Misclassifications: 36\n",
      "Epoch 20: train_loss=0.2514, train_acc=0.9902 | val_loss=0.1532, val_acc=0.9738, val_mis=21\n",
      "Min SSE: 26.409964038389376\n",
      "Min Misclassifications: 21\n",
      "Epoch 25: train_loss=0.2122, train_acc=0.9918 | val_loss=0.1389, val_acc=0.9738, val_mis=21\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 30: train_loss=0.1873, train_acc=0.9929 | val_loss=0.0817, val_acc=0.9825, val_mis=14\n",
      "Min SSE: 18.18823141266677\n",
      "Min Misclassifications: 14\n",
      "Epoch 35: train_loss=0.1643, train_acc=0.9937 | val_loss=0.0926, val_acc=0.9812, val_mis=15\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 40: train_loss=0.1490, train_acc=0.9942 | val_loss=0.0995, val_acc=0.9862, val_mis=11\n",
      "Min SSE: 15.187291519001596\n",
      "Min Misclassifications: 11\n",
      "Epoch 45: train_loss=0.1335, train_acc=0.9948 | val_loss=0.0909, val_acc=0.9825, val_mis=14\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 50: train_loss=0.1190, train_acc=0.9955 | val_loss=0.0545, val_acc=0.9925, val_mis=6\n",
      "Min SSE: 9.958755872641358\n",
      "Min Misclassifications: 6\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 9.958755872641358\n",
      "Final Min Misclassifications 6\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[3, 1, 0, 6, 4, 4, 6, 2, 5, 3, 1, 0, 2, 1, 7, 6, 0, 7, 2, 5, 1, 5, 1, 3, 6, 6, 7, 6, 7, 5, 4, 6, 4, 1, 7, 1, 2, 5, 3, 3, 1, 1, 1, 4, 5, 7, 0, 3, 7, 4, 5, 0, 6, 3, 1, 4, 5, 1, 4, 4, 0, 7, 7, 2, 0, 0, 5, 2, 0, 7, 1, 1, 7, 2, 7, 3, 0, 2, 3, 6, 1, 3, 3, 4, 1, 0, 7, 0, 6, 5, 0, 1, 6, 6, 7, 4, 4, 4, 0, 0, 2, 3, 2, 4, 5, 6, 3, 2, 7, 5, 0, 4, 7, 0, 3, 7, 0, 2, 0, 4, 3, 6, 7, 2, 7, 5, 6, 5, 2, 7, 0, 5, 2, 3, 2, 2, 1, 3, 2, 0, 3, 1, 0, 1, 3, 5, 4, 1, 4, 1, 6, 0, 4, 4, 6, 2, 0, 3, 3, 4, 6, 4, 4, 6, 2, 3, 4, 1, 4, 0, 4, 1, 3, 5, 7, 2, 3, 7, 5, 7, 1, 7, 7, 4, 3, 2, 7, 5, 2, 4, 7, 2, 7, 3, 3, 6, 5, 2, 6, 6, 7, 1, 1, 1, 7, 4, 6, 5, 2, 7, 7, 5, 6, 7, 7, 7, 1, 4, 1, 3, 5, 1, 5, 6, 5, 3, 7, 7, 0, 2, 7, 4, 3, 2, 2, 1, 5, 1, 7, 7, 0, 1, 0, 4, 0, 6, 7, 7, 5, 5, 4, 2, 5, 0, 1, 5, 6, 0, 6, 6, 5, 4, 4, 7, 5, 3, 7, 3, 5, 4, 5, 3, 6, 3, 2, 2, 4, 3, 6, 7, 7, 3, 6, 3, 7, 7, 6, 7, 5, 3, 7, 4, 3, 0, 7, 7, 1, 1, 5, 2, 7, 2, 7, 3, 2, 6, 7, 2, 6, 1, 1, 0, 6, 0, 1, 1, 1, 2, 3, 4, 0, 7, 6, 7, 0, 5, 5, 1, 5, 5, 0, 4, 0, 3, 1, 3, 0, 0, 3, 1, 1, 4, 0, 5, 3, 4, 2, 7, 6, 6, 5, 5, 5, 0, 0, 1, 1, 7, 1, 2, 0, 1, 5, 0, 6, 0, 3, 0, 4, 0, 4, 0, 7, 0, 2, 0, 7, 7, 7, 5, 3, 0, 1, 6, 1, 4, 2, 2, 6, 5, 6, 0, 5, 1, 2, 4, 7, 4, 5, 7, 2, 5, 3, 3, 0, 5, 7, 3, 4, 5, 6, 6, 2, 6, 3, 0, 3, 1, 4, 3, 1, 2, 0, 5, 7, 7, 4, 3, 1, 5, 5, 5, 6, 5, 4, 1, 3, 1, 2, 4, 3, 0, 2, 6, 2, 2, 6, 5, 5, 2, 2, 7, 6, 4, 6, 2, 0, 5, 6, 7, 1, 0, 1, 6, 6, 7, 1, 3, 0, 1, 0, 7, 7, 4, 0, 7, 0, 1, 7, 2, 6, 7, 2, 3, 1, 7, 3, 7, 4, 7, 5, 2, 1, 7, 3, 3, 3, 2, 7, 0, 5, 7, 5, 1, 2, 7, 1, 3, 0, 0, 7, 6, 6, 2, 1, 4, 4, 5, 5, 6, 0, 3, 5, 3, 5, 2, 3, 1, 3, 0, 4, 4, 1, 5, 2, 3, 6, 6, 2, 4, 0, 4, 4, 1, 0, 1, 6, 3, 3, 3, 4, 7, 0, 3, 6, 4, 2, 1, 1, 2, 1, 6, 3, 2, 1, 1, 1, 6, 3, 7, 5, 1, 0, 5, 0, 4, 7, 3, 6, 3, 6, 0, 4, 1, 4, 2, 5, 7, 5, 5, 6, 6, 6, 5, 4, 2, 2, 5, 7, 7, 3, 5, 3, 4, 5, 4, 5, 2, 5, 1, 2, 5, 6, 2, 5, 1, 1, 0, 4, 5, 6, 7, 1, 6, 7, 4, 6, 5, 5, 2, 7, 1, 3, 4, 4, 0, 2, 3, 2, 5, 3, 5, 4, 5, 3, 1, 6, 5, 7, 6, 1, 2, 6, 0, 2, 3, 3, 2, 3, 7, 2, 4, 3, 1, 2, 4, 1, 7, 2, 7, 1, 4, 7, 6, 4, 7, 4, 6, 1, 5, 5, 1, 0, 6, 4, 0, 3, 0, 4, 6, 3, 1, 7, 0, 6, 4, 1, 3, 0, 5, 1, 0, 5, 0, 6, 6, 7, 1, 2, 6, 2, 7, 0, 0, 5, 7, 7, 5, 2, 4, 7, 1, 1, 0, 6, 1, 0, 2, 2, 1, 1, 6, 0, 6, 2, 5, 7, 4, 2, 5, 4, 3, 0, 6, 0, 2, 4, 7, 2, 7, 4, 4, 6, 1, 1, 7, 7, 7, 4, 3, 4, 0, 2, 0, 1, 7, 6, 4, 1, 5, 2, 6, 7, 4, 4, 6, 5, 7, 7, 2, 3, 3, 0, 7, 5, 6, 0, 2, 1, 4, 7, 0, 0, 3, 3, 4, 2, 3, 7, 0]\n",
      "New best training duration:  0:00:14\n",
      "Given hidden layer counts and learning rate:  32 16 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 25 ---------\n",
      "h1 = 16\n",
      "h2 = 16\n",
      "{'hidden1': 16, 'hidden2': 16, 'learning_rate': 0.001}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=2.7278, train_acc=0.8758 | val_loss=1.7838, val_acc=0.4300, val_mis=456\n",
      "Min SSE: 317.23390849699115\n",
      "Min Misclassifications: 456\n",
      "Epoch 10: train_loss=2.3551, train_acc=0.8889 | val_loss=1.4810, val_acc=0.5112, val_mis=391\n",
      "Min SSE: 273.3017346064304\n",
      "Min Misclassifications: 391\n",
      "Epoch 15: train_loss=2.0246, train_acc=0.8994 | val_loss=1.2361, val_acc=0.6975, val_mis=242\n",
      "Min SSE: 231.97527728442043\n",
      "Min Misclassifications: 242\n",
      "Epoch 20: train_loss=1.7726, train_acc=0.9131 | val_loss=1.0726, val_acc=0.7650, val_mis=188\n",
      "Min SSE: 200.24051286130845\n",
      "Min Misclassifications: 188\n",
      "Epoch 25: train_loss=1.5683, train_acc=0.9271 | val_loss=0.9414, val_acc=0.8087, val_mis=153\n",
      "Min SSE: 174.30122746139193\n",
      "Min Misclassifications: 153\n",
      "Epoch 30: train_loss=1.3996, train_acc=0.9367 | val_loss=0.8318, val_acc=0.8337, val_mis=133\n",
      "Min SSE: 155.07317585978421\n",
      "Min Misclassifications: 133\n",
      "Epoch 35: train_loss=1.2618, train_acc=0.9421 | val_loss=0.7627, val_acc=0.8287, val_mis=137\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 40: train_loss=1.1490, train_acc=0.9465 | val_loss=0.6775, val_acc=0.8600, val_mis=112\n",
      "Min SSE: 128.11941315570053\n",
      "Min Misclassifications: 112\n",
      "Epoch 45: train_loss=1.0517, train_acc=0.9507 | val_loss=0.6374, val_acc=0.8612, val_mis=111\n",
      "Min SSE: 119.2561982175381\n",
      "Min Misclassifications: 111\n",
      "Epoch 50: train_loss=0.9638, train_acc=0.9548 | val_loss=0.5592, val_acc=0.8850, val_mis=92\n",
      "Min SSE: 108.7589854930447\n",
      "Min Misclassifications: 92\n",
      "learning rate: 0.001\n",
      "logistic slope: 2\n",
      "Final Min SSE: 108.7589854930447\n",
      "Final Min Misclassifications 92\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[5, 3, 3, 5, 0, 7, 4, 4, 6, 4, 1, 6, 1, 6, 7, 6, 7, 0, 7, 7, 6, 5, 5, 0, 4, 4, 3, 3, 7, 5, 1, 7, 4, 5, 7, 7, 7, 4, 7, 1, 3, 0, 7, 7, 5, 5, 6, 5, 0, 6, 4, 4, 1, 3, 5, 2, 5, 7, 2, 1, 3, 0, 5, 7, 5, 7, 7, 4, 5, 0, 3, 6, 1, 7, 3, 0, 0, 6, 2, 0, 2, 5, 3, 7, 0, 4, 1, 5, 0, 4, 0, 1, 1, 1, 5, 0, 7, 0, 5, 2, 4, 1, 4, 4, 0, 4, 2, 2, 6, 7, 5, 1, 5, 6, 0, 7, 7, 5, 4, 0, 4, 3, 7, 0, 5, 0, 7, 1, 4, 2, 1, 1, 0, 3, 3, 2, 3, 2, 1, 3, 0, 1, 4, 2, 1, 4, 2, 3, 5, 4, 4, 7, 1, 4, 1, 6, 5, 5, 3, 0, 3, 5, 0, 7, 7, 7, 3, 2, 7, 0, 6, 0, 1, 4, 0, 1, 0, 1, 6, 4, 7, 1, 4, 0, 5, 4, 0, 3, 5, 1, 5, 7, 1, 4, 7, 2, 2, 7, 0, 6, 1, 7, 5, 4, 5, 4, 4, 1, 0, 0, 3, 4, 4, 3, 5, 2, 7, 3, 7, 1, 1, 2, 6, 2, 0, 0, 1, 7, 5, 5, 1, 1, 2, 2, 1, 1, 0, 0, 0, 4, 7, 0, 6, 5, 7, 5, 1, 3, 6, 7, 4, 7, 6, 3, 4, 3, 0, 4, 3, 5, 3, 4, 7, 2, 4, 7, 0, 5, 0, 2, 5, 6, 5, 7, 1, 2, 6, 7, 6, 3, 4, 5, 2, 6, 5, 2, 6, 4, 4, 7, 0, 6, 0, 5, 2, 1, 1, 4, 3, 6, 3, 3, 0, 2, 2, 2, 6, 4, 0, 5, 0, 6, 5, 4, 7, 4, 6, 6, 1, 7, 1, 1, 1, 2, 5, 2, 0, 4, 5, 5, 6, 4, 2, 0, 4, 5, 1, 6, 6, 7, 7, 2, 4, 2, 7, 7, 2, 7, 0, 0, 3, 2, 1, 1, 6, 4, 1, 6, 5, 0, 2, 2, 3, 6, 4, 2, 4, 7, 1, 5, 2, 3, 4, 3, 4, 1, 0, 6, 3, 5, 3, 3, 0, 5, 3, 3, 0, 7, 0, 3, 3, 1, 2, 5, 6, 3, 2, 2, 1, 4, 4, 1, 5, 3, 4, 7, 2, 4, 7, 6, 3, 5, 0, 6, 4, 1, 5, 2, 2, 3, 7, 7, 0, 0, 6, 4, 7, 4, 0, 2, 3, 5, 5, 3, 4, 4, 1, 2, 1, 4, 4, 5, 3, 2, 5, 3, 0, 2, 2, 7, 5, 5, 0, 6, 4, 2, 5, 2, 2, 7, 1, 6, 6, 0, 4, 3, 0, 4, 7, 6, 3, 0, 4, 6, 0, 5, 7, 2, 6, 7, 4, 4, 2, 1, 0, 3, 0, 6, 6, 4, 4, 1, 5, 5, 0, 7, 1, 5, 5, 5, 0, 6, 7, 7, 5, 0, 4, 0, 0, 7, 7, 1, 3, 5, 4, 3, 3, 5, 0, 7, 2, 3, 7, 7, 0, 1, 7, 6, 5, 6, 7, 3, 4, 0, 0, 1, 2, 4, 5, 0, 7, 7, 2, 1, 4, 2, 2, 2, 3, 1, 6, 3, 4, 7, 7, 6, 7, 6, 6, 0, 2, 4, 2, 1, 4, 1, 1, 6, 7, 5, 6, 1, 4, 2, 3, 3, 0, 4, 7, 3, 1, 2, 7, 2, 3, 5, 4, 4, 2, 3, 4, 0, 5, 5, 5, 4, 2, 6, 2, 5, 5, 2, 6, 1, 0, 3, 3, 7, 3, 3, 3, 2, 5, 6, 6, 3, 0, 0, 0, 4, 6, 1, 3, 5, 4, 1, 3, 0, 7, 4, 1, 5, 6, 2, 7, 0, 3, 4, 3, 3, 7, 1, 6, 4, 6, 0, 1, 2, 4, 6, 5, 3, 0, 2, 7, 0, 6, 0, 1, 5, 2, 6, 4, 2, 0, 3, 0, 7, 2, 0, 4, 7, 4, 3, 4, 0, 1, 0, 3, 3, 1, 5, 2, 7, 3, 0, 2, 6, 2, 4, 6, 5, 2, 0, 7, 3, 3, 7, 0, 7, 0, 5, 1, 3, 6, 5, 0, 6, 0, 3, 5, 3, 5, 4, 7, 6, 3, 0, 5, 6, 3, 4, 3, 1, 2, 2, 1, 1, 2, 5, 0, 7, 5, 5, 2, 1, 7, 5, 0, 3, 4, 3, 5, 3, 0, 3, 6, 5, 2, 0, 6, 6, 4, 7, 5, 7, 4, 2, 0, 4, 2, 4, 6, 4, 2, 3, 3, 1, 3, 6, 1, 4, 4, 1, 2, 4, 2, 3, 1, 2, 0, 0, 3, 2, 3, 0, 5, 3, 7, 0, 7, 1, 5, 2, 3, 1, 0, 7, 3, 7]\n",
      "--------- Config 26 ---------\n",
      "h1 = 16\n",
      "h2 = 16\n",
      "{'hidden1': 16, 'hidden2': 16, 'learning_rate': 0.005}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.4857, train_acc=0.9316 | val_loss=0.8934, val_acc=0.7925, val_mis=166\n",
      "Min SSE: 165.79444907815252\n",
      "Min Misclassifications: 166\n",
      "Epoch 10: train_loss=0.9398, train_acc=0.9590 | val_loss=0.5589, val_acc=0.8425, val_mis=126\n",
      "Min SSE: 108.80827577845781\n",
      "Min Misclassifications: 126\n",
      "Epoch 15: train_loss=0.6548, train_acc=0.9716 | val_loss=0.4057, val_acc=0.9275, val_mis=58\n",
      "Min SSE: 73.40378614000802\n",
      "Min Misclassifications: 58\n",
      "Epoch 20: train_loss=0.4882, train_acc=0.9805 | val_loss=0.2644, val_acc=0.9450, val_mis=44\n",
      "Min SSE: 55.71745144930985\n",
      "Min Misclassifications: 44\n",
      "Epoch 25: train_loss=0.3871, train_acc=0.9847 | val_loss=0.2051, val_acc=0.9587, val_mis=33\n",
      "Min SSE: 41.049331833181384\n",
      "Min Misclassifications: 33\n",
      "Epoch 30: train_loss=0.3190, train_acc=0.9878 | val_loss=0.2008, val_acc=0.9637, val_mis=29\n",
      "Min SSE: 34.674847611533664\n",
      "Min Misclassifications: 29\n",
      "Epoch 35: train_loss=0.2692, train_acc=0.9902 | val_loss=0.1639, val_acc=0.9688, val_mis=25\n",
      "Min SSE: 30.89743948488971\n",
      "Min Misclassifications: 25\n",
      "Epoch 40: train_loss=0.2414, train_acc=0.9909 | val_loss=0.1453, val_acc=0.9688, val_mis=25\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.2086, train_acc=0.9925 | val_loss=0.1120, val_acc=0.9775, val_mis=18\n",
      "Min SSE: 19.461327290092573\n",
      "Min Misclassifications: 18\n",
      "Epoch 50: train_loss=0.1932, train_acc=0.9931 | val_loss=0.1116, val_acc=0.9788, val_mis=17\n",
      "Min SSE: 19.296622654598153\n",
      "Min Misclassifications: 17\n",
      "learning rate: 0.005\n",
      "logistic slope: 2\n",
      "Final Min SSE: 19.296622654598153\n",
      "Final Min Misclassifications 17\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[7, 5, 4, 3, 5, 0, 7, 6, 1, 2, 0, 3, 6, 2, 0, 5, 6, 3, 7, 7, 2, 3, 4, 5, 7, 5, 5, 2, 1, 5, 3, 2, 6, 0, 7, 5, 6, 3, 0, 7, 2, 2, 1, 6, 7, 1, 6, 4, 3, 3, 6, 1, 5, 4, 5, 0, 4, 0, 2, 3, 3, 6, 6, 6, 1, 5, 5, 1, 0, 4, 5, 1, 3, 3, 6, 7, 2, 2, 3, 4, 1, 3, 2, 7, 7, 5, 4, 6, 6, 0, 0, 6, 5, 6, 7, 1, 3, 1, 0, 4, 4, 1, 3, 1, 4, 2, 2, 1, 7, 7, 3, 7, 5, 3, 2, 4, 6, 6, 4, 5, 3, 1, 7, 7, 0, 3, 2, 7, 1, 7, 1, 0, 0, 2, 7, 6, 3, 4, 0, 2, 6, 5, 3, 3, 4, 1, 1, 5, 2, 2, 4, 6, 4, 0, 2, 6, 0, 4, 2, 0, 2, 0, 2, 6, 1, 7, 3, 0, 6, 6, 0, 3, 6, 4, 4, 4, 4, 0, 0, 5, 0, 0, 7, 3, 4, 7, 7, 5, 6, 4, 4, 4, 7, 6, 7, 6, 2, 7, 2, 1, 2, 0, 7, 4, 1, 6, 4, 2, 0, 7, 1, 5, 5, 5, 7, 5, 7, 0, 1, 5, 1, 0, 5, 1, 1, 1, 3, 2, 6, 0, 1, 2, 4, 4, 0, 5, 4, 0, 4, 7, 0, 0, 7, 6, 3, 5, 5, 0, 2, 4, 5, 4, 3, 3, 3, 4, 0, 5, 5, 2, 4, 6, 0, 4, 3, 4, 5, 1, 4, 7, 4, 2, 6, 4, 5, 6, 2, 7, 6, 2, 0, 1, 6, 0, 1, 1, 6, 3, 7, 6, 4, 3, 3, 2, 4, 5, 7, 5, 5, 3, 5, 3, 6, 4, 6, 5, 3, 0, 0, 3, 4, 0, 5, 0, 1, 1, 7, 5, 4, 6, 6, 5, 3, 1, 5, 6, 2, 0, 6, 1, 6, 2, 4, 1, 7, 7, 0, 6, 4, 1, 5, 3, 4, 5, 5, 1, 2, 0, 5, 7, 4, 5, 7, 0, 5, 4, 6, 3, 3, 2, 3, 7, 1, 4, 3, 2, 7, 0, 6, 2, 2, 0, 1, 4, 3, 6, 4, 1, 3, 5, 7, 1, 7, 2, 5, 4, 7, 6, 5, 3, 1, 7, 3, 3, 4, 4, 7, 3, 2, 3, 1, 2, 6, 3, 5, 5, 1, 7, 3, 2, 0, 0, 5, 7, 6, 4, 4, 2, 0, 1, 5, 7, 0, 5, 7, 1, 7, 7, 7, 4, 7, 2, 4, 0, 0, 1, 2, 5, 5, 1, 7, 2, 4, 7, 6, 5, 0, 2, 5, 7, 2, 4, 0, 4, 5, 5, 4, 0, 7, 7, 3, 1, 7, 3, 5, 5, 3, 4, 2, 0, 5, 3, 7, 3, 3, 6, 4, 7, 3, 2, 6, 6, 6, 5, 2, 7, 3, 5, 6, 2, 2, 4, 0, 5, 5, 5, 3, 3, 0, 4, 0, 3, 2, 7, 1, 6, 5, 6, 4, 5, 0, 5, 1, 7, 2, 4, 0, 3, 5, 6, 4, 1, 0, 7, 5, 7, 4, 2, 4, 1, 6, 1, 3, 7, 7, 6, 0, 7, 2, 1, 6, 5, 4, 4, 2, 0, 7, 6, 5, 3, 2, 0, 0, 3, 5, 0, 5, 1, 5, 6, 6, 2, 6, 1, 7, 1, 0, 2, 7, 6, 6, 7, 1, 3, 7, 7, 5, 7, 0, 2, 0, 0, 1, 4, 6, 0, 0, 6, 6, 1, 6, 6, 6, 6, 3, 2, 3, 1, 2, 1, 3, 2, 3, 1, 3, 4, 2, 2, 1, 1, 4, 4, 0, 3, 5, 3, 4, 3, 2, 6, 0, 2, 4, 6, 7, 0, 5, 4, 3, 1, 6, 6, 0, 5, 3, 6, 3, 1, 6, 4, 7, 1, 6, 5, 3, 4, 1, 7, 2, 2, 0, 6, 4, 2, 0, 5, 0, 7, 6, 5, 6, 6, 1, 1, 3, 1, 4, 0, 7, 3, 6, 1, 0, 4, 6, 5, 7, 5, 4, 7, 7, 7, 5, 5, 3, 7, 6, 7, 0, 6, 2, 5, 0, 1, 1, 6, 0, 5, 3, 4, 7, 7, 0, 6, 7, 6, 0, 4, 2, 0, 5, 2, 2, 3, 1, 0, 4, 6, 4, 7, 0, 7, 5, 4, 0, 7, 6, 4, 2, 3, 4, 5, 3, 3, 0, 4, 2, 2, 5, 7, 4, 5, 1, 5, 6, 6, 0, 4, 0, 0, 0, 1, 0, 6, 6, 5, 5, 6, 3, 2, 7, 0, 3, 0, 0, 2, 2, 4, 3, 5, 3, 5, 6, 0, 4, 3, 5, 7, 0, 6, 1, 2, 6, 6, 7, 3, 7, 0, 5, 2, 4, 6, 1, 7, 3, 7, 5, 2, 2, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config 27 ---------\n",
      "h1 = 16\n",
      "h2 = 16\n",
      "{'hidden1': 16, 'hidden2': 16, 'learning_rate': 0.01}\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=0.9945, train_acc=0.9539 | val_loss=0.5220, val_acc=0.9087, val_mis=73\n",
      "Min SSE: 94.27060362733687\n",
      "Min Misclassifications: 73\n",
      "Epoch 10: train_loss=0.5403, train_acc=0.9775 | val_loss=0.2676, val_acc=0.9575, val_mis=34\n",
      "Min SSE: 45.51974236855209\n",
      "Min Misclassifications: 34\n",
      "Epoch 15: train_loss=0.3699, train_acc=0.9852 | val_loss=0.1599, val_acc=0.9700, val_mis=24\n",
      "Min SSE: 28.474147320946592\n",
      "Min Misclassifications: 24\n",
      "Epoch 20: train_loss=0.2866, train_acc=0.9885 | val_loss=0.1055, val_acc=0.9750, val_mis=20\n",
      "Min SSE: 23.611892402413794\n",
      "Min Misclassifications: 20\n",
      "Epoch 25: train_loss=0.2379, train_acc=0.9903 | val_loss=0.0861, val_acc=0.9812, val_mis=15\n",
      "Min SSE: 18.72805163245666\n",
      "Min Misclassifications: 15\n",
      "Epoch 30: train_loss=0.1957, train_acc=0.9924 | val_loss=0.0839, val_acc=0.9862, val_mis=11\n",
      "Min SSE: 14.619006804456767\n",
      "Min Misclassifications: 11\n",
      "Epoch 35: train_loss=0.1696, train_acc=0.9935 | val_loss=0.0686, val_acc=0.9862, val_mis=11\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 40: train_loss=0.1503, train_acc=0.9942 | val_loss=0.0697, val_acc=0.9850, val_mis=12\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 45: train_loss=0.1451, train_acc=0.9945 | val_loss=0.0693, val_acc=0.9812, val_mis=15\n",
      "  → no improvement for 3/10 epochs\n",
      "Epoch 50: train_loss=0.1272, train_acc=0.9952 | val_loss=0.0723, val_acc=0.9762, val_mis=19\n",
      "  → no improvement for 4/10 epochs\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 12.73737198011054\n",
      "Final Min Misclassifications 11\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n",
      "[6, 7, 6, 3, 1, 2, 6, 6, 7, 1, 3, 3, 3, 2, 6, 4, 3, 5, 4, 3, 1, 6, 4, 7, 7, 0, 5, 2, 1, 4, 1, 1, 3, 7, 2, 3, 7, 2, 2, 0, 3, 3, 5, 6, 2, 0, 2, 1, 7, 0, 7, 6, 1, 6, 7, 4, 5, 7, 7, 3, 0, 3, 7, 2, 7, 2, 4, 7, 4, 4, 3, 3, 3, 6, 5, 2, 4, 5, 5, 5, 1, 1, 4, 1, 3, 0, 2, 3, 3, 2, 4, 0, 1, 7, 7, 6, 6, 7, 4, 0, 3, 0, 4, 5, 4, 4, 4, 4, 1, 2, 5, 0, 0, 7, 1, 4, 3, 0, 0, 2, 2, 1, 3, 2, 2, 5, 1, 5, 6, 7, 2, 1, 0, 5, 6, 3, 0, 5, 2, 4, 0, 0, 7, 5, 1, 6, 6, 0, 5, 2, 0, 5, 5, 7, 7, 3, 7, 3, 4, 7, 5, 4, 7, 2, 2, 1, 5, 5, 4, 5, 0, 6, 2, 1, 3, 1, 0, 0, 5, 6, 2, 6, 4, 4, 4, 5, 5, 1, 5, 6, 4, 0, 1, 5, 3, 6, 0, 7, 6, 4, 3, 0, 4, 5, 6, 6, 2, 1, 0, 1, 7, 0, 5, 7, 6, 1, 2, 4, 1, 0, 1, 3, 3, 1, 1, 5, 7, 7, 4, 1, 6, 6, 3, 4, 3, 1, 3, 0, 6, 4, 1, 0, 3, 4, 4, 4, 2, 1, 0, 5, 0, 1, 6, 1, 5, 7, 0, 6, 2, 3, 4, 2, 6, 4, 7, 4, 2, 6, 0, 2, 0, 5, 7, 0, 6, 1, 2, 3, 6, 1, 5, 4, 2, 0, 0, 1, 4, 6, 7, 7, 6, 0, 6, 1, 0, 3, 5, 4, 6, 3, 3, 2, 3, 4, 4, 6, 4, 3, 5, 3, 2, 0, 6, 6, 0, 1, 6, 3, 1, 5, 3, 5, 6, 3, 3, 0, 2, 2, 4, 2, 6, 5, 5, 7, 0, 0, 5, 4, 0, 2, 5, 6, 3, 0, 3, 4, 7, 6, 2, 2, 5, 1, 7, 2, 0, 1, 2, 3, 2, 6, 3, 1, 3, 3, 6, 2, 5, 5, 3, 0, 2, 0, 4, 2, 6, 3, 1, 4, 7, 2, 7, 1, 7, 5, 6, 1, 6, 7, 2, 7, 4, 3, 7, 1, 1, 2, 6, 2, 4, 0, 5, 3, 6, 5, 2, 4, 5, 6, 3, 2, 6, 1, 3, 3, 7, 6, 3, 5, 0, 7, 2, 6, 6, 0, 0, 1, 1, 3, 3, 2, 3, 5, 6, 6, 2, 5, 0, 0, 7, 6, 0, 4, 3, 2, 4, 4, 6, 7, 6, 1, 3, 3, 0, 6, 2, 4, 6, 1, 7, 0, 3, 6, 4, 1, 4, 7, 5, 0, 2, 5, 4, 0, 0, 1, 6, 0, 5, 7, 3, 0, 5, 6, 5, 5, 4, 4, 0, 4, 1, 0, 2, 5, 5, 7, 3, 5, 3, 2, 4, 3, 4, 7, 3, 2, 6, 2, 1, 5, 7, 6, 5, 6, 1, 4, 7, 7, 1, 3, 5, 3, 4, 4, 7, 7, 7, 2, 2, 4, 4, 6, 6, 4, 0, 4, 3, 6, 4, 2, 2, 5, 5, 2, 3, 3, 0, 5, 2, 7, 4, 2, 5, 0, 4, 3, 7, 4, 3, 2, 6, 1, 3, 1, 2, 3, 5, 7, 3, 4, 0, 2, 2, 3, 7, 6, 6, 7, 1, 7, 7, 3, 5, 4, 6, 0, 5, 1, 1, 5, 5, 2, 5, 1, 7, 1, 1, 3, 5, 5, 6, 5, 2, 5, 2, 3, 1, 4, 6, 4, 0, 6, 6, 2, 3, 7, 4, 4, 6, 3, 2, 2, 3, 5, 1, 5, 3, 6, 7, 2, 5, 1, 3, 6, 7, 7, 0, 7, 4, 2, 1, 2, 7, 3, 7, 7, 4, 1, 3, 4, 6, 3, 0, 0, 4, 7, 5, 0, 6, 7, 2, 0, 2, 1, 4, 5, 0, 5, 3, 5, 6, 7, 3, 2, 1, 2, 5, 6, 1, 3, 2, 1, 5, 6, 1, 3, 7, 4, 4, 3, 1, 6, 5, 4, 1, 1, 3, 2, 5, 5, 6, 4, 2, 6, 6, 2, 3, 6, 0, 3, 1, 1, 1, 0, 5, 6, 0, 2, 2, 2, 2, 3, 7, 2, 2, 2, 1, 5, 1, 2, 5, 7, 6, 4, 7, 3, 6, 1, 4, 3, 4, 0, 7, 6, 1, 1, 3, 7, 6, 3, 3, 7, 7, 6, 5, 0, 6, 1, 4, 2, 7, 6, 3, 4, 1, 1, 6, 3, 4, 3, 6, 4, 0, 2, 0, 1, 1, 0, 1, 3, 0, 5, 4, 4, 1, 1, 4, 1, 3, 1, 4, 7, 1, 6, 0, 2, 6, 5, 0, 5, 6, 4]\n",
      "New best training duration:  0:00:13\n",
      "Given hidden layer counts and learning rate:  16 16 0.01\n",
      "Best Configuration Accuracy:\n",
      "Hidden Layer 1: 256\n",
      "Hidden Layer 2: 64\n",
      "Learning Rate: 0.01\n",
      "Minimum SSE: 7.864794579016\n",
      "Minimum Misclassifications: 5\n",
      "Training Loss: 1620.8398496296954\n",
      "Training Accuracy: 12135.375\n",
      "Validation Loss: 0.045930484829508345\n",
      "Validation Accuracy: 0.99375\n",
      "Training Duration: 0:00:48\n",
      "Best Configuration Time:\n",
      "Hidden Layer 1: 16\n",
      "Hidden Layer 2: 16\n",
      "Learning Rate: 0.01\n",
      "Minimum SSE: 17.663765786095176\n",
      "Minimum Misclassifications: 19\n",
      "Training Loss: 1551.8571814464744\n",
      "Training Accuracy: 12140.875\n",
      "Validation Loss: 0.07228858413533462\n",
      "Validation Accuracy: 0.97625\n",
      "Training Duration: 0:00:13\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "best_configuration_accuracy = {\n",
    "    'hidden_layer_count1': 0,\n",
    "    'hidden_layer_count2': 0,\n",
    "    'learning_rate': 0,\n",
    "    'min_sse': float('inf'),\n",
    "    'min_misclassifications': float('inf'),\n",
    "    'training_loss': 0,\n",
    "    'training_accuracy': 0,\n",
    "    'validation_loss': 0,\n",
    "    'validation_accuracy': 0,\n",
    "    'training_duration': timedelta(999999999),\n",
    "}\n",
    "best_configuration_time = {\n",
    "    'hidden_layer_count1': 0,\n",
    "    'hidden_layer_count2': 0,\n",
    "    'learning_rate': 0,\n",
    "    'min_sse': float('inf'),\n",
    "    'min_misclassifications': float('inf'),\n",
    "    'training_loss': 0,\n",
    "    'training_accuracy': 0,\n",
    "    'validation_loss': 0,\n",
    "    'validation_accuracy': 0,\n",
    "    'training_duration': timedelta(999999999),\n",
    "}\n",
    "\n",
    "training_summary = []\n",
    "\n",
    "for i, config in enumerate(hyperparameter_configs):\n",
    "\n",
    "    hidden_layer_count1 = config['hidden1']\n",
    "    hidden_layer_count2 = config['hidden2']\n",
    "    learning_rate = config['learning_rate']\n",
    "    print(f\"--------- Config {i+1} ---------\")\n",
    "    print(f\"h1 = {hidden_layer_count1}\")\n",
    "    print(f\"h2 = {hidden_layer_count2}\")\n",
    "    print(config)\n",
    "    print(\"---------            ---------\")\n",
    "    \n",
    "    # training accuracy, training loss, validation_accuracy, validation_loss\n",
    "    (training_results, validation_results, training_all_actual_curr, training_all_computed_curr,\n",
    "     validation_all_actual_curr, validation_all_computed_curr, best_W1, best_W2, best_W3, best_b1,\n",
    "     best_b2, best_b3, start_time, end_time, duration, min_train_loss, min_train_acc,\n",
    "        min_val_loss, min_val_acc) = backprop_training_v2(\n",
    "        df=df,\n",
    "        df_labels=df_labels,\n",
    "        patience=2, \n",
    "        hidden_layer_count1=hidden_layer_count1,\n",
    "        hidden_layer_count2=hidden_layer_count2,\n",
    "        learning_rate=learning_rate,\n",
    "        tanh_param_a=tanh_param_a,\n",
    "        tanh_param_b=tanh_param_b,\n",
    "        leaky_param=leaky_param,\n",
    "        logistic_slope_param=logistic_slope_param,\n",
    "        activation_function1='tanh',\n",
    "        activation_function2='tanh')\n",
    "    print(validation_all_actual_curr)\n",
    "    \n",
    "    training_summary.append(\n",
    "        {'hidden1': hidden_layer_count1,\n",
    "         'hidden2': hidden_layer_count2,\n",
    "         'learning_rate': learning_rate,\n",
    "         'logistic slope': logistic_slope_param,\n",
    "         'duration': duration,\n",
    "         'training_loss': min_train_loss,\n",
    "         'training_accuracy': min_train_acc,\n",
    "         'validation_loss': min_val_loss,\n",
    "         'validation_accuracy': min_val_acc\n",
    "        }\n",
    "        )\n",
    "    \n",
    "    # Check if the current configuration has the best validation accuracy\n",
    "    # and update the best configuration if necessary\n",
    "    if validation_results[-1]['Validation Accuracy'] > best_configuration_accuracy['validation_accuracy']:\n",
    "        print(\"New best validation accuracy: \", validation_results[-1]['Validation Accuracy'])\n",
    "        print(\"Given hidden layer counts and learning rate: \", hidden_layer_count1, hidden_layer_count2, learning_rate)\n",
    "        best_configuration_accuracy['hidden_layer_count1'] = hidden_layer_count1\n",
    "        best_configuration_accuracy['hidden_layer_count2'] = hidden_layer_count2\n",
    "        best_configuration_accuracy['learning_rate'] = learning_rate\n",
    "        best_configuration_accuracy['min_sse'] = validation_results[-1]['SSE']\n",
    "        best_configuration_accuracy['min_misclassifications'] = validation_results[-1]['Misclassifications']\n",
    "        best_configuration_accuracy['training_loss'] = training_results[-1]['Training Loss']\n",
    "        best_configuration_accuracy['training_accuracy'] = training_results[-1]['Training Accuracy']\n",
    "        best_configuration_accuracy['validation_loss'] = validation_results[-1]['Validation Loss']\n",
    "        best_configuration_accuracy['validation_accuracy'] = validation_results[-1]['Validation Accuracy']\n",
    "        best_configuration_accuracy['training_duration'] = duration\n",
    "\n",
    "    # Check if the current configuration has the best training duration\n",
    "    # and update the best configuration if necessary\n",
    "    if duration < best_configuration_time['training_duration']:\n",
    "        print(\"New best training duration: \", duration)\n",
    "        print(\"Given hidden layer counts and learning rate: \", hidden_layer_count1, hidden_layer_count2, learning_rate)\n",
    "        best_configuration_time['hidden_layer_count1'] = hidden_layer_count1\n",
    "        best_configuration_time['hidden_layer_count2'] = hidden_layer_count2\n",
    "        best_configuration_time['learning_rate'] = learning_rate\n",
    "        best_configuration_time['min_sse'] = validation_results[-1]['SSE']\n",
    "        best_configuration_time['min_misclassifications'] = validation_results[-1]['Misclassifications']\n",
    "        best_configuration_time['training_loss'] = training_results[-1]['Training Loss']\n",
    "        best_configuration_time['training_accuracy'] = training_results[-1]['Training Accuracy']\n",
    "        best_configuration_time['validation_loss'] = validation_results[-1]['Validation Loss']\n",
    "        best_configuration_time['validation_accuracy'] = validation_results[-1]['Validation Accuracy']\n",
    "        best_configuration_time['training_duration'] = duration\n",
    "    \n",
    "    calculate_and_save_metrics(training_results, validation_results, training_all_actual_curr,\n",
    "                               training_all_computed_curr, validation_all_actual_curr,\n",
    "                               validation_all_computed_curr, hidden_layer_count1, hidden_layer_count2,\n",
    "                               best_W1, best_W2, best_W3, best_b1, best_b2, best_b3,\n",
    "                               learning_rate, \"tanh\", \"tanh\", start_time, end_time, duration)\n",
    "\n",
    "print(\"Best Configuration Accuracy:\")\n",
    "print(f\"Hidden Layer 1: {best_configuration_accuracy['hidden_layer_count1']}\")\n",
    "print(f\"Hidden Layer 2: {best_configuration_accuracy['hidden_layer_count2']}\")\n",
    "print(f\"Learning Rate: {best_configuration_accuracy['learning_rate']}\")\n",
    "print(f\"Minimum SSE: {best_configuration_accuracy['min_sse']}\")\n",
    "print(f\"Minimum Misclassifications: {best_configuration_accuracy['min_misclassifications']}\")\n",
    "print(f\"Training Loss: {best_configuration_accuracy['training_loss']}\")\n",
    "print(f\"Training Accuracy: {best_configuration_accuracy['training_accuracy']}\")\n",
    "print(f\"Validation Loss: {best_configuration_accuracy['validation_loss']}\")\n",
    "print(f\"Validation Accuracy: {best_configuration_accuracy['validation_accuracy']}\")\n",
    "print(f\"Training Duration: {best_configuration_accuracy['training_duration']}\")\n",
    "\n",
    "print(\"Best Configuration Time:\")\n",
    "print(f\"Hidden Layer 1: {best_configuration_time['hidden_layer_count1']}\")\n",
    "print(f\"Hidden Layer 2: {best_configuration_time['hidden_layer_count2']}\")\n",
    "print(f\"Learning Rate: {best_configuration_time['learning_rate']}\")\n",
    "print(f\"Minimum SSE: {best_configuration_time['min_sse']}\")\n",
    "print(f\"Minimum Misclassifications: {best_configuration_time['min_misclassifications']}\")\n",
    "print(f\"Training Loss: {best_configuration_time['training_loss']}\")\n",
    "print(f\"Training Accuracy: {best_configuration_time['training_accuracy']}\")\n",
    "print(f\"Validation Loss: {best_configuration_time['validation_loss']}\")\n",
    "print(f\"Validation Accuracy: {best_configuration_time['validation_accuracy']}\")\n",
    "print(f\"Training Duration: {best_configuration_time['training_duration']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dcec080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training weights and biases into their own files\n",
    "A_best_W1_df = pd.DataFrame(best_W1)\n",
    "A_best_b1_df = pd.DataFrame(best_b1)\n",
    "A_best_W2_df = pd.DataFrame(best_W2)\n",
    "A_best_b2_df = pd.DataFrame(best_b2)\n",
    "A_best_W3_df = pd.DataFrame(best_W3)\n",
    "A_best_b3_df = pd.DataFrame(best_b3)\n",
    "\n",
    "os.makedirs(os.path.join(\"best_weights\", \"A\"), exist_ok=True)\n",
    "A_best_W1_df.to_csv(os.path.join(\"best_weights\", \"A\", \"best_W1.csv\"), index=False, header=None)\n",
    "A_best_b1_df.to_csv(os.path.join(\"best_weights\", \"A\", \"best_b1.csv\"), index=False, header=None)\n",
    "A_best_W2_df.to_csv(os.path.join(\"best_weights\", \"A\", \"best_W2.csv\"), index=False, header=None)\n",
    "A_best_b2_df.to_csv(os.path.join(\"best_weights\", \"A\", \"best_b2.csv\"), index=False, header=None)\n",
    "A_best_W3_df.to_csv(os.path.join(\"best_weights\", \"A\", \"best_W3.csv\"), index=False, header=None)\n",
    "A_best_b3_df.to_csv(os.path.join(\"best_weights\", \"A\", \"best_b3.csv\"), index=False, header=None)\n",
    "# Save the best configuration to a file\n",
    "os.makedirs(os.path.join(\"best_configuration\",\"A\"), exist_ok=True)\n",
    "with open(os.path.join(\"best_configuration\", \"A\", \"best_configuration.txt\"), 'w') as f:\n",
    "    f.write(\"Best Configuration Accuracy:\\n\")\n",
    "    for key, value in best_configuration_accuracy.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\nBest Configuration Time:\\n\")\n",
    "    for key, value in best_configuration_time.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "training_summary_pda = pd.DataFrame(training_summary)\n",
    "training_summary_pda.to_csv('training_summary_a.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300750ef",
   "metadata": {
    "id": "300750ef"
   },
   "source": [
    "# Training Phase 2 using Network B Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef4837",
   "metadata": {},
   "source": [
    "This takes the best configuration from the Network A runs, and runs 50 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270dbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Network = 'B'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c551d",
   "metadata": {},
   "source": [
    "Best Configuration based on both accuracy and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70a03d49",
   "metadata": {
    "id": "70a03d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Config Network B ---------\n",
      "h1 = 32\n",
      "h2 = 16\n",
      "learning rate = 0.01\n",
      "---------            ---------\n",
      "Epoch  5: train_loss=1.3032, train_acc=0.9390 | val_loss=1.1689, val_acc=0.4963, val_mis=403\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 403\n",
      "Epoch 10: train_loss=0.6918, train_acc=0.9700 | val_loss=0.6959, val_acc=0.6088, val_mis=313\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 313\n",
      "Epoch 15: train_loss=0.4456, train_acc=0.9823 | val_loss=0.4807, val_acc=0.6438, val_mis=285\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 285\n",
      "Epoch 20: train_loss=0.3264, train_acc=0.9876 | val_loss=0.3603, val_acc=0.6913, val_mis=247\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 247\n",
      "Epoch 25: train_loss=0.2539, train_acc=0.9904 | val_loss=0.1593, val_acc=0.7350, val_mis=212\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 212\n",
      "Epoch 30: train_loss=0.2132, train_acc=0.9921 | val_loss=0.1095, val_acc=0.7675, val_mis=186\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 186\n",
      "Epoch 35: train_loss=0.1733, train_acc=0.9937 | val_loss=0.0838, val_acc=0.7837, val_mis=173\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 173\n",
      "Epoch 40: train_loss=0.1549, train_acc=0.9943 | val_loss=0.0816, val_acc=0.7788, val_mis=177\n",
      "  → no improvement for 1/10 epochs\n",
      "Epoch 45: train_loss=0.1401, train_acc=0.9948 | val_loss=0.0925, val_acc=0.7837, val_mis=173\n",
      "  → no improvement for 2/10 epochs\n",
      "Epoch 50: train_loss=0.1239, train_acc=0.9955 | val_loss=0.1375, val_acc=0.7937, val_mis=165\n",
      "Min SSE: 283.8004227863593\n",
      "Min Misclassifications: 165\n",
      "learning rate: 0.01\n",
      "logistic slope: 2\n",
      "Final Min SSE: 283.8004227863593\n",
      "Final Min Misclassifications 165\n",
      "lengths\n",
      "12200\n",
      "12200\n",
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "print(f\"--------- Config Network B ---------\")\n",
    "print(f\"h1 = {32}\")\n",
    "print(f\"h2 = {16}\")\n",
    "print(f\"learning rate = {0.01}\")\n",
    "print(\"---------            ---------\")\n",
    "H1=32\n",
    "H2=16\n",
    "(training_results, validation_results, training_all_actual_curr,\n",
    " training_all_computed_curr, validation_all_actual_curr, validation_all_computed_curr,\n",
    " networkb_best_W1, networkb_best_W2, networkb_best_W3, networkb_best_b1, networkb_best_b2,\n",
    " networkb_best_b3, start_time, end_time, duration, min_train_loss, min_train_acc,\n",
    "        min_val_loss, min_val_acc) = backprop_training_v2(\n",
    "        df=df,\n",
    "        df_labels=df_labels,\n",
    "        patience=2, \n",
    "        hidden_layer_count1=32,\n",
    "        hidden_layer_count2=16,\n",
    "        learning_rate=0.01,\n",
    "        tanh_param_a=tanh_param_a,\n",
    "        tanh_param_b=tanh_param_b,\n",
    "        leaky_param=leaky_param,\n",
    "        logistic_slope_param=logistic_slope_param,\n",
    "        activation_function1='relu',\n",
    "        activation_function2='relu')\n",
    "hidden_layer_count1=H1\n",
    "hidden_layer_count2=H2\n",
    "calculate_and_save_metrics(training_results, validation_results, training_all_actual_curr,\n",
    "                           training_all_computed_curr, validation_all_actual_curr,\n",
    "                           validation_all_computed_curr, hidden_layer_count1, hidden_layer_count2,\n",
    "                           networkb_best_W1, networkb_best_W2, networkb_best_W3, networkb_best_b1,\n",
    "                           networkb_best_b2, networkb_best_b3, learning_rate, \"relu\", \"relu\",\n",
    "                           start_time, end_time, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a80eb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training weights and biases into their own files\n",
    "B_best_W1_df = pd.DataFrame(networkb_best_W1)\n",
    "B_best_b1_df = pd.DataFrame(networkb_best_b1)\n",
    "B_best_W2_df = pd.DataFrame(networkb_best_W2)\n",
    "B_best_b2_df = pd.DataFrame(networkb_best_b2)\n",
    "B_best_W3_df = pd.DataFrame(networkb_best_W3)\n",
    "B_best_b3_df = pd.DataFrame(networkb_best_b3)\n",
    "\n",
    "os.makedirs(os.path.join(\"best_weights\", \"B\"), exist_ok=True)\n",
    "B_best_W1_df.to_csv(os.path.join(\"best_weights\", \"B\", \"best_W1.csv\"), index=False, header=None)\n",
    "B_best_b1_df.to_csv(os.path.join(\"best_weights\", \"B\", \"best_b1.csv\"), index=False, header=None)\n",
    "B_best_W2_df.to_csv(os.path.join(\"best_weights\", \"B\", \"best_W2.csv\"), index=False, header=None)\n",
    "B_best_b2_df.to_csv(os.path.join(\"best_weights\", \"B\", \"best_b2.csv\"), index=False, header=None)\n",
    "B_best_W3_df.to_csv(os.path.join(\"best_weights\", \"B\", \"best_W3.csv\"), index=False, header=None)\n",
    "B_best_b3_df.to_csv(os.path.join(\"best_weights\", \"B\", \"best_b3.csv\"), index=False, header=None)\n",
    "# Save the best configuration to a file\n",
    "os.makedirs(os.path.join(\"best_configuration\",\"B\"), exist_ok=True)\n",
    "with open(os.path.join(\"best_configuration\", \"B\", \"best_configuration.txt\"), 'w') as f:\n",
    "    f.write(\"Best Configuration Accuracy:\\n\")\n",
    "    f.write(str(min_val_acc))\n",
    "    f.write(\"\\nBest Configuration Time:\\n\")\n",
    "    f.write(str(duration))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Hidden Layer 1: \")\n",
    "    f.write(str(32))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Hidden Layer 2: \")\n",
    "    f.write(str(16))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Learning Rate: \")\n",
    "    f.write(str(0.01))\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ac257",
   "metadata": {},
   "source": [
    "# Run best weights from Networks A and B on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ff941",
   "metadata": {},
   "source": [
    "## Network A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08ecabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions saved to 'predictions_for_test_tanh.csv\n"
     ]
    }
   ],
   "source": [
    "function_hidden1 = 'tanh'\n",
    "function_hidden2 = 'tanh'\n",
    "\n",
    "# Retrieve the best weights and biases\n",
    "best_W1 = pd.read_csv('best_weights/A/best_W1.csv', header=None).values\n",
    "best_b1 = pd.read_csv('best_weights/A/best_b1.csv', header=None).values\n",
    "best_W2 = pd.read_csv('best_weights/A/best_W2.csv', header=None).values\n",
    "best_b2 = pd.read_csv('best_weights/A/best_b2.csv', header=None).values\n",
    "best_W3 = pd.read_csv('best_weights/A/best_W3.csv', header=None).values\n",
    "best_b3 = pd.read_csv('best_weights/A/best_b3.csv', header=None).values\n",
    "# Load the test set\n",
    "df_test = pd.read_csv('test_set.csv', header=None)\n",
    "# Run forward_pass_v2 on the df_test which doesn't have labels\n",
    "X_test = df_test.to_numpy()\n",
    "# Perform forward pass\n",
    "outputs = forward_pass_v2(\n",
    "    function_hidden1, function_hidden2, function_output, X_test, best_W1, best_W2, best_W3,\n",
    "    best_b1, best_b2, best_b3, None, tanh_param_a, tanh_param_b, logistic_slope_param,\n",
    "    leaky_param)\n",
    "classification_computed = np.argmax(outputs, axis=1) + 1\n",
    "pd.DataFrame(classification_computed).to_csv('predictions_for_test_tanh.csv', index=False, header=None)\n",
    "print(\"Test set predictions saved to 'predictions_for_test_tanh.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c366c",
   "metadata": {},
   "source": [
    "## Network B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ae53fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions saved to 'predictions_for_test_tanh.csv\n"
     ]
    }
   ],
   "source": [
    "function_hidden1 = 'relu'\n",
    "function_hidden2 = 'relu'\n",
    "\n",
    "# Retrieve the best weights and biases\n",
    "best_W1 = pd.read_csv('best_weights/B/best_W1.csv', header=None).values\n",
    "best_b1 = pd.read_csv('best_weights/B/best_b1.csv', header=None).values\n",
    "best_W2 = pd.read_csv('best_weights/B/best_W2.csv', header=None).values\n",
    "best_b2 = pd.read_csv('best_weights/B/best_b2.csv', header=None).values\n",
    "best_W3 = pd.read_csv('best_weights/B/best_W3.csv', header=None).values\n",
    "best_b3 = pd.read_csv('best_weights/B/best_b3.csv', header=None).values\n",
    "# Load the test set\n",
    "df_test = pd.read_csv('test_set.csv', header=None)\n",
    "# Run forward_pass_v2 on the df_test which doesn't have labels\n",
    "X_test = df_test.to_numpy()\n",
    "# Perform forward pass\n",
    "outputs = forward_pass_v2(\n",
    "    function_hidden1, function_hidden2, function_output, X_test, best_W1, best_W2, best_W3,\n",
    "    best_b1, best_b2, best_b3, None, tanh_param_a, tanh_param_b, logistic_slope_param,\n",
    "    leaky_param)\n",
    "classification_computed = np.argmax(outputs, axis=1) + 1\n",
    "pd.DataFrame(classification_computed).to_csv('predictions_for_test_leakyrelu.csv', index=False, header=None)\n",
    "print(\"Test set predictions saved to 'predictions_for_test_tanh.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
